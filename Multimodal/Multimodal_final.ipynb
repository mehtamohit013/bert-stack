{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of MultiModal.ipynb","provenance":[],"collapsed_sections":["JHAMYwNfv5Th","quJKUGIXv8zk","tgk_opqd2prV","xnOxcgwk5WiU","rVzPL-EMTXpM","J2Mw6eG5KqVn","mwKqXD75KiPI","ZuGYeCAq97yQ"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JHAMYwNfv5Th"},"source":["# Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"_pwgo3m2wVQS","executionInfo":{"status":"ok","timestamp":1613459098291,"user_tz":-330,"elapsed":2944,"user":{"displayName":"MOHIT MEHTA","photoUrl":"","userId":"00949415454628222481"}},"outputId":"24b879cb-f569-49b2-c60e-60172b6970be"},"source":["!pip install transformers\n","# # !pip install torch==1.5.0 \n","# !pip install torchvision==0.4.0 -f https://download.pytorch.org/whl/torch_stable.html"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.3.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mz76Bz490lqB","executionInfo":{"status":"ok","timestamp":1613459098292,"user_tz":-330,"elapsed":2940,"user":{"displayName":"MOHIT MEHTA","photoUrl":"","userId":"00949415454628222481"}},"outputId":"205cb740-5757-4309-d911-391b9c20ceef"},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jKIzzX6J3QtS"},"source":["import pandas as pd\n","import pickle\n","import random\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","import os\n","from enum import Enum\n","from torch.nn import functional as F\n","import time\n","import logging\n","import numpy as np\n","\n","\n","from transformers import DistilBertTokenizerFast, DistilBertModel\n","\n","logger = logging.getLogger(__name__)\n","random.seed(13)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"quJKUGIXv8zk"},"source":["# Utilities"]},{"cell_type":"code","metadata":{"id":"u1t9DLnOsFN_"},"source":["def pytorch_cos_sim(a: torch.as_tensor, b: torch.as_tensor):\n","    \"\"\"\n","    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n","    This function can be used as a faster replacement for 1-scipy.spatial.distance.cdist(a,b)\n","    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n","    \"\"\"\n","    if not isinstance(a, torch.Tensor):\n","        a = torch.as_tensor(a)\n","\n","    if not isinstance(b, torch.Tensor):\n","        b = torch.as_tensor(b)\n","\n","    if len(a.shape) == 1:\n","        a = a.unsqueeze(0)\n","\n","    if len(b.shape) == 1:\n","        b = b.unsqueeze(0)\n","\n","    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n","    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n","    return torch.mm(a_norm, b_norm.transpose(0, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1cajVVruorC_"},"source":["def print_full(x):\n","    pd.set_option('display.max_rows', len(x))\n","    pd.set_option('display.max_columns', None)\n","    pd.set_option('display.width', 2000)\n","    pd.set_option('display.float_format', '{:20,.2f}'.format)\n","    pd.set_option('display.max_colwidth', None)\n","    print(x)\n","    pd.reset_option('display.max_rows')\n","    pd.reset_option('display.max_columns')\n","    pd.reset_option('display.width')\n","    pd.reset_option('display.float_format')\n","    pd.reset_option('display.max_colwidth')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tgk_opqd2prV"},"source":["# Dataset and Dataloader"]},{"cell_type":"markdown","metadata":{"id":"NQxUv21Ik7yo"},"source":["### Config"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DebNqaCF2uE_","executionInfo":{"status":"ok","timestamp":1613459098647,"user_tz":-330,"elapsed":1483,"user":{"displayName":"MOHIT MEHTA","photoUrl":"","userId":"00949415454628222481"}},"outputId":"b105430f-db9a-47c9-e9ed-784ef76205aa"},"source":["folder_quora = '/gdrive/MyDrive/quora_android_2'\n","folder = '/gdrive/MyDrive/MultiModal'\n","img_dir = '/gdrive/MyDrive/MultiModal/data'\n","BATCH_SIZE = 1\n","fin_BATCH_SIZE = 32\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xnOxcgwk5WiU"},"source":["###Loading Data"]},{"cell_type":"code","metadata":{"id":"N1RqPrOk5Ynm"},"source":["with open(folder_quora+'/data/splits/pandas_split.txt','rb') as a:\n","    train_qr=pickle.load(a)\n","    dev_qr = pickle.load(a)\n","    test_qr = pickle.load(a)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z5qm94QOFH2V"},"source":["with open(folder+'/data/splits/data_pos_neg.txt','rb') as a:\n","    train_data_pos = pickle.load(a)\n","    train_data_neg = pickle.load(a)\n","    dev_data_pos = pickle.load(a)\n","    dev_data_neg = pickle.load(a)\n","    test_data_pos = pickle.load(a)\n","    test_data_neg = pickle.load(a)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ODDEOOhwqY9_"},"source":["with open('/gdrive/MyDrive/sbert_supervised(for_data_only)/android_nosw_rearranged.txt','rb') as a:\n","    score_qr = pickle.load(a)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M2mT9dqsm5Vy"},"source":["### Creating Dataset and Dataloader class "]},{"cell_type":"code","metadata":{"id":"NqWN5n-Q8fOk"},"source":["# !pip install sentence-transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"x78sEuM43ncK"},"source":["# from sentence_transformers import models, losses, util, SentenceTransformer, SentencesDataset, InputExample, evaluation\n","# from sentence_transformers.cross_encoder import CrossEncoder"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X86sdgPk3lQx"},"source":["from PIL import Image\n","from torchvision import transforms\n","transform_pipe = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KXPoomQx4Zby"},"source":["class custom_dataset(Dataset):\n","    def __init__(self,qr,qr_idx,img_dir,label,transform = None,score_qr = score_qr):\n","        self.qr = qr\n","        self.qr_idx = qr_idx\n","        self.img_dir = img_dir\n","        self.label = label\n","        self.transform = transform\n","        self.score_qr = score_qr\n","\n","    def image_adder(self,id1):\n","        img_id1 = list()\n","        if((self.qr.at[id1,'Attachments'])!=None):\n","            for i in self.qr.at[id1,'Attachments']:\n","                try:\n","                    img_path = os.path.join(self.img_dir,i)\n","                    img = Image.open(img_path).convert('RGB')\n","                    if(self.transform):\n","                        img = self.transform(img)\n","                        img.reshape(3,224,224)\n","                    img_id1.append(img)\n","                except Exception as e: \n","                    print(e)\n","        else:\n","            img_id1.append(torch.zeros(3,224,224))\n","\n","        # Work on this, for few examples, it is still saying list index out of range\n","        if(len(img_id1)==0):\n","            # print('No attachments found for id {}'.format(id1))\n","            print(f'Something went wrong with the image of id {id1}')\n","            img_id1.append(torch.zeros(3,224,224))\n","\n","        return img_id1\n","    \n","    def __getitem__(self,idx):\n","        id1 = self.qr_idx[idx][0]\n","        id2 = self.qr_idx[idx][1]\n","        img_id1 = self.image_adder(id1)\n","        img_id2 = self.image_adder(id2)\n","\n","        # print(len(img_id1))\n","\n","        # print('Printing id1 {} and len {} and id2 {} and len {} '.format(\n","        #     id1,len(img_id1),\n","        #     id2, len(img_id2)\n","        # ))\n","\n","        # print('Printing id1 shape {} and id2  shape {}'.format(\n","        #     img_id1[0].shape,\n","        #     img_id2[0].shape\n","        # ))        \n","\n","        sample = {\n","            'image': [img_id1[0],img_id2[0]]    #Currently taking only one input image\n","        }\n","\n","        t1 = '[CLS]' + self.qr.loc[id1,'Title'] + ' ' + ' '.join(self.qr.loc[id1,'Tags']) + ' ' + self.qr.loc[id1,'Text'] + '[SEP]'\n","        t2 = '[CLS]' + self.qr.loc[id2,'Title']+ ' ' + ' '.join(self.qr.loc[id2,'Tags']) + ' ' + self.qr.loc[id2,'Text'] + '[SEP]'\n","        tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","        indexed_t1 = tokenizer.encode(t1,max_length = 512,truncation = True)\n","        indexed_t2 = tokenizer.encode(t2,max_length = 512,truncation = True)\n","        # t2_token = tokenizer.tokenize(t2)\n","        # indexed_t1 = tokenizer.convert_tokens_to_ids(t1_token)\n","        # indexed_t2 = tokenizer.convert_tokens_to_ids(t2_token)\n","\n","        while(len(indexed_t1)<512):\n","            indexed_t1.append(0)\n","        while(len(indexed_t2)<512):\n","            indexed_t2.append(0)\n","\n","        ten_t1 = torch.as_tensor(indexed_t1)[:512]\n","        ten_t2 = torch.as_tensor(indexed_t2)[:512]\n","        \n","        # related_score = list()\n","        for l in self.label:\n","            try:\n","                if(l==torch.tensor(1)):\n","                    related_score=(score_qr.loc[id1,'Related_Scores'][score_qr.loc[id1,'New_Related'].index(id2)])\n","                else:\n","                    related_score=(torch.tensor(0.0))\n","            except:\n","                related_score = torch.tensor(0.0)\n","\n","        try:\n","            sample[\"label\"] = self.label[idx]\n","            sample[\"token\"] = [ten_t1,ten_t2] # torch.Size([batch_size, 512])\n","            sample['score'] = related_score\n","        except Exception as e:\n","            print(e)\n","        \n","        return sample\n","\n","    def __len__(self):\n","        return len(self.label)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dujP6lnnrpJB"},"source":["### Intializing dataset and dataloader"]},{"cell_type":"code","metadata":{"id":"qRNteBxHOomg"},"source":["train_dataset = custom_dataset(train_qr,train_data_pos + train_data_neg,\n","                               img_dir,torch.ones(len(train_data_pos))+\n","                               torch.zeros(len(train_data_neg)),\n","                               transform = transform_pipe)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d78ebAQBSdJI"},"source":["train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=BATCH_SIZE,\n","    pin_memory=True,\n","    num_workers = 8,\n","    shuffle = True\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IU4CNMybfgqI"},"source":["dev_dataset = custom_dataset(pd.concat([train_qr,dev_qr]),dev_data_pos + dev_data_neg,\n","                               img_dir,torch.ones(len(dev_data_pos))+\n","                               torch.zeros(len(dev_data_neg)),\n","                               transform = transform_pipe)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AUvKZ6rifxQW"},"source":["dev_loader = DataLoader(\n","    dev_dataset,\n","    batch_size=BATCH_SIZE,\n","    pin_memory=True,\n","    num_workers = 8,\n","    shuffle = True\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fe1vYfiifhM2"},"source":["test_dataset = custom_dataset(pd.concat([train_qr,test_qr]),test_data_pos + test_data_neg,\n","                               img_dir,torch.ones(len(test_data_pos))+\n","                               torch.zeros(len(test_data_neg)),\n","                               transform = transform_pipe)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RP_N_Kb5f1jD"},"source":["test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=BATCH_SIZE,\n","    pin_memory=True,\n","    num_workers = 8,\n","    shuffle = True\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rVzPL-EMTXpM"},"source":["#Model"]},{"cell_type":"markdown","metadata":{"id":"jzm3kk6oj5uD"},"source":["### Downloading models"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Ye9P1XUUToUA"},"source":["from torchvision import models\n","res50 = models.resnet50(pretrained = True)\n","res50 = res50.to(device)\n","for param in res50.parameters():\n","    param.requires_grad = True\n","# res50.eval()\n","\n","distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n","distilbert = distilbert.to(device)\n","for param in distilbert.parameters():\n","    param.requires_grad = True\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e2QNS8cQj-az"},"source":["### Forward Hook"]},{"cell_type":"code","metadata":{"id":"9H9pkv80TYxA"},"source":["def get_activation(name, activation):\n","    def hook(model, input, output):\n","        activation[name] = output.detach()\n","    return hook"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RVbWlEu1kFKJ"},"source":["### 2d intra attention layer"]},{"cell_type":"code","metadata":{"id":"T967YR1fTcFo"},"source":["import math\n","class Final2d(torch.nn.Module):\n","    \"\"\" Custom Linear layer for equation (9) in paper --> 2D intra attention layer\"\"\" \n","    def __init__(self, size_in, size_out):\n","        super().__init__()\n","        self.size_in, self.size_out = size_in, size_out\n","        weights = torch.Tensor(size_out, size_in)\n","        self.weights = torch.nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.\n","\n","        # initialize weights and biases\n","        torch.nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5)) # weight init\n","        fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(self.weights)\n","\n","    def forward(self, x, a):\n","        # x.shape = batch_size, 768, 119\n","        # a.shape = batch_size, 119\n","        n = x.shape[2]\n","        h_cap = torch.zeros(x.shape[0], x.shape[1], device = device)\n","        # for k in range(x.shape[0]):\n","        #     for i in range(n):\n","        #         h_cap[k] = h_cap[k] + a[k][i]*torch.matmul(self.weights, x[k, :,i])\n","        z = torch.matmul(self.weights, x)\n","        for k in range(x.shape[0]):\n","            h_cap[k] = torch.sum(a[k, :]*z[k, :, :], dim = 1)\n","        return h_cap"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9O_fMyVlkJwu"},"source":["### Mask"]},{"cell_type":"code","metadata":{"id":"GvmgGBtPTt3W"},"source":["n_val = 360+49 #360 is the text input vector length, and 49 is the image vector length\n","sz = (BATCH_SIZE, n_val*n_val, 1)\n","mask = torch.zeros(sz, dtype=torch.bool, device = device)\n","for i in range(n_val):\n","    mask[:, i*n_val+i] = 1\n","        \n","for i in range(n_val-50, n_val):\n","    for j in range(n_val-50, n_val):\n","        mask[:, i*n_val+j] = 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kuuki0zTkLis"},"source":["### Model class"]},{"cell_type":"code","metadata":{"id":"zv3UCSWbUNGO"},"source":["class BridgeModel(torch.nn.Module):\n","    # define model elements\n","    def __init__(self):\n","        super(BridgeModel, self).__init__()\n","        # input to first hidden layer\n","        self.activation = {}\n","        # self.res50 = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n","        # self.res50 = models.resnet50(pretrained = True)\n","        # res50.eval()\n","        self.res50 = res50.to(device)\n","        self.res50.layer4[2].relu.register_forward_hook(get_activation('conv1', self.activation))\n","        self.res50.avgpool.register_forward_hook(get_activation('conv2', self.activation))\n","        self.bridge_seven_conv = torch.nn.Conv2d(in_channels=2048, out_channels=768, kernel_size=1, stride=1, padding = 0)\n","        self.bridge_one_conv = torch.nn.Conv2d(in_channels=2048, out_channels=768, kernel_size=1, stride=1, padding = 0)\n","        self.flatten = torch.nn.Flatten(start_dim = 2)\n","        self.distilbert = distilbert.to(device)\n","        # self.mod_v = list()\n","        self.mod_v = 360 #Overall text token length\n","        self.linear_2d = torch.nn.Linear(768*2, 1)\n","        self.soft_2d = torch.nn.Softmax(dim = 1)\n","        self.final_2d = Final2d(768, 768) #2D intra attention layer\n","        self.fc = torch.nn.Linear(768+2048+768, 500)\n","        # self.sigm = torch.nn.Sigmoid()\n","    # forward propagate input\n","    def forward(self, X1, X2):\n","        # input to first hidden layer/\n","        res_out = self.res50(X1)  # torch.Size([batch_size, 1000])\n","        seven_conv = self.activation['conv1'] # torch.Size([batch_size, 2048, 7, 7])\n","        one_conv = self.activation['conv2'] # torch.Size([batch_size, 2048, 1, 1])\n","        out3 = one_conv # torch.Size([batch_size, 2048, 1, 1])\n","        out3 = out3[:, :, 0, 0].clone()\n","        seven_conv = self.bridge_seven_conv(seven_conv)  # torch.Size([batch_size, 768, 7, 7])\n","        one_conv = self.bridge_one_conv(one_conv)  # torch.Size([batch_size, 768, 1, 1])\n","        seven_conv = self.flatten(seven_conv) # torch.Size([batch_size, 768, 49])\n","        one_conv = self.flatten(one_conv) # torch.Size([batch_size, 768, 1])\n","        bridge_cat_temp = torch.cat((one_conv, seven_conv), dim = 2) # torch.Size([1, 768, 50])\n","        bridge_cat = bridge_cat_temp.permute(0, 2, 1) # torch.Size([1, 50, 768])\n","        distilbert_embed = self.distilbert.embeddings(input_ids = X2) # torch.Size([1, 512, 768])\n","        distilbert_embed = distilbert_embed[:,:self.mod_v,:]\n","        attn_mask = torch.ones(distilbert_embed.shape[0],self.mod_v + 50).to(device)\n","        prev = torch.cat((distilbert_embed, bridge_cat), dim = 1) #562\n","        prev2 = prev[:, self.mod_v:, :]\n","        \n","        for i in range(6):\n","            part1 = self.distilbert.transformer.layer[i](prev,attn_mask)[0] # torch.Size([1, 562, 768])\n","            part2 = torch.matmul(part1[:, self.mod_v:, :], self.distilbert.transformer.layer[i].attention.v_lin.weight)\n","            part1 = part1[:, :self.mod_v, :] # torch.Size([1, 512, 768])\n","            part1 = torch.cat((part1, part2), dim = 1)\n","            prev = part1\n","            prev2 = prev[:, self.mod_v:, :]\n","            \n","        out1 = prev[:, 0, :]\n","        prev = prev[:, 1:, :]\n","        \n","        n = self.mod_v + 49 # length(n) = |v| + |g|\n","\n","        # mask = self.mask_creater(BATCH_SIZE,n) \n","\n","        hij = torch.zeros(prev.shape[0], n*n, 2*prev.shape[2], device = device) # batch_size, 119*119=14161, 768+768\n","        # for k in range(prev.shape[0]):\n","        #    for i in range(n):\n","        #        for j in range(n):\n","        #            hij[k][i*n+j] = torch.cat((prev[k][i], prev[k][j]), dim = 0)\n","\n","        prev_repeat1 =  prev.repeat(1, n, 1) \n","        prev_repeat2 = torch.repeat_interleave(prev, repeats = n, dim = 1)\n","        hij = torch.cat((prev_repeat1, prev_repeat2), dim = 2)\n","\n","        sij = self.linear_2d(hij) # batch_size, 14161, 1\n","        \n","        # aij = self.soft_2d(sij) # batch_size, 14161, 1\n","        \n","        sij[mask] = -1000\n","\n","        aij_tmp = self.soft_2d(sij) # batch_size, 14161, 1\n","\n","        aij = aij_tmp.reshape(aij_tmp.shape[0], n, n) # batch_size, n, n\n","        \n","        ai_cap = torch.zeros(prev.shape[0], n, device = device) # batch_size, n\n","        \n","        ai_cap = (torch.sum(aij, dim = 1) + torch.sum(aij, dim = 2))/2\n","        \n","        #for k in range(prev.shape[0]):\n","         #   for i in range(n):\n","          #      for j in range(n):\n","           #         ai_cap[k][i] = ai_cap[k][i] + aij[k][i*n+j][0]/2\n","            #        ai_cap[k][i] = ai_cap[k][i] + aij[k][j*n+i][0]/2\n","        \n","        new_hi = prev.permute(0, 2, 1)\n","        out2 = self.final_2d(new_hi, ai_cap) # torch.Size([batch_size, 768])\n","        \n","        out = torch.cat((out1, out2, out3), dim = 1) # torch.Size([batch_size, 2048+768+768])\n","        out = self.fc(out) # torch.Size([batch_size, 500])\n","        # out = torch.nn.functional.normalize(out, p=2, dim=1, eps=1e-12) #L2 normalizing the final tensor\n","        \n","        return out\n","\n","    # def mask_creater(self,n_val,BATCH_SIZE=BATCH_SIZE):\n","    #     print(n_val)\n","    #     sz = (BATCH_SIZE, n_val*n_val, 1)\n","    #     mask = torch.zeros(sz, dtype=torch.bool, device = device)\n","    #     for i in range(n_val):\n","    #         mask[:, i*n_val+i] = 1\n","                \n","    #     for i in range(n_val-50, n_val):\n","    #         for j in range(n_val-1, n_val):\n","    #             mask[:, i*n_val+j] = 1\n","        \n","    #     return mask"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J2Mw6eG5KqVn"},"source":["# Losses"]},{"cell_type":"markdown","metadata":{"id":"hFtpg_GR4iNJ"},"source":["## Multiple Negative Ranking loss"]},{"cell_type":"code","metadata":{"id":"xMIA3Ydod65P"},"source":["class negrankloss(nn.Module):\n","    def __init__(self,scale: float = 20.0,reduction:str = 'mean'):\n","        # self.cosine_sim = nn.CosineSimilarity()\n","        super().__init__()\n","        self.red = reduction\n","        self.scale = scale\n","        self.cross_entropy = nn.CrossEntropyLoss(reduction=self.red)\n","\n","    def cal_loss(self,emb1: torch.as_tensor,emb2: torch.as_tensor, label: torch.Tensor):\n","        scores  = pytorch_cos_sim(emb1,emb2) \n","        # print(f'The scores of cosine similarity for MNRloss is {scores}')\n","        labels = torch.as_tensor(range(len(scores)), dtype=torch.long, device=scores.device)\n","        loss = self.cross_entropy(scores, labels)\n","        return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tMbsWT-DlN1G"},"source":["MNRloss = negrankloss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3O5iEjYD7H-s"},"source":["## Online Constrantive Loss\n"]},{"cell_type":"code","metadata":{"id":"pv3V30gQ7LKy"},"source":["class SiameseDistanceMetric(Enum):\n","    \"\"\"\n","    The metric for the contrastive loss\n","    \"\"\"\n","    EUCLIDEAN = lambda x, y: F.pairwise_distance(x, y, p=2)\n","    MANHATTAN = lambda x, y: F.pairwise_distance(x, y, p=1)\n","    COSINE_DISTANCE = lambda x, y: 1-F.cosine_similarity(x, y)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zSArl7MQ4sO"},"source":["class OnlineConstrantiveLoss(nn.Module):\n","    def __init__(self,distance_metric=SiameseDistanceMetric.COSINE_DISTANCE,margin: float = 0.5):\n","        super().__init__()\n","        self.distance_metric = distance_metric\n","        self.margin = margin\n","\n","    def cal_loss(self,emb1,emb2,labels,size_average=False):\n","        distance_matrix = self.distance_metric(emb1,emb2)\n","        # print(f'distance matrix of OCloss is {distance_matrix}')\n","        negs = distance_matrix[labels == 0]\n","        poss = distance_matrix[labels == 1]\n","        # print(f'positive and negatives are {poss} and {negs}')\n","\n","        # select hard positive and hard negative pairs\n","        # But for current batch size of 1, it is impossible to consider hard positive and hard negative\n","        # negative_pairs = negs[negs < (poss.max() if len(poss) > 1 else negs.mean())]\n","        # positive_pairs = poss[poss > (negs.min() if len(negs) > 1 else poss.mean())]\n","\n","        negative_pairs = negs\n","        positive_pairs = poss\n","\n","        # print(f'positive and negative pairs are {positive_pairs} and {negative_pairs}')\n","\n","        positive_loss = positive_pairs.pow(2).sum()\n","        negative_loss = F.relu(self.margin - negative_pairs).pow(2).sum()\n","        # print(f'positive loss is {positive_loss} and negative loss is {negative_loss}')\n","        loss = positive_loss + negative_loss\n","        return loss\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cr5sO1wM8NIc"},"source":["OCloss = OnlineConstrantiveLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mWCOk6UhlIiM"},"source":["## Cosine Similarity Loss"]},{"cell_type":"code","metadata":{"id":"ynVvNMYLlOpb"},"source":["class CosineSimilarityLoss(nn.Module):\n","    def __init__(self, loss_fct = nn.MSELoss(), cos_score_transformation=nn.Identity()):\n","        super(CosineSimilarityLoss, self).__init__()\n","        self.loss_fct = loss_fct\n","        self.cos_score_transformation = cos_score_transformation\n","\n","\n","    def cal_loss(self,emb1:torch.Tensor,emb2:torch.Tensor, labels: torch.Tensor):\n","        output = self.cos_score_transformation(torch.cosine_similarity(emb1,emb2))\n","        return self.loss_fct(output, labels.view(-1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DbRuMqc3mNaY"},"source":["Cosloss = CosineSimilarityLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mwKqXD75KiPI"},"source":["# Calculating loss and optimizing"]},{"cell_type":"code","metadata":{"id":"_gc2jj5PKkGP"},"source":["from torch.optim import Adam\n","from torch.nn import BCELoss\n","import time\n","import copy\n","from transformers import get_linear_schedule_with_warmup\n","\n","def train_model(train_loader, model,num_epochs):\n","    model.train()\n","\n","    since = time.time()\n","\n","    optimizer = Adam(model.parameters())\n","    train_steps = num_epochs\n","\n","    acc_steps = fin_BATCH_SIZE/BATCH_SIZE\n","\n","    use_amp = False\n","    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n","    \n","    # enumerate epochs\n","    for epoch in range(num_epochs):\n","\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","        \n","        running_OCloss = 0.0\n","        running_MNRloss = 0.0\n","        running_Cosloss = 0.0\n","\n","        for i, batch in enumerate(train_loader):\n","\n","            with torch.cuda.amp.autocast(enabled=use_amp):   \n","                images = batch['image']\n","                token = batch['token']\n","                label = batch['label']\n","                score = batch['score']\n","\n","                images[0],images[1] = images[0].to(device),images[1].to(device)\n","                token[0],token[1] = token[0].to(device), token[1].to(device)\n","                label = label.to(device)\n","                score = score.to(device)\n","                \n","                # compute the model output\n","                yhat1 = model(images[0],token[0])\n","                yhat2 = model(images[1],token[1])\n","\n","                OCloss_val = OCloss.cal_loss(yhat1,yhat2,label)\n","                running_OCloss +=  OCloss_val.item()*BATCH_SIZE\n","                OCloss_val = OCloss_val/acc_steps\n","                # print(f'Ocloss values is {OCloss_val.item()}')\n","    \n","                MNRloss_val = MNRloss.cal_loss(yhat1,yhat2,label)\n","                running_MNRloss += MNRloss_val.item()*BATCH_SIZE\n","                MNRloss_val = MNRloss_val/acc_steps\n","                 # print(f'MNRloss values is {MNRloss_val}')\n","\n","                Cosloss_val = Cosloss.cal_loss(yhat1,yhat2,score)\n","                running_Cosloss += Cosloss_val.item()*BATCH_SIZE\n","                Cosloss_val = Cosloss_val/acc_steps\n","\n","\n","            scaler.scale(OCloss_val).backward(retain_graph = True)\n","            scaler.scale(MNRloss_val).backward(retain_graph=True)\n","            scaler.scale(Cosloss_val).backward()\n","\n","            if((i+1)%acc_steps == 0):\n","                scaler.step(optimizer)\n","                scaler.update()\n","                optimizer.zero_grad()\n","\n","            if(i%30 == 0 ):\n","                print(' OCloss is {} and MNRloss is {} and Cosloss is {} and time taken is {} after {} iterations'.format(\n","                    running_OCloss/((i+1)*BATCH_SIZE),\n","                    running_MNRloss/((i+1)*BATCH_SIZE),\n","                    running_Cosloss/((i+1)*BATCH_SIZE),\n","                    time.time()-since,\n","                    i))\n","\n","            del yhat1,yhat2, images, label, token, score, OCloss_val, Cosloss_val, MNRloss_val\n","\n","        save_dir = folder + '/model_state_dict'\n","        os.makedirs(save_dir, exist_ok=True) \n","        torch.save(model.state_dict(), save_dir + '/distilbert_cossim.bin') \n","        print(f\"Model Saved after epoch {epoch}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7AnEOxse-WiR"},"source":["# Training the model"]},{"cell_type":"code","metadata":{"id":"qsGN1shRiijm"},"source":["torch.cuda.empty_cache()\n","# torch.cuda.ipc_collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lMyEMF1Zijt7","executionInfo":{"status":"ok","timestamp":1613412685120,"user_tz":-330,"elapsed":13084,"user":{"displayName":"Ticket project _CKM","photoUrl":"","userId":"12122662661545911577"}},"outputId":"a6377524-31a2-4571-ea55-f5d17634fc70"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon Feb 15 18:11:25 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   63C    P0    30W /  70W |   1328MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nADvbQN9Lx6M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613458576973,"user_tz":-330,"elapsed":14330,"user":{"displayName":"MOHIT MEHTA","photoUrl":"","userId":"00949415454628222481"}},"outputId":"7c4f88f5-02b4-4888-e0ce-99f7b03ed18d"},"source":["model = BridgeModel().to(device)\n","print(sum(p.numel() for p in model.parameters()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["97451037\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PhF_7QMqM9Hx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"83649fbe-3608-4c1a-9507-309650be9bf1"},"source":["train_model(train_loader,model,1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 0/0\n","----------\n"," OCloss is 0.002375280950218439 and MNRloss is 0.6944969296455383 and Cosloss is 0.18439336121082306 and time taken is 42.082067012786865 after 0 iterations\n"," OCloss is 0.03494626876944551 and MNRloss is 0.7028353329627745 and Cosloss is 0.25314821399027304 and time taken is 180.1316978931427 after 30 iterations\n"," OCloss is 0.01776020457117371 and MNRloss is 0.6980558262496698 and Cosloss is 0.2520949334883299 and time taken is 348.59856247901917 after 60 iterations\n"," OCloss is 0.011906538631371128 and MNRloss is 0.6964812173948183 and Cosloss is 0.24214543582318904 and time taken is 515.3554110527039 after 90 iterations\n"," OCloss is 0.00895527454179868 and MNRloss is 0.6956738164602232 and Cosloss is 0.24628667419483838 and time taken is 682.9870879650116 after 120 iterations\n"," OCloss is 0.007177171607264861 and MNRloss is 0.69517648614795 and Cosloss is 0.24278666071643104 and time taken is 815.4570307731628 after 150 iterations\n"," OCloss is 0.005990727226712252 and MNRloss is 0.6948272829556333 and Cosloss is 0.2416050252376011 and time taken is 981.6548538208008 after 180 iterations\n"," OCloss is 0.005315858467736551 and MNRloss is 0.6941595783730818 and Cosloss is 0.24126529815425804 and time taken is 1145.7903594970703 after 210 iterations\n"," OCloss is 0.004658252108253937 and MNRloss is 0.6940226483147174 and Cosloss is 0.23980912675934213 and time taken is 1316.6331596374512 after 240 iterations\n"," OCloss is 0.006282864297344393 and MNRloss is 0.694676523279 and Cosloss is 0.24087561792745582 and time taken is 1449.5133693218231 after 270 iterations\n"," OCloss is 0.005660856546309298 and MNRloss is 0.6945248172924764 and Cosloss is 0.24003595516605433 and time taken is 1613.7180786132812 after 300 iterations\n"," OCloss is 0.005147801828027668 and MNRloss is 0.6943940127724247 and Cosloss is 0.23735846267883692 and time taken is 1780.4374475479126 after 330 iterations\n"," OCloss is 0.004720047227251123 and MNRloss is 0.6942952820138588 and Cosloss is 0.23680499385412876 and time taken is 1945.3471882343292 after 360 iterations\n"," OCloss is 0.004357905491276178 and MNRloss is 0.694200449587439 and Cosloss is 0.23591643628542838 and time taken is 2080.132345199585 after 390 iterations\n"," OCloss is 0.0040473878083908755 and MNRloss is 0.694121520762772 and Cosloss is 0.23760960746176027 and time taken is 2244.8973758220673 after 420 iterations\n"," OCloss is 0.0037781831991129176 and MNRloss is 0.6940569719031222 and Cosloss is 0.23807347862838774 and time taken is 2406.8160588741302 after 450 iterations\n"," OCloss is 0.0035425680649824333 and MNRloss is 0.6939958807336566 and Cosloss is 0.2358762921103259 and time taken is 2574.1566462516785 after 480 iterations\n"," OCloss is 0.003334614510870236 and MNRloss is 0.6939454500922485 and Cosloss is 0.2373662782676241 and time taken is 2716.8943684101105 after 510 iterations\n"," OCloss is 0.003149754315930771 and MNRloss is 0.6939025368135209 and Cosloss is 0.23713477275053696 and time taken is 2878.0078144073486 after 540 iterations\n"," OCloss is 0.0029843290604150406 and MNRloss is 0.6938582962532177 and Cosloss is 0.2382637903244347 and time taken is 3048.0408158302307 after 570 iterations\n"," OCloss is 0.0028354969696133317 and MNRloss is 0.69382464102223 and Cosloss is 0.2360157862138282 and time taken is 3213.063589811325 after 600 iterations\n"," OCloss is 0.0034492590485322196 and MNRloss is 0.6939739871138438 and Cosloss is 0.23310535278602276 and time taken is 3352.6512010097504 after 630 iterations\n"," OCloss is 0.0032928315686459415 and MNRloss is 0.693937117140881 and Cosloss is 0.23171755305453345 and time taken is 3516.061044216156 after 660 iterations\n"," OCloss is 0.0031500515855321727 and MNRloss is 0.6939020853829281 and Cosloss is 0.2325351891146943 and time taken is 3681.1098415851593 after 690 iterations\n"," OCloss is 0.0030229410433582765 and MNRloss is 0.6938841667816807 and Cosloss is 0.23429178859103322 and time taken is 3855.2416031360626 after 720 iterations\n"," OCloss is 0.0029689274261805103 and MNRloss is 0.6936648073748806 and Cosloss is 0.23265127607741543 and time taken is 3994.391263484955 after 750 iterations\n"," OCloss is 0.0028744348145753984 and MNRloss is 0.6934648406490321 and Cosloss is 0.2328428756922636 and time taken is 4158.1265070438385 after 780 iterations\n"," OCloss is 0.003224004902561828 and MNRloss is 0.6934433277379423 and Cosloss is 0.23220622399649624 and time taken is 4324.47776222229 after 810 iterations\n"," OCloss is 0.0031090022722301664 and MNRloss is 0.6934331435794354 and Cosloss is 0.2324032509116972 and time taken is 4488.814323663712 after 840 iterations\n"," OCloss is 0.003001920851865587 and MNRloss is 0.6934228349224708 and Cosloss is 0.23198866352105318 and time taken is 4628.497665882111 after 870 iterations\n"," OCloss is 0.002901970521013595 and MNRloss is 0.6934139081561208 and Cosloss is 0.2320163215962254 and time taken is 4789.679314613342 after 900 iterations\n"," OCloss is 0.002808464132644074 and MNRloss is 0.6934054098247073 and Cosloss is 0.23230909687195825 and time taken is 4957.394215345383 after 930 iterations\n"," OCloss is 0.0027207938042724325 and MNRloss is 0.6933959127712944 and Cosloss is 0.23132499181602487 and time taken is 5124.26652097702 after 960 iterations\n"," OCloss is 0.0026384353014579746 and MNRloss is 0.6933884088374772 and Cosloss is 0.23003491816250937 and time taken is 5266.316557168961 after 990 iterations\n"," OCloss is 0.002560915346336119 and MNRloss is 0.6933817179266083 and Cosloss is 0.23005113170375494 and time taken is 5423.573391914368 after 1020 iterations\n"," OCloss is 0.002487818346208917 and MNRloss is 0.6933747166457571 and Cosloss is 0.23055726496926326 and time taken is 5591.4935982227325 after 1050 iterations\n"," OCloss is 0.002418782876828165 and MNRloss is 0.6933686948285733 and Cosloss is 0.23156760904720874 and time taken is 5757.132492303848 after 1080 iterations\n"," OCloss is 0.002353471145797361 and MNRloss is 0.6933628684974382 and Cosloss is 0.23115364550826628 and time taken is 5903.2630207538605 after 1110 iterations\n"," OCloss is 0.0022915927087714246 and MNRloss is 0.6933558423408388 and Cosloss is 0.23024624701194288 and time taken is 6061.165817737579 after 1140 iterations\n"," OCloss is 0.0022328877159708133 and MNRloss is 0.6933506132190193 and Cosloss is 0.23094406206857487 and time taken is 6227.865157365799 after 1170 iterations\n"," OCloss is 0.0021771134011336797 and MNRloss is 0.6933452313289753 and Cosloss is 0.23139012612551327 and time taken is 6394.790818929672 after 1200 iterations\n"," OCloss is 0.002124059365355773 and MNRloss is 0.6933409283550458 and Cosloss is 0.23254914740501478 and time taken is 6539.749790668488 after 1230 iterations\n"," OCloss is 0.0020735333653032414 and MNRloss is 0.6933370143718705 and Cosloss is 0.2321487478247174 and time taken is 6697.918667078018 after 1260 iterations\n"," OCloss is 0.0020253527993300212 and MNRloss is 0.693333322506926 and Cosloss is 0.23217708675304788 and time taken is 6867.241504907608 after 1290 iterations\n"," OCloss is 0.001979361160178734 and MNRloss is 0.6933297548304896 and Cosloss is 0.23231330564292113 and time taken is 7036.90446472168 after 1320 iterations\n"," OCloss is 0.0019354103565408752 and MNRloss is 0.6933244552372297 and Cosloss is 0.23347958096397486 and time taken is 7194.643097162247 after 1350 iterations\n"," OCloss is 0.0018933703790936323 and MNRloss is 0.6933198976050591 and Cosloss is 0.2333386608727875 and time taken is 7371.847426652908 after 1380 iterations\n"," OCloss is 0.0018531192046587633 and MNRloss is 0.693317377846094 and Cosloss is 0.2330628962161628 and time taken is 7553.443429946899 after 1410 iterations\n"," OCloss is 0.0018145435806871128 and MNRloss is 0.6933136830968546 and Cosloss is 0.23385602319684193 and time taken is 7738.44438290596 after 1440 iterations\n"," OCloss is 0.0017946147089845873 and MNRloss is 0.6933039097782708 and Cosloss is 0.2341767796394393 and time taken is 7884.43760061264 after 1470 iterations\n"," OCloss is 0.0017587484437998112 and MNRloss is 0.6932992069900711 and Cosloss is 0.23343147293383443 and time taken is 8064.7694499492645 after 1500 iterations\n"," OCloss is 0.0017242880161062407 and MNRloss is 0.6932964541022876 and Cosloss is 0.23260988991349876 and time taken is 8242.689414978027 after 1530 iterations\n"," OCloss is 0.0016911550228497346 and MNRloss is 0.6932940209698478 and Cosloss is 0.23223881975107472 and time taken is 8420.65978050232 after 1560 iterations\n"," OCloss is 0.0016592727862331823 and MNRloss is 0.6932907004464279 and Cosloss is 0.23220535235082593 and time taken is 8566.922960281372 after 1590 iterations\n"," OCloss is 0.0016285673537931315 and MNRloss is 0.6932878743932984 and Cosloss is 0.23271266130511037 and time taken is 8747.879163980484 after 1620 iterations\n"," OCloss is 0.0015989766911434355 and MNRloss is 0.6932848384350014 and Cosloss is 0.23275078901133164 and time taken is 8927.944684028625 after 1650 iterations\n"," OCloss is 0.0015704452419607765 and MNRloss is 0.6932823755853166 and Cosloss is 0.232888449733586 and time taken is 9107.328607797623 after 1680 iterations\n"," OCloss is 0.001542911633278553 and MNRloss is 0.6932801419291003 and Cosloss is 0.23227953437382648 and time taken is 9252.518859863281 after 1710 iterations\n"," OCloss is 0.0015163296465462344 and MNRloss is 0.6932766230403521 and Cosloss is 0.2320825925780517 and time taken is 9433.235203027725 after 1740 iterations\n"," OCloss is 0.0014906579495885205 and MNRloss is 0.6932764254943723 and Cosloss is 0.23201789029094036 and time taken is 9615.030205249786 after 1770 iterations\n"," OCloss is 0.0014658346874049854 and MNRloss is 0.6932738628207412 and Cosloss is 0.2315435637148518 and time taken is 9793.221582174301 after 1800 iterations\n"," OCloss is 0.0014418220237231963 and MNRloss is 0.6932715720520978 and Cosloss is 0.23207300355640642 and time taken is 9938.583274364471 after 1830 iterations\n"," OCloss is 0.0014185819104525058 and MNRloss is 0.6932693042465591 and Cosloss is 0.23236161176853926 and time taken is 10111.504333019257 after 1860 iterations\n"," OCloss is 0.0013960795636567785 and MNRloss is 0.6932669357292744 and Cosloss is 0.23229147358204025 and time taken is 10291.87267422676 after 1890 iterations\n"," OCloss is 0.0013742822848473756 and MNRloss is 0.6932653886213208 and Cosloss is 0.23157342895186706 and time taken is 10465.286214590073 after 1920 iterations\n"," OCloss is 0.0013531522389141073 and MNRloss is 0.6932620475806681 and Cosloss is 0.23196936319980757 and time taken is 10614.687240123749 after 1950 iterations\n"," OCloss is 0.001332678638769878 and MNRloss is 0.6932622586940648 and Cosloss is 0.23166603706250552 and time taken is 10780.6418800354 after 1980 iterations\n"," OCloss is 0.001312803176499446 and MNRloss is 0.6932600011047826 and Cosloss is 0.23156185935273182 and time taken is 10955.567798137665 after 2010 iterations\n"," OCloss is 0.0012935132572959708 and MNRloss is 0.6932574070475371 and Cosloss is 0.23201120184759105 and time taken is 11131.26956319809 after 2040 iterations\n"," OCloss is 0.0012747791486570764 and MNRloss is 0.6932557939562114 and Cosloss is 0.2314357551580132 and time taken is 11285.089398622513 after 2070 iterations\n","image file is truncated (3 bytes not processed)\n","Something went wrong with the image of id 164569\n"," OCloss is 0.0012565880478070173 and MNRloss is 0.6932551809460251 and Cosloss is 0.23202390829876937 and time taken is 11448.397579431534 after 2100 iterations\n"," OCloss is 0.0012389039127707832 and MNRloss is 0.6932535029699521 and Cosloss is 0.23245723645282793 and time taken is 11624.209938526154 after 2130 iterations\n"," OCloss is 0.0012217072014496103 and MNRloss is 0.693250702658719 and Cosloss is 0.23194331421065612 and time taken is 11796.501986980438 after 2160 iterations\n"," OCloss is 0.001204990365073384 and MNRloss is 0.6932497939145059 and Cosloss is 0.23273226466167604 and time taken is 11952.334687232971 after 2190 iterations\n"," OCloss is 0.001188720517927345 and MNRloss is 0.6932472182200439 and Cosloss is 0.23254066532018994 and time taken is 12098.632841348648 after 2220 iterations\n"," OCloss is 0.001172886676013061 and MNRloss is 0.6932465134594823 and Cosloss is 0.23217943620626819 and time taken is 12261.506088972092 after 2250 iterations\n"," OCloss is 0.0011574689271354052 and MNRloss is 0.6932447740562335 and Cosloss is 0.2324831137561853 and time taken is 12428.060044288635 after 2280 iterations\n"," OCloss is 0.0011424574799461468 and MNRloss is 0.6932444033144047 and Cosloss is 0.23275831199324865 and time taken is 12577.877860069275 after 2310 iterations\n"," OCloss is 0.0011278460888901687 and MNRloss is 0.6932436222451612 and Cosloss is 0.23328643908747262 and time taken is 12729.87138915062 after 2340 iterations\n"," OCloss is 0.0011135818855672723 and MNRloss is 0.6932398310345167 and Cosloss is 0.23266787690714233 and time taken is 12890.03725862503 after 2370 iterations\n"," OCloss is 0.0010996955923721745 and MNRloss is 0.6932401236322014 and Cosloss is 0.23264224413411536 and time taken is 13053.631795883179 after 2400 iterations\n"," OCloss is 0.0010861685887867613 and MNRloss is 0.6932403319463569 and Cosloss is 0.2324961192671444 and time taken is 13204.457842826843 after 2430 iterations\n"," OCloss is 0.0010729629917103157 and MNRloss is 0.6932388570724295 and Cosloss is 0.23276643756639298 and time taken is 13357.712597846985 after 2460 iterations\n"," OCloss is 0.0010600614916937163 and MNRloss is 0.6932379734272078 and Cosloss is 0.23250822558481618 and time taken is 13515.297350883484 after 2490 iterations\n"," OCloss is 0.0010475089864415345 and MNRloss is 0.6932379509285772 and Cosloss is 0.23244784026525292 and time taken is 13682.829904317856 after 2520 iterations\n"," OCloss is 0.0010352171886717815 and MNRloss is 0.6932370786758462 and Cosloss is 0.23299054651999768 and time taken is 13831.87614107132 after 2550 iterations\n"," OCloss is 0.0010232350103684606 and MNRloss is 0.6932363857690884 and Cosloss is 0.2331703706503388 and time taken is 13981.129108905792 after 2580 iterations\n"," OCloss is 0.0010115139023489893 and MNRloss is 0.6932349051611033 and Cosloss is 0.2330315570011364 and time taken is 14143.356093883514 after 2610 iterations\n"," OCloss is 0.001134459830129227 and MNRloss is 0.6931945223196219 and Cosloss is 0.2328202530956097 and time taken is 14310.284340143204 after 2640 iterations\n"," OCloss is 0.0011217210543447845 and MNRloss is 0.6931941089046354 and Cosloss is 0.23359895133539246 and time taken is 14463.14114522934 after 2670 iterations\n"," OCloss is 0.0011092724734592671 and MNRloss is 0.6931938891364927 and Cosloss is 0.23349261276702535 and time taken is 14612.496536016464 after 2700 iterations\n"," OCloss is 0.0010970938968099682 and MNRloss is 0.6931927828551299 and Cosloss is 0.2330937282162156 and time taken is 14777.177173137665 after 2730 iterations\n"," OCloss is 0.001085180633435644 and MNRloss is 0.6931918830553806 and Cosloss is 0.23310533490562216 and time taken is 14942.558978319168 after 2760 iterations\n"," OCloss is 0.001073524057461306 and MNRloss is 0.6931923448676407 and Cosloss is 0.23292186159262815 and time taken is 15093.412187337875 after 2790 iterations\n"," OCloss is 0.0010621141584708728 and MNRloss is 0.6931916801948913 and Cosloss is 0.23259919414343627 and time taken is 15247.238957643509 after 2820 iterations\n"," OCloss is 0.0010509487883167896 and MNRloss is 0.6931916266021206 and Cosloss is 0.23245457049442234 and time taken is 15403.669132471085 after 2850 iterations\n"," OCloss is 0.0010400135540498815 and MNRloss is 0.6931907165302911 and Cosloss is 0.23249328411864723 and time taken is 15568.178313732147 after 2880 iterations\n"," OCloss is 0.0010293079217211073 and MNRloss is 0.693190688367809 and Cosloss is 0.23269467654198725 and time taken is 15726.17910027504 after 2910 iterations\n"," OCloss is 0.0010188224570974282 and MNRloss is 0.6931911695777702 and Cosloss is 0.23230485289539055 and time taken is 15878.129979133606 after 2940 iterations\n"," OCloss is 0.0010085621362867143 and MNRloss is 0.6931920384004516 and Cosloss is 0.2325989916389015 and time taken is 16034.31809091568 after 2970 iterations\n"," OCloss is 0.0009984985825526923 and MNRloss is 0.693192524200517 and Cosloss is 0.232719473928084 and time taken is 16199.104376792908 after 3000 iterations\n"," OCloss is 0.0009886211183237725 and MNRloss is 0.6931919460247862 and Cosloss is 0.2329870673152764 and time taken is 16356.290330171585 after 3030 iterations\n"," OCloss is 0.0009789390473064125 and MNRloss is 0.6931908005633723 and Cosloss is 0.23252845764384086 and time taken is 16505.80623936653 after 3060 iterations\n"," OCloss is 0.000969446340297425 and MNRloss is 0.6931899906708869 and Cosloss is 0.23256742594379778 and time taken is 16661.589747428894 after 3090 iterations\n"," OCloss is 0.0009601543278293156 and MNRloss is 0.6931856059180128 and Cosloss is 0.23232669684079854 and time taken is 16823.44684767723 after 3120 iterations\n"," OCloss is 0.0009510532287901291 and MNRloss is 0.6931851574709513 and Cosloss is 0.23248701778357841 and time taken is 16981.478294849396 after 3150 iterations\n"," OCloss is 0.0009421244340193163 and MNRloss is 0.6931842298711557 and Cosloss is 0.23278865142040603 and time taken is 17127.930027723312 after 3180 iterations\n"," OCloss is 0.0009334370320318526 and MNRloss is 0.6931825683370108 and Cosloss is 0.23291055977400202 and time taken is 17291.363173246384 after 3210 iterations\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":[" OCloss is 0.0009252511661413488 and MNRloss is 0.6931818946759225 and Cosloss is 0.23302959788341243 and time taken is 17452.928606987 after 3240 iterations\n"," OCloss is 0.0013239819040468915 and MNRloss is 0.6932093867720613 and Cosloss is 0.2333045216366644 and time taken is 17609.810970067978 after 3270 iterations\n"," OCloss is 0.0013119691908857769 and MNRloss is 0.6932097517949312 and Cosloss is 0.2332696698727896 and time taken is 17752.01113176346 after 3300 iterations\n"," OCloss is 0.0013001601946285273 and MNRloss is 0.6932071743516799 and Cosloss is 0.23293365239403657 and time taken is 17910.309165477753 after 3330 iterations\n"," OCloss is 0.001288576554039919 and MNRloss is 0.6932069812101893 and Cosloss is 0.23320273558779048 and time taken is 18073.736450195312 after 3360 iterations\n"," OCloss is 0.0012771946008460495 and MNRloss is 0.6932072223234725 and Cosloss is 0.2331420189191004 and time taken is 18238.942098379135 after 3390 iterations\n"," OCloss is 0.001266010320667285 and MNRloss is 0.6932059616869704 and Cosloss is 0.23260146807100612 and time taken is 18373.799748659134 after 3420 iterations\n"," OCloss is 0.001255027053338542 and MNRloss is 0.6932043686392548 and Cosloss is 0.23268148510616193 and time taken is 18535.840478658676 after 3450 iterations\n"," OCloss is 0.0012442391151267784 and MNRloss is 0.6932023462636894 and Cosloss is 0.23266414241398145 and time taken is 18701.680916786194 after 3480 iterations\n"," OCloss is 0.0012336304166930111 and MNRloss is 0.6932016300937791 and Cosloss is 0.23255930159042548 and time taken is 18864.458350658417 after 3510 iterations\n"," OCloss is 0.00122322661952838 and MNRloss is 0.6932018642471323 and Cosloss is 0.2324688930797715 and time taken is 18998.673271417618 after 3540 iterations\n"," OCloss is 0.0012129612572843158 and MNRloss is 0.6931982373396778 and Cosloss is 0.2327814317209001 and time taken is 19163.921727657318 after 3570 iterations\n"," OCloss is 0.0012028888117542034 and MNRloss is 0.693197275012508 and Cosloss is 0.23245212924944728 and time taken is 19327.212697267532 after 3600 iterations\n"," OCloss is 0.0011930174521928734 and MNRloss is 0.6931977303879743 and Cosloss is 0.23253318144270652 and time taken is 19489.543601751328 after 3630 iterations\n"," OCloss is 0.0011833229598112156 and MNRloss is 0.6931973766577241 and Cosloss is 0.2324297259246528 and time taken is 19623.35749387741 after 3660 iterations\n"," OCloss is 0.0011737282731051385 and MNRloss is 0.6931964393005692 and Cosloss is 0.23216878839666782 and time taken is 19786.53330206871 after 3690 iterations\n"," OCloss is 0.0011643141784036034 and MNRloss is 0.693194148826266 and Cosloss is 0.23219363421433972 and time taken is 19952.5053293705 after 3720 iterations\n"," OCloss is 0.0011550627533856985 and MNRloss is 0.6931904184916788 and Cosloss is 0.23230092220506932 and time taken is 20115.270409584045 after 3750 iterations\n"," OCloss is 0.001146200919438683 and MNRloss is 0.6931945960599258 and Cosloss is 0.23227300766645617 and time taken is 20251.837268590927 after 3780 iterations\n"," OCloss is 0.0011372416182577787 and MNRloss is 0.6931918796608374 and Cosloss is 0.23201395718444837 and time taken is 20413.274176120758 after 3810 iterations\n"," OCloss is 0.001128478817287434 and MNRloss is 0.6931906477047484 and Cosloss is 0.23193273051653762 and time taken is 20578.2835354805 after 3840 iterations\n"," OCloss is 0.00111995429865651 and MNRloss is 0.693183437332384 and Cosloss is 0.23170377572387788 and time taken is 20741.367146253586 after 3870 iterations\n"," OCloss is 0.0011118946069639008 and MNRloss is 0.6931839127841285 and Cosloss is 0.2321501274384755 and time taken is 20874.10360312462 after 3900 iterations\n"," OCloss is 0.0011041551361844087 and MNRloss is 0.6931751274753242 and Cosloss is 0.23227498267263863 and time taken is 21038.298536539078 after 3930 iterations\n"," OCloss is 0.0011094159319157558 and MNRloss is 0.6931699784047012 and Cosloss is 0.2322438991412509 and time taken is 21205.78205728531 after 3960 iterations\n"," OCloss is 0.0011789505652851906 and MNRloss is 0.6931994341872025 and Cosloss is 0.23189437603827662 and time taken is 21372.347249746323 after 3990 iterations\n"," OCloss is 0.001170462819209906 and MNRloss is 0.6931984392276186 and Cosloss is 0.2317227405731957 and time taken is 21510.71585202217 after 4020 iterations\n"," OCloss is 0.0011618685080503107 and MNRloss is 0.6931937679453445 and Cosloss is 0.23179309216832134 and time taken is 21684.96587586403 after 4050 iterations\n"," OCloss is 0.0011540971895756323 and MNRloss is 0.6932006041169956 and Cosloss is 0.2320001900165952 and time taken is 21853.712004184723 after 4080 iterations\n"," OCloss is 0.0011463638967434565 and MNRloss is 0.6931923631043134 and Cosloss is 0.2322279099824473 and time taken is 22023.327208042145 after 4110 iterations\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TBTAVM7Qnmkk","executionInfo":{"status":"ok","timestamp":1613458585118,"user_tz":-330,"elapsed":7361,"user":{"displayName":"MOHIT MEHTA","photoUrl":"","userId":"00949415454628222481"}},"outputId":"5bcfc6bb-43e2-4453-c2fc-e46d9e4fd962"},"source":["model.load_state_dict(torch.load(folder+'/model_state_dict/distilbert.bin'))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"ZuGYeCAq97yQ"},"source":["# Evaluator"]},{"cell_type":"code","metadata":{"id":"qj6NLqZmaNDB"},"source":["model = BridgeModel().to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kiIvwpyFaRQV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613459108750,"user_tz":-330,"elapsed":3535,"user":{"displayName":"MOHIT MEHTA","photoUrl":"","userId":"00949415454628222481"}},"outputId":"7be310ae-72ff-49d7-846b-802189e2942a"},"source":["model.load_state_dict(torch.load('/gdrive/MyDrive/MultiModal/model_state_dict/distilbert.bin'))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"kYlESuc6HmGF"},"source":["## Binary Classification Evaluator"]},{"cell_type":"markdown","metadata":{"id":"qOfg82LFffGh"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"NJ-NKaASKXoM"},"source":["# from . import SentenceEvaluator\n","import logging\n","import os\n","import csv\n","from sklearn.metrics.pairwise import paired_cosine_distances, paired_euclidean_distances, paired_manhattan_distances\n","from sklearn.metrics import average_precision_score\n","import numpy as np\n","from typing import List\n","# from ..readers import InputExample\n","\n","\n","logger = logging.getLogger(__name__)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eDghCKtbfg_7"},"source":["### Functiion"]},{"cell_type":"code","metadata":{"id":"LWrcz7PMHlaJ"},"source":["class BinaryClassificationEvaluator():\n","    \"\"\"\n","    Evaluate a model based on the similarity of the embeddings by calculating the accuracy of identifying similar and\n","    dissimilar sentences.\n","    The metrics are the cosine similarity as well as euclidean and Manhattan distance\n","    The returned score is the accuracy with a specified metric.\n","    The results are written in a CSV. If a CSV already exists, then values are appended.\n","    The labels need to be 0 for dissimilar pairs and 1 for similar pairs.\n","    :param sentences1: The first column of sentences\n","    :param sentences2: The second column of sentences\n","    :param labels: labels[i] is the label for the pair (sentences1[i], sentences2[i]). Must be 0 or 1\n","    :param name: Name for the output\n","    :param batch_size: Batch size used to compute embeddings\n","    :param show_progress_bar: If true, prints a progress bar\n","    :param write_csv: Write results to a CSV file\n","    \"\"\"\n","\n","    def __init__(self,\n","                 dataset,\n","                 name: str = '',\n","                 batch_size: int = 32,\n","                 show_progress_bar: bool = False,\n","                 write_csv: bool = True\n","                 ):\n","        \n","        self.dataset = dataset\n","        self.labels = list()\n","        self.write_csv = write_csv\n","        self.name = name\n","        self.batch_size = batch_size\n","        self.dataloader = DataLoader(\n","            self.dataset,\n","            batch_size=self.batch_size,\n","            pin_memory=True,\n","            num_workers = 8,\n","            shuffle = True\n","        )\n","\n","        if show_progress_bar is None:\n","            show_progress_bar = (logger.getEffectiveLevel() == logging.INFO or logger.getEffectiveLevel() == logging.DEBUG)\n","        self.show_progress_bar = show_progress_bar\n","\n","        self.csv_file = \"binary_classification_evaluation\" + (\"_\"+name if name else '') + \"_results.csv\"\n","        self.csv_headers = [\"epoch\", \"steps\",\n","                            \"cosine_acc\", \"cosine_acc_threshold\", \"cosine_f1\", \"cosine_precision\", \"cosine_recall\", \"cosine_f1_threshold\", \"cosine_average_precision\",\n","                            \"manhatten_acc\", \"manhatten_acc_threshold\", \"manhatten_f1\", \"manhatten_precision\", \"manhatten_recall\", \"manhatten_f1_threshold\", \"manhatten_average_precision\",\n","                            \"eucledian_acc\", \"eucledian_acc_threshold\", \"eucledian_f1\", \"eucledian_precision\", \"eucledian_recall\", \"eucledian_f1_threshold\", \"eucledian_average_precision\"]\n","\n","\n","    # @classmethod\n","    # def from_input_examples(cls, examples: List[InputExample], **kwargs):\n","    #     sentences1 = []\n","    #     sentences2 = []\n","    #     scores = []\n","\n","    #     for example in examples:\n","    #         sentences1.append(example.texts[0])\n","    #         sentences2.append(example.texts[1])\n","    #         scores.append(example.label)\n","    #     return cls(sentences1, sentences2, scores, **kwargs)\n","\n","    def __call__(self, model, output_path: str = None, epoch: int = -1, steps: int = -1) -> float:\n","\n","        if epoch != -1:\n","            if steps == -1:\n","                out_txt = f\" after epoch {epoch}:\"\n","            else:\n","                out_txt = f\" in epoch {epoch} after {steps} steps:\"\n","        else:\n","            out_txt = \":\"\n","\n","        logger.info(\"Binary Accuracy Evaluation of the model on \" + self.name + \" dataset\" + out_txt)\n","        \n","        embeddings1 = list()\n","        embeddings2 = list()\n","\n","        with torch.no_grad():\n","            model.eval()\n","            for i, batch in enumerate(self.dataloader):\n","                images = batch[\"image\"]\n","                label = batch[\"label\"]\n","                label = label.float()\n","                token = batch[\"token\"]\n","                \n","                # print(images,label,token)\n","\n","                images[0],images[1] = images[0].to(device),images[1].to(device)\n","                token[0],token[1] = token[0].to(device), token[1].to(device)\n","                label = label.to(device)\n","                \n","                # compute the model output\n","                yhat1 = model(images[0], token[0])\n","                yhat2 = model(images[1],token[1])\n","\n","                for j in yhat1:\n","                    embeddings1.append(j.cpu().detach().numpy())\n","                for j in yhat2:\n","                    embeddings2.append(j.cpu().detach().numpy())\n","                for j in label:\n","                    self.labels.append(float(j))\n","                \n","                if(i%30==0 and i!=0):\n","                    print(f'Completed {i} iterations')\n","\n","        cosine_scores = 1-paired_cosine_distances(embeddings1[:400], embeddings2[:400])\n","        manhattan_distances = paired_manhattan_distances(embeddings1[:400], embeddings2[:400])\n","        euclidean_distances = paired_euclidean_distances(embeddings1[:400], embeddings2[:400])\n","\n","\n","        labels = np.asarray(self.labels[:400])\n","\n","        file_output_data = [epoch, steps]\n","\n","        main_score = None\n","        for name, scores, reverse in [['Cosine-Similarity', cosine_scores, True], ['Manhatten-Distance', manhattan_distances, False], ['Euclidean-Distance', euclidean_distances, False]]:\n","            acc, acc_threshold = self.find_best_acc_and_threshold(scores, labels, reverse)\n","            f1, precision, recall, f1_threshold = self.find_best_f1_and_threshold(scores, labels, reverse)\n","            ap = average_precision_score(labels, scores * (1 if reverse else -1))\n","\n","            logger.info(\"Accuracy with {}:           {:.2f}\\t(Threshold: {:.4f})\".format(name, acc * 100, acc_threshold))\n","            logger.info(\"F1 with {}:                 {:.2f}\\t(Threshold: {:.4f})\".format(name, f1 * 100, f1_threshold))\n","            logger.info(\"Precision with {}:          {:.2f}\".format(name, precision * 100))\n","            logger.info(\"Recall with {}:             {:.2f}\".format(name, recall * 100))\n","            logger.info(\"Average Precision with {}:  {:.2f}\\n\".format(name, ap * 100))\n","\n","            file_output_data.extend([acc, acc_threshold, f1, precision, recall, f1_threshold, ap])\n","\n","            if main_score is None: #Use AveragePrecision with Cosine-Similarity as main score\n","                main_score = ap\n","\n","        if output_path is not None and self.write_csv:\n","            csv_path = os.path.join(output_path, self.csv_file)\n","            if not os.path.isfile(csv_path):\n","                with open(csv_path, mode=\"w\", encoding=\"utf-8\") as f:\n","                    writer = csv.writer(f)\n","                    writer.writerow(self.csv_headers)\n","                    writer.writerow(file_output_data)\n","            else:\n","                with open(csv_path, mode=\"a\", encoding=\"utf-8\") as f:\n","                    writer = csv.writer(f)\n","                    writer.writerow(file_output_data)\n","\n","        return main_score\n","\n","    @staticmethod\n","    def find_best_acc_and_threshold(scores, labels, high_score_more_similar: bool):\n","        # assert len(scores) == len(labels)\n","        rows = list(zip(scores, labels))\n","\n","        rows = sorted(rows, key=lambda x: x[0], reverse=high_score_more_similar)\n","\n","        max_acc = 0\n","        best_threshold = -1\n","\n","        positive_so_far = 0\n","        remaining_negatives = sum(labels == 0)\n","\n","        for i in range(len(rows)-1):\n","            score, label = rows[i]\n","            if label == 1:\n","                positive_so_far += 1\n","            else:\n","                remaining_negatives -= 1\n","\n","            acc = (positive_so_far + remaining_negatives) / len(labels)\n","            if acc > max_acc:\n","                max_acc = acc\n","                best_threshold = (rows[i][0] + rows[i+1][0]) / 2\n","\n","        return max_acc, best_threshold\n","\n","    @staticmethod\n","    def find_best_f1_and_threshold(scores, labels, high_score_more_similar: bool):\n","        # assert len(scores) == len(labels)\n","\n","        scores = np.asarray(scores)\n","        labels = np.asarray(labels)\n","\n","        rows = list(zip(scores, labels))\n","\n","        rows = sorted(rows, key=lambda x: x[0], reverse=high_score_more_similar)\n","\n","        best_f1 = best_precision = best_recall = 0\n","        threshold = 0\n","        nextract = 0\n","        ncorrect = 0\n","        total_num_duplicates = sum(labels)\n","\n","        for i in range(len(rows)-1):\n","            score, label = rows[i]\n","            nextract += 1\n","\n","            if label == 1:\n","                ncorrect += 1\n","\n","            if ncorrect > 0:\n","                precision = ncorrect / nextract\n","                recall = ncorrect / total_num_duplicates\n","                f1 = 2 * precision * recall / (precision + recall)\n","                if f1 > best_f1:\n","                    best_f1 = f1\n","                    best_precision = precision\n","                    best_recall = recall\n","                    threshold = (rows[i][0] + rows[i + 1][0]) / 2\n","\n","        return best_f1, best_precision, best_recall, threshold"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"icQIl4tMfbo9"},"source":["### Evaluation"]},{"cell_type":"code","metadata":{"id":"iSnnK9vk-U_J"},"source":["dev_BCEvaluator = BinaryClassificationEvaluator(dev_dataset,batch_size=BATCH_SIZE,show_progress_bar=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZG6rpop6avKv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613459359973,"user_tz":-330,"elapsed":254744,"user":{"displayName":"MOHIT MEHTA","photoUrl":"","userId":"00949415454628222481"}},"outputId":"a89e0556-5b40-40b3-e433-115034c75cb7"},"source":["dev_BCEvaluator(model,output_path=folder+'/dev')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Completed 30 iterations\n","Completed 60 iterations\n","Completed 90 iterations\n","Completed 120 iterations\n","Completed 150 iterations\n","Completed 180 iterations\n","Completed 210 iterations\n","Completed 240 iterations\n","Completed 270 iterations\n","Completed 300 iterations\n","Completed 330 iterations\n","Completed 360 iterations\n","Completed 390 iterations\n","Completed 420 iterations\n","Completed 450 iterations\n","Completed 480 iterations\n","Completed 510 iterations\n","Completed 540 iterations\n","Completed 570 iterations\n","Completed 600 iterations\n","Completed 630 iterations\n","Completed 660 iterations\n","Completed 690 iterations\n","Completed 720 iterations\n","Completed 750 iterations\n","Completed 780 iterations\n","Completed 810 iterations\n","Completed 840 iterations\n","Completed 870 iterations\n","Completed 900 iterations\n","Completed 930 iterations\n","Completed 960 iterations\n","Completed 990 iterations\n","Completed 1020 iterations\n","Completed 1050 iterations\n","Completed 1080 iterations\n","Completed 1110 iterations\n","Completed 1140 iterations\n","Completed 1170 iterations\n","Completed 1200 iterations\n","Completed 1230 iterations\n","Completed 1260 iterations\n","Completed 1290 iterations\n","Completed 1320 iterations\n","Completed 1350 iterations\n","Completed 1380 iterations\n","Completed 1410 iterations\n","Completed 1440 iterations\n","Completed 1470 iterations\n","Completed 1500 iterations\n","Completed 1530 iterations\n","Completed 1560 iterations\n","Completed 1590 iterations\n","Completed 1620 iterations\n","Completed 1650 iterations\n","Completed 1680 iterations\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"MQ3f5gO7Hhu0"},"source":["## Information retreival evaluator"]},{"cell_type":"code","metadata":{"id":"f4yW9Gn2DL9i"},"source":["import torch\n","import logging\n","from tqdm import tqdm, trange\n","import os\n","import numpy as np\n","from typing import List, Tuple, Dict, Set"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"izMNQie5XZmi"},"source":["class infodataset(Dataset):\n","    def __init__(self,qr,qr_idx,img_dir,transform = None):\n","        self.qr = qr\n","        self.qr_idx = qr_idx\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def image_adder(self,id1):\n","        img_id1 = list()\n","        if((self.qr.at[id1,'Attachments'])!=None):\n","            for i in self.qr.at[id1,'Attachments']:\n","                try:\n","                    img_path = os.path.join(self.img_dir,i)\n","                    img = Image.open(img_path).convert('RGB')\n","                    if(self.transform):\n","                        img = self.transform(img)\n","                        img.reshape(3,224,224)\n","                    img_id1.append(img)\n","                except Exception as e: \n","                    print(e)\n","        else:\n","            img_id1.append(torch.zeros(3,224,224))\n","\n","        # Work on this, for few examples, it is still saying list index out of range\n","        if(len(img_id1)==0):\n","            # print('No attachments found for id {}'.format(id1))\n","            print(f'Something went wrong with the image of id {id1}')\n","            img_id1.append(torch.zeros(3,224,224))\n","\n","        return img_id1\n","    \n","    def __getitem__(self,idx):\n","        id1 = self.qr_idx[idx]\n","        img_id1 = self.image_adder(id1)\n","\n","        # print(len(img_id1))\n","\n","        # print('Printing id1 {} and len {} and id2 {} and len {} '.format(\n","        #     id1,len(img_id1),\n","        #     id2, len(img_id2)\n","        # ))\n","\n","        # print('Printing id1 shape {} and id2  shape {}'.format(\n","        #     img_id1[0].shape,\n","        #     img_id2[0].shape\n","        # ))        \n","\n","        sample = {\n","            'image': img_id1[0]    #Currently taking only one input image\n","        }\n","\n","        t1 = '[CLS]' + self.qr.loc[id1,'Title'] + ' ' + ' '.join(self.qr.loc[id1,'Tags']) + ' ' + self.qr.loc[id1,'Text'] + '[SEP]'\n","        tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","        t1_token = tokenizer.tokenize(t1)\n","        indexed_t1 = tokenizer.convert_tokens_to_ids(t1_token)\n","        \n","        while(len(indexed_t1)<512):\n","            indexed_t1.append(0)\n","        \n","        ten_t1 = torch.as_tensor(indexed_t1)[:512]\n","        \n","        try:\n","            sample[\"token\"] = ten_t1 # torch.Size([batch_size, 512])\n","        except Exception as e:\n","            print(e)\n","        \n","        return sample\n","\n","    def __len__(self):\n","        return len(self.qr_idx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qhOlgHW9El3T"},"source":["class InformationRetreivalEvaluator():\n","    def __init__(self,\n","                 qr,\n","                 queries: Dict[str, str],  #qid => query\n","                 corpus: Dict[str, str],  #cid => doc\n","                 relevant_docs: Dict[str, Set[str]],  #qid => Set[cid]\n","                 corpus_chunk_size: int = 50000,\n","                 mrr_at_k: List[int] = [10],\n","                 ndcg_at_k: List[int] = [10],\n","                 accuracy_at_k: List[int] = [1, 3, 5, 10],\n","                 precision_recall_at_k: List[int] = [1, 3, 5, 10],\n","                 map_at_k: List[int] = [100],\n","                 show_progress_bar: bool = False,\n","                 batch_size: int = 32,\n","                 name: str = '',\n","                 write_csv: bool = True\n","                 ):\n","        \n","        self.qr = qr\n","        self.queries_ids = []\n","        for qid in queries:\n","            if qid in relevant_docs and len(relevant_docs[qid]) > 0:\n","                self.queries_ids.append(qid)\n","\n","        self.queries = [queries[qid] for qid in self.queries_ids]\n","\n","        self.corpus_ids = list(corpus.keys())\n","        self.corpus = [corpus[cid] for cid in self.corpus_ids]\n","\n","        self.relevant_docs = relevant_docs\n","        self.corpus_chunk_size = corpus_chunk_size\n","        self.mrr_at_k = mrr_at_k\n","        self.ndcg_at_k = ndcg_at_k\n","        self.accuracy_at_k = accuracy_at_k\n","        self.precision_recall_at_k = precision_recall_at_k\n","        self.map_at_k = map_at_k\n","\n","        self.show_progress_bar = show_progress_bar\n","        self.batch_size = batch_size\n","        self.name = name\n","        self.write_csv = write_csv\n","\n","        if name:\n","            name = \"_\" + name\n","\n","        self.csv_file: str = \"Information-Retrieval_evaluation\" + name + \"_results.csv\"\n","        self.csv_headers = [\"epoch\", \"steps\"]\n","\n","\n","        for k in accuracy_at_k:\n","            self.csv_headers.append(\"Accuracy@{}\".format(k))\n","\n","        for k in precision_recall_at_k:\n","            self.csv_headers.append(\"Precision@{}\".format(k))\n","            self.csv_headers.append(\"Recall@{}\".format(k))\n","\n","        for k in mrr_at_k:\n","            self.csv_headers.append(\"MRR@{}\".format(k))\n","\n","        for k in ndcg_at_k:\n","            self.csv_headers.append(\"NDCG@{}\".format(k))\n","\n","        for k in map_at_k:\n","            self.csv_headers.append(\"MAP@{}\".format(k))\n","    \n","    def __call__(self,model : BridgeModel,output_path: str = None,epoch: int = -1, steps: int = -1) ->float:\n","        if epoch != -1:\n","            out_txt = \" after epoch {}:\".format(epoch) if steps == -1 else \" in epoch {} after {} steps:\".format(epoch, steps)\n","        else:\n","            out_txt = \":\"\n","\n","        logger.info(\"Information Retrieval Evaluation on \" + self.name + \" dataset\" + out_txt)\n","\n","        max_k = max(max(self.mrr_at_k), max(self.ndcg_at_k), max(self.accuracy_at_k), max(self.precision_recall_at_k), max(self.map_at_k))\n","\n","        query_embeddings = self.get_embeddings(model,self.qr,self.queries_ids)\n","\n","        queries_result_list = [[] for _ in range(len(query_embeddings))]\n","\n","        itr = range(0, len(self.corpus), self.corpus_chunk_size)\n","\n","        if self.show_progress_bar:\n","            itr = tqdm(itr, desc='Corpus Chunks')\n","\n","        #Iterate over chunks of the corpus\n","        for corpus_start_idx in itr:\n","            corpus_end_idx = min(corpus_start_idx + self.corpus_chunk_size, len(self.corpus))\n","\n","            #Encode chunk of corpus\n","            sub_corpus_embeddings = self.get_embeddings(model,self.qr,self.corpus_ids[corpus_start_idx:corpus_end_idx])\n","\n","            #Compute cosine similarites\n","            cos_scores = pytorch_cos_sim(query_embeddings, sub_corpus_embeddings)\n","            del sub_corpus_embeddings\n","\n","            #Get top-k values\n","            cos_scores_top_k_values, cos_scores_top_k_idx = torch.topk(cos_scores, min(max_k, len(cos_scores[0])), dim=1, largest=True, sorted=False)\n","            cos_scores_top_k_values = cos_scores_top_k_values.cpu().tolist()\n","            cos_scores_top_k_idx = cos_scores_top_k_idx.cpu().tolist()\n","            del cos_scores\n","\n","            for query_itr in range(len(query_embeddings)):\n","                for sub_corpus_id, score in zip(cos_scores_top_k_idx[query_itr], cos_scores_top_k_values[query_itr]):\n","                    corpus_id = self.corpus_ids[corpus_start_idx+sub_corpus_id]\n","                    queries_result_list[query_itr].append({'corpus_id': corpus_id, 'score': score})\n","\n","\n","        #Compute scores\n","        scores = self.compute_metrics(queries_result_list)\n","\n","        #Output\n","        self.output_scores(scores)\n","\n","\n","        # logger.info(\"Queries: {}\".format(len(self.queries)))\n","        # logger.info(\"Corpus: {}\\n\".format(len(self.corpus)))\n","\n","        if output_path is not None and self.write_csv:\n","            csv_path = os.path.join(output_path, self.csv_file)\n","            if not os.path.isfile(csv_path):\n","                fOut = open(csv_path, mode=\"w\", encoding=\"utf-8\")\n","                fOut.write(\",\".join(self.csv_headers))\n","                fOut.write(\"\\n\")\n","\n","            else:\n","                fOut = open(csv_path, mode=\"a\", encoding=\"utf-8\")\n","\n","            output_data = [epoch, steps]\n","            for k in self.accuracy_at_k:\n","                output_data.append(scores['accuracy@k'][k])\n","\n","            for k in self.precision_recall_at_k:\n","                output_data.append(scores['precision@k'][k])\n","                output_data.append(scores['recall@k'][k])\n","\n","            for k in self.mrr_at_k:\n","                output_data.append(scores['mrr@k'][k])\n","\n","            for k in self.ndcg_at_k:\n","                output_data.append(scores['ndcg@k'][k])\n","\n","            for k in self.map_at_k:\n","                output_data.append(scores['map@k'][k])\n","\n","            fOut.write(\",\".join(map(str,output_data)))\n","            fOut.write(\"\\n\")\n","            fOut.close()\n","\n","        return scores['map@k'][max(self.map_at_k)]\n","\n","\n","    def compute_metrics(self, queries_result_list: List[object]):\n","        # Init score computation values\n","        num_hits_at_k = {k: 0 for k in self.accuracy_at_k}\n","        precisions_at_k = {k: [] for k in self.precision_recall_at_k}\n","        recall_at_k = {k: [] for k in self.precision_recall_at_k}\n","        MRR = {k: 0 for k in self.mrr_at_k}\n","        ndcg = {k: [] for k in self.ndcg_at_k}\n","        AveP_at_k = {k: [] for k in self.map_at_k}\n","\n","        # Compute scores on results\n","        for query_itr in range(len(queries_result_list)):\n","            query_id = self.queries_ids[query_itr]\n","\n","            # Sort scores\n","            top_hits = sorted(queries_result_list[query_itr], key=lambda x: x['score'], reverse=True)\n","            query_relevant_docs = self.relevant_docs[query_id]\n","\n","            # Accuracy@k - We count the result correct, if at least one relevant doc is accross the top-k documents\n","            for k_val in self.accuracy_at_k:\n","                for hit in top_hits[0:k_val]:\n","                    if hit['corpus_id'] in query_relevant_docs:\n","                        num_hits_at_k[k_val] += 1\n","                        break\n","\n","            # Precision and Recall@k\n","            for k_val in self.precision_recall_at_k:\n","                num_correct = 0\n","                for hit in top_hits[0:k_val]:\n","                    if hit['corpus_id'] in query_relevant_docs:\n","                        num_correct += 1\n","\n","                precisions_at_k[k_val].append(num_correct / k_val)\n","                recall_at_k[k_val].append(num_correct / len(query_relevant_docs))\n","\n","            # MRR@k\n","            for k_val in self.mrr_at_k:\n","                for rank, hit in enumerate(top_hits[0:k_val]):\n","                    if hit['corpus_id'] in query_relevant_docs:\n","                        MRR[k_val] += 1.0 / (rank + 1)\n","                        break\n","\n","            # NDCG@k\n","            for k_val in self.ndcg_at_k:\n","                predicted_relevance = [1 if top_hit['corpus_id'] in query_relevant_docs else 0 for top_hit in top_hits[0:k_val]]\n","                true_relevances = [1] * len(query_relevant_docs)\n","\n","                ndcg_value = self.compute_dcg_at_k(predicted_relevance, k_val) / self.compute_dcg_at_k(true_relevances, k_val)\n","                ndcg[k_val].append(ndcg_value)\n","\n","            # MAP@k\n","            for k_val in self.map_at_k:\n","                num_correct = 0\n","                sum_precisions = 0\n","\n","                for rank, hit in enumerate(top_hits[0:k_val]):\n","                    if hit['corpus_id'] in query_relevant_docs:\n","                        num_correct += 1\n","                        sum_precisions += num_correct / (rank + 1)\n","\n","                avg_precision = sum_precisions / min(k_val, len(query_relevant_docs))\n","                AveP_at_k[k_val].append(avg_precision)\n","\n","        # Compute averages\n","        for k in num_hits_at_k:\n","            num_hits_at_k[k] /= len(self.queries_ids)\n","\n","        for k in precisions_at_k:\n","            precisions_at_k[k] = np.mean(precisions_at_k[k])\n","\n","        for k in recall_at_k:\n","            recall_at_k[k] = np.mean(recall_at_k[k])\n","\n","        for k in ndcg:\n","            ndcg[k] = np.mean(ndcg[k])\n","\n","        for k in MRR:\n","            MRR[k] /= len(self.queries_ids)\n","\n","        for k in AveP_at_k:\n","            AveP_at_k[k] = np.mean(AveP_at_k[k])\n","\n","\n","        return {'accuracy@k': num_hits_at_k, 'precision@k': precisions_at_k, 'recall@k': recall_at_k, 'ndcg@k': ndcg, 'mrr@k': MRR, 'map@k': AveP_at_k}\n","\n","\n","    def output_scores(self, scores):\n","        for k in scores['accuracy@k']:\n","            logger.info(\"Accuracy@{}: {:.2f}%\".format(k, scores['accuracy@k'][k]*100))\n","\n","        for k in scores['precision@k']:\n","            logger.info(\"Precision@{}: {:.2f}%\".format(k, scores['precision@k'][k]*100))\n","\n","        for k in scores['recall@k']:\n","            logger.info(\"Recall@{}: {:.2f}%\".format(k, scores['recall@k'][k]*100))\n","\n","        for k in scores['mrr@k']:\n","            logger.info(\"MRR@{}: {:.4f}\".format(k, scores['mrr@k'][k]))\n","\n","        for k in scores['ndcg@k']:\n","            logger.info(\"NDCG@{}: {:.4f}\".format(k, scores['ndcg@k'][k]))\n","\n","        for k in scores['map@k']:\n","            logger.info(\"MAP@{}: {:.4f}\".format(k, scores['map@k'][k]))\n","\n","\n","    @staticmethod\n","    def compute_dcg_at_k(relevances, k):\n","        dcg = 0\n","        for i in range(min(len(relevances), k)):\n","            dcg += relevances[i] / np.log2(i + 2)  #+2 as we start our idx at 0\n","        return dcg\n","    \n","    def get_embeddings(self,model,qr,qr_idx):\n","        info_dataset = infodataset(qr,qr_idx,img_dir,transform = transform_pipe)\n","        info_loader = DataLoader(\n","            info_dataset,\n","            batch_size=BATCH_SIZE,\n","            pin_memory=True,\n","            num_workers = 8,\n","            )\n","        \n","        embeddings = list()\n","        since = time.time()\n","        for i,batch in enumerate(info_loader):\n","            model.eval()\n","\n","            text = batch['token']\n","            images = batch['image']\n","\n","            text,images = torch.as_tensor(text).to(device), torch.as_tensor(images).to(device)\n","\n","            with torch.no_grad():\n","                yhat = model.forward(images,text)\n","            \n","            for j in yhat:\n","                embeddings.append(j.cpu().detach().numpy())\n","            \n","            if(i%40==0):\n","                print(f'{i} iterations hase been completed, and model is running for {time.time()-since}')\n","        \n","        return embeddings\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pZFzkQT1oKEP"},"source":["with open(folder_quora+'/devinfo_100.txt','rb') as a:\n","    queries_dev = pickle.load(a)\n","    rel_docs_dev= pickle.load(a)\n","\n","with open(folder_quora+'/testinfo_100.txt','rb') as a:\n","    queries_test= pickle.load(a)\n","    rel_docs_test= pickle.load(a)\n","\n","with open(folder_quora+'/traininfo_100.txt','rb') as a:\n","    queries_train= pickle.load(a)\n","    rel_docs_train= pickle.load(a)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rVKAcaqIbgDN"},"source":["def string_sentence(i,qr):\n","    return qr.loc[i,'Title']+ ' '+' '.join(qr.loc[i,'Tags'])+ ' ' + qr.loc[i,'Text']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5XTuVNlbeF-5"},"source":["def corpus(qr):\n","    corpus = dict()\n","    for i in qr.index.values:\n","        corpus[i] = string_sentence(i,qr)\n","    return corpus"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zFwNBTJCoOS4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613460482283,"user_tz":-330,"elapsed":1377036,"user":{"displayName":"MOHIT MEHTA","photoUrl":"","userId":"00949415454628222481"}},"outputId":"27055007-399c-4874-f142-eb4bc8bdc1f6"},"source":["train_inforet = InformationRetreivalEvaluator(train_qr,queries_train,corpus(train_qr),rel_docs_train)\n","os.makedirs(folder+'/info',exist_ok=True)\n","train_inforet(model,folder+'/info')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 iterations hase been completed, and model is running for 0.8856837749481201\n","40 iterations hase been completed, and model is running for 3.478123188018799\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (802 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1843 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["80 iterations hase been completed, and model is running for 6.241954565048218\n","0 iterations hase been completed, and model is running for 0.9674324989318848\n","40 iterations hase been completed, and model is running for 3.6424734592437744\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (893 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["80 iterations hase been completed, and model is running for 6.236653089523315\n","120 iterations hase been completed, and model is running for 8.907212257385254\n","160 iterations hase been completed, and model is running for 11.506620645523071\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1708 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["200 iterations hase been completed, and model is running for 13.969954013824463\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1957 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["240 iterations hase been completed, and model is running for 16.54749846458435\n","280 iterations hase been completed, and model is running for 19.120650053024292\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1759 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["320 iterations hase been completed, and model is running for 21.68238854408264\n","360 iterations hase been completed, and model is running for 24.283759593963623\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (4157 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["400 iterations hase been completed, and model is running for 26.956613063812256\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["440 iterations hase been completed, and model is running for 29.503349781036377\n","480 iterations hase been completed, and model is running for 32.1271710395813\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (3270 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["520 iterations hase been completed, and model is running for 34.6437668800354\n","560 iterations hase been completed, and model is running for 37.2528018951416\n","600 iterations hase been completed, and model is running for 39.737855434417725\n","640 iterations hase been completed, and model is running for 42.31553792953491\n","680 iterations hase been completed, and model is running for 44.842400789260864\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2115 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["720 iterations hase been completed, and model is running for 47.46142554283142\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["760 iterations hase been completed, and model is running for 49.96222448348999\n","800 iterations hase been completed, and model is running for 52.40080547332764\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["image file is truncated (3 bytes not processed)\n","Something went wrong with the image of id 164569\n","840 iterations hase been completed, and model is running for 54.87905836105347\n","880 iterations hase been completed, and model is running for 57.41687870025635\n","920 iterations hase been completed, and model is running for 60.00661587715149\n","960 iterations hase been completed, and model is running for 62.49047827720642\n","1000 iterations hase been completed, and model is running for 65.07870864868164\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1339 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["1040 iterations hase been completed, and model is running for 67.5641942024231\n","1080 iterations hase been completed, and model is running for 70.05850458145142\n","1120 iterations hase been completed, and model is running for 72.69360303878784\n","1160 iterations hase been completed, and model is running for 75.23489332199097\n","1200 iterations hase been completed, and model is running for 77.69236445426941\n","1240 iterations hase been completed, and model is running for 80.37102842330933\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1908 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["1280 iterations hase been completed, and model is running for 82.93906140327454\n","1320 iterations hase been completed, and model is running for 85.43973636627197\n","1360 iterations hase been completed, and model is running for 88.11757683753967\n","1400 iterations hase been completed, and model is running for 90.62862396240234\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (4089 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["1440 iterations hase been completed, and model is running for 93.25732207298279\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["1480 iterations hase been completed, and model is running for 96.01798963546753\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["1520 iterations hase been completed, and model is running for 99.782719373703\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2386 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["1560 iterations hase been completed, and model is running for 102.40466094017029\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["1600 iterations hase been completed, and model is running for 104.8958432674408\n","1640 iterations hase been completed, and model is running for 107.45791983604431\n","1680 iterations hase been completed, and model is running for 110.0976824760437\n","1720 iterations hase been completed, and model is running for 112.73395323753357\n","1760 iterations hase been completed, and model is running for 115.32906341552734\n","1800 iterations hase been completed, and model is running for 118.29383659362793\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1843 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (3436 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["1840 iterations hase been completed, and model is running for 120.97662997245789\n","1880 iterations hase been completed, and model is running for 123.78635239601135\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["1920 iterations hase been completed, and model is running for 126.34797668457031\n","1960 iterations hase been completed, and model is running for 128.80212664604187\n","2000 iterations hase been completed, and model is running for 131.4257185459137\n","2040 iterations hase been completed, and model is running for 133.89185762405396\n","2080 iterations hase been completed, and model is running for 136.45922708511353\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["2120 iterations hase been completed, and model is running for 139.6079216003418\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["2160 iterations hase been completed, and model is running for 142.32287073135376\n","2200 iterations hase been completed, and model is running for 144.99061727523804\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (4009 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["2240 iterations hase been completed, and model is running for 147.4653604030609\n","2280 iterations hase been completed, and model is running for 150.0389745235443\n","2320 iterations hase been completed, and model is running for 152.69701170921326\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["2360 iterations hase been completed, and model is running for 155.3216483592987\n","2400 iterations hase been completed, and model is running for 158.21587944030762\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (969 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (3527 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["2440 iterations hase been completed, and model is running for 161.16766214370728\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2095 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["2480 iterations hase been completed, and model is running for 163.84451842308044\n","2520 iterations hase been completed, and model is running for 166.54182314872742\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (4285 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["2560 iterations hase been completed, and model is running for 169.3038854598999\n","2600 iterations hase been completed, and model is running for 171.87788891792297\n","2640 iterations hase been completed, and model is running for 174.56079363822937\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["2680 iterations hase been completed, and model is running for 177.16135692596436\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (10008 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1656 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (806 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["2720 iterations hase been completed, and model is running for 179.80821800231934\n","2760 iterations hase been completed, and model is running for 182.4702832698822\n","2800 iterations hase been completed, and model is running for 185.17908382415771\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (2841 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["2840 iterations hase been completed, and model is running for 187.91712498664856\n","2880 iterations hase been completed, and model is running for 190.4338505268097\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["2920 iterations hase been completed, and model is running for 193.2725019454956\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1612 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["2960 iterations hase been completed, and model is running for 195.98811173439026\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["3000 iterations hase been completed, and model is running for 198.6402509212494\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["3040 iterations hase been completed, and model is running for 201.35849714279175\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2514 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (808 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["3080 iterations hase been completed, and model is running for 205.36569929122925\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1014 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["3120 iterations hase been completed, and model is running for 208.04548406600952\n","3160 iterations hase been completed, and model is running for 210.60832285881042\n","3200 iterations hase been completed, and model is running for 213.16331100463867\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (897 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1490 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["3240 iterations hase been completed, and model is running for 215.69271159172058\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["3280 iterations hase been completed, and model is running for 218.24050307273865\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["3320 iterations hase been completed, and model is running for 220.88585305213928\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (792 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["3360 iterations hase been completed, and model is running for 223.5522825717926\n","3400 iterations hase been completed, and model is running for 226.57529187202454\n","3440 iterations hase been completed, and model is running for 229.0826392173767\n","3480 iterations hase been completed, and model is running for 231.7031877040863\n","3520 iterations hase been completed, and model is running for 235.18933987617493\n","3560 iterations hase been completed, and model is running for 237.80187940597534\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (877 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["3600 iterations hase been completed, and model is running for 240.50283670425415\n","3640 iterations hase been completed, and model is running for 243.22559475898743\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["3680 iterations hase been completed, and model is running for 245.92620992660522\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (2411 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (890 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["3720 iterations hase been completed, and model is running for 248.92879843711853\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1823 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (766 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["3760 iterations hase been completed, and model is running for 252.3208270072937\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (5978 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["3800 iterations hase been completed, and model is running for 255.09083938598633\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["3840 iterations hase been completed, and model is running for 257.778799533844\n","3880 iterations hase been completed, and model is running for 260.4871551990509\n","3920 iterations hase been completed, and model is running for 263.0950622558594\n","3960 iterations hase been completed, and model is running for 265.6756157875061\n","4000 iterations hase been completed, and model is running for 268.29007029533386\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["4040 iterations hase been completed, and model is running for 270.99666142463684\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (3989 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["4080 iterations hase been completed, and model is running for 273.81050086021423\n","4120 iterations hase been completed, and model is running for 276.5716519355774\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["4160 iterations hase been completed, and model is running for 279.1690547466278\n","4200 iterations hase been completed, and model is running for 281.7795042991638\n","4240 iterations hase been completed, and model is running for 284.361932516098\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (2560 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["4280 iterations hase been completed, and model is running for 286.9014928340912\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["4320 iterations hase been completed, and model is running for 289.84517645835876\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (802 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["4360 iterations hase been completed, and model is running for 292.47769808769226\n","4400 iterations hase been completed, and model is running for 295.154988527298\n","4440 iterations hase been completed, and model is running for 297.8566460609436\n","4480 iterations hase been completed, and model is running for 300.2699739933014\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["4520 iterations hase been completed, and model is running for 303.19382309913635\n","4560 iterations hase been completed, and model is running for 305.8096787929535\n","4600 iterations hase been completed, and model is running for 309.006573677063\n","4640 iterations hase been completed, and model is running for 311.62696957588196\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (809 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["4680 iterations hase been completed, and model is running for 314.9603228569031\n","4720 iterations hase been completed, and model is running for 317.5916030406952\n","4760 iterations hase been completed, and model is running for 320.07470083236694\n","4800 iterations hase been completed, and model is running for 322.6126093864441\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["4840 iterations hase been completed, and model is running for 325.1393883228302\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (9739 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["4880 iterations hase been completed, and model is running for 327.7905304431915\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1326 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["4920 iterations hase been completed, and model is running for 330.46126222610474\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["4960 iterations hase been completed, and model is running for 333.72746896743774\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["5000 iterations hase been completed, and model is running for 336.25618290901184\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["5040 iterations hase been completed, and model is running for 339.10152554512024\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["5080 iterations hase been completed, and model is running for 341.76183009147644\n","5120 iterations hase been completed, and model is running for 344.32851576805115\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1601 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["5160 iterations hase been completed, and model is running for 346.9846725463867\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["5200 iterations hase been completed, and model is running for 349.68683218955994\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["5240 iterations hase been completed, and model is running for 352.36608028411865\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["5280 iterations hase been completed, and model is running for 355.61923575401306\n","5320 iterations hase been completed, and model is running for 358.3277733325958\n","5360 iterations hase been completed, and model is running for 360.964396238327\n","5400 iterations hase been completed, and model is running for 363.49634552001953\n","5440 iterations hase been completed, and model is running for 366.13134145736694\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["5480 iterations hase been completed, and model is running for 368.8617489337921\n","5520 iterations hase been completed, and model is running for 371.5421905517578\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["5560 iterations hase been completed, and model is running for 374.1155436038971\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["5600 iterations hase been completed, and model is running for 376.6978540420532\n","5640 iterations hase been completed, and model is running for 379.32415413856506\n","5680 iterations hase been completed, and model is running for 382.0591011047363\n","5720 iterations hase been completed, and model is running for 384.6441538333893\n","5760 iterations hase been completed, and model is running for 387.16873693466187\n","5800 iterations hase been completed, and model is running for 389.6358675956726\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["5840 iterations hase been completed, and model is running for 392.26647758483887\n","5880 iterations hase been completed, and model is running for 394.8036277294159\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1323 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["5920 iterations hase been completed, and model is running for 397.4328444004059\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2384 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["5960 iterations hase been completed, and model is running for 399.9716296195984\n","6000 iterations hase been completed, and model is running for 402.5628294944763\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["6040 iterations hase been completed, and model is running for 406.0761706829071\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1450 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["6080 iterations hase been completed, and model is running for 408.6216151714325\n","6120 iterations hase been completed, and model is running for 411.24605441093445\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["6160 iterations hase been completed, and model is running for 413.909930229187\n","6200 iterations hase been completed, and model is running for 416.4760594367981\n","6240 iterations hase been completed, and model is running for 419.2959339618683\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["6280 iterations hase been completed, and model is running for 421.9280688762665\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (695 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["6320 iterations hase been completed, and model is running for 424.51249957084656\n","6360 iterations hase been completed, and model is running for 427.172447681427\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1818 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["6400 iterations hase been completed, and model is running for 429.7524244785309\n","6440 iterations hase been completed, and model is running for 432.4273257255554\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["6480 iterations hase been completed, and model is running for 435.11587166786194\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["6520 iterations hase been completed, and model is running for 437.74440121650696\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (898 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["6560 iterations hase been completed, and model is running for 440.54165506362915\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (732 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["6600 iterations hase been completed, and model is running for 443.107709646225\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2097 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["6640 iterations hase been completed, and model is running for 445.6573135852814\n","6680 iterations hase been completed, and model is running for 448.13474702835083\n","6720 iterations hase been completed, and model is running for 450.7053611278534\n","6760 iterations hase been completed, and model is running for 453.33682799339294\n","6800 iterations hase been completed, and model is running for 455.9411656856537\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["6840 iterations hase been completed, and model is running for 458.44456219673157\n","6880 iterations hase been completed, and model is running for 461.0957806110382\n","6920 iterations hase been completed, and model is running for 464.2354726791382\n","6960 iterations hase been completed, and model is running for 466.85004925727844\n","7000 iterations hase been completed, and model is running for 469.48578691482544\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (800 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["7040 iterations hase been completed, and model is running for 472.02378153800964\n","7080 iterations hase been completed, and model is running for 474.7024838924408\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["7120 iterations hase been completed, and model is running for 477.3007667064667\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["7160 iterations hase been completed, and model is running for 479.86666917800903\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (743 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (2098 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["7200 iterations hase been completed, and model is running for 482.9584107398987\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["7240 iterations hase been completed, and model is running for 485.8827347755432\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (6048 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["7280 iterations hase been completed, and model is running for 488.4747393131256\n","7320 iterations hase been completed, and model is running for 490.95707178115845\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["7360 iterations hase been completed, and model is running for 493.84721326828003\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2166 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["7400 iterations hase been completed, and model is running for 496.64507126808167\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["7440 iterations hase been completed, and model is running for 499.2661302089691\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (851 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["7480 iterations hase been completed, and model is running for 502.07439517974854\n","7520 iterations hase been completed, and model is running for 504.57206082344055\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["7560 iterations hase been completed, and model is running for 507.19387674331665\n","7600 iterations hase been completed, and model is running for 509.7615566253662\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (6565 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["7640 iterations hase been completed, and model is running for 512.2549993991852\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1540 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["7680 iterations hase been completed, and model is running for 514.8569846153259\n","7720 iterations hase been completed, and model is running for 517.3507027626038\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2017 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["7760 iterations hase been completed, and model is running for 519.8612995147705\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["7800 iterations hase been completed, and model is running for 522.583331823349\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (946 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["7840 iterations hase been completed, and model is running for 525.0733304023743\n","7880 iterations hase been completed, and model is running for 529.42032122612\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (798 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["7920 iterations hase been completed, and model is running for 532.4331471920013\n","7960 iterations hase been completed, and model is running for 535.1090633869171\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (978 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["8000 iterations hase been completed, and model is running for 537.8709704875946\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1444 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["8040 iterations hase been completed, and model is running for 540.4366838932037\n","8080 iterations hase been completed, and model is running for 542.9886493682861\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["8120 iterations hase been completed, and model is running for 545.8001339435577\n","8160 iterations hase been completed, and model is running for 548.3953199386597\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (949 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["8200 iterations hase been completed, and model is running for 551.5856301784515\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (897 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["8240 iterations hase been completed, and model is running for 554.1380264759064\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2194 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["8280 iterations hase been completed, and model is running for 556.8071329593658\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2452 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["8320 iterations hase been completed, and model is running for 559.4950938224792\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["8360 iterations hase been completed, and model is running for 562.093873500824\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["8400 iterations hase been completed, and model is running for 564.6042695045471\n","8440 iterations hase been completed, and model is running for 567.7225923538208\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["8480 iterations hase been completed, and model is running for 570.3503630161285\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["8520 iterations hase been completed, and model is running for 572.8838589191437\n","8560 iterations hase been completed, and model is running for 575.4593870639801\n","8600 iterations hase been completed, and model is running for 578.2190747261047\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["8640 iterations hase been completed, and model is running for 581.0213322639465\n","8680 iterations hase been completed, and model is running for 584.4047393798828\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (4049 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["8720 iterations hase been completed, and model is running for 586.9005341529846\n","8760 iterations hase been completed, and model is running for 589.5471160411835\n","8800 iterations hase been completed, and model is running for 592.2239496707916\n","8840 iterations hase been completed, and model is running for 595.238753080368\n","8880 iterations hase been completed, and model is running for 597.8540415763855\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (853 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["8920 iterations hase been completed, and model is running for 600.5504133701324\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["8960 iterations hase been completed, and model is running for 603.1194734573364\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["9000 iterations hase been completed, and model is running for 605.7586433887482\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["9040 iterations hase been completed, and model is running for 608.505049943924\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1002 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["9080 iterations hase been completed, and model is running for 611.0702562332153\n","9120 iterations hase been completed, and model is running for 613.6226041316986\n","9160 iterations hase been completed, and model is running for 616.1886417865753\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["9200 iterations hase been completed, and model is running for 618.7480223178864\n","9240 iterations hase been completed, and model is running for 621.5348496437073\n","9280 iterations hase been completed, and model is running for 624.298686504364\n","9320 iterations hase been completed, and model is running for 626.8227035999298\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["9360 iterations hase been completed, and model is running for 629.5237257480621\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (2879 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (3045 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["9400 iterations hase been completed, and model is running for 632.2836787700653\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2147 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["9440 iterations hase been completed, and model is running for 635.9755458831787\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["9480 iterations hase been completed, and model is running for 638.7524785995483\n","9520 iterations hase been completed, and model is running for 641.2879300117493\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2334 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (4282 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["9560 iterations hase been completed, and model is running for 644.2368543148041\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (914 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["9600 iterations hase been completed, and model is running for 647.0702791213989\n","9640 iterations hase been completed, and model is running for 649.6199643611908\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["9680 iterations hase been completed, and model is running for 652.2019488811493\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["9720 iterations hase been completed, and model is running for 654.7404277324677\n","9760 iterations hase been completed, and model is running for 657.4567105770111\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["9800 iterations hase been completed, and model is running for 660.1388881206512\n","9840 iterations hase been completed, and model is running for 662.8936741352081\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (743 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["9880 iterations hase been completed, and model is running for 665.5986750125885\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (831 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["9920 iterations hase been completed, and model is running for 668.1550042629242\n","9960 iterations hase been completed, and model is running for 670.6542382240295\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["10000 iterations hase been completed, and model is running for 673.132119178772\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["10040 iterations hase been completed, and model is running for 675.68514752388\n","10080 iterations hase been completed, and model is running for 678.4440426826477\n","10120 iterations hase been completed, and model is running for 681.019781589508\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["10160 iterations hase been completed, and model is running for 683.7633554935455\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (6808 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["10200 iterations hase been completed, and model is running for 686.642404794693\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (5480 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (3952 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["10240 iterations hase been completed, and model is running for 689.8802690505981\n","10280 iterations hase been completed, and model is running for 692.3814628124237\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["10320 iterations hase been completed, and model is running for 694.865713596344\n","10360 iterations hase been completed, and model is running for 697.3613646030426\n","10400 iterations hase been completed, and model is running for 699.9473583698273\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (3519 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["10440 iterations hase been completed, and model is running for 702.6770477294922\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (978 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (2147 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["10480 iterations hase been completed, and model is running for 705.2827270030975\n","10520 iterations hase been completed, and model is running for 707.9017548561096\n","10560 iterations hase been completed, and model is running for 710.4367198944092\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (845 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["10600 iterations hase been completed, and model is running for 713.1932446956635\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (817 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["10640 iterations hase been completed, and model is running for 715.921689748764\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (887 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["10680 iterations hase been completed, and model is running for 718.5348875522614\n","10720 iterations hase been completed, and model is running for 721.2549171447754\n","10760 iterations hase been completed, and model is running for 724.7239398956299\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["10800 iterations hase been completed, and model is running for 727.4743309020996\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (960 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["10840 iterations hase been completed, and model is running for 730.2281744480133\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2163 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["10880 iterations hase been completed, and model is running for 732.761396408081\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (4475 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["10920 iterations hase been completed, and model is running for 735.3219878673553\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["10960 iterations hase been completed, and model is running for 737.854838848114\n","11000 iterations hase been completed, and model is running for 740.5405945777893\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2251 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["11040 iterations hase been completed, and model is running for 743.2512814998627\n","11080 iterations hase been completed, and model is running for 746.0111434459686\n","11120 iterations hase been completed, and model is running for 748.9023287296295\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["11160 iterations hase been completed, and model is running for 751.8160936832428\n","11200 iterations hase been completed, and model is running for 754.4149954319\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["11240 iterations hase been completed, and model is running for 756.9940860271454\n","11280 iterations hase been completed, and model is running for 759.7167963981628\n","11320 iterations hase been completed, and model is running for 762.2649853229523\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1023 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["11360 iterations hase been completed, and model is running for 765.1017549037933\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["11400 iterations hase been completed, and model is running for 767.6605455875397\n","11440 iterations hase been completed, and model is running for 770.3920795917511\n","11480 iterations hase been completed, and model is running for 772.9864735603333\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (846 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["11520 iterations hase been completed, and model is running for 775.5555212497711\n","11560 iterations hase been completed, and model is running for 778.0402495861053\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (3758 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["11600 iterations hase been completed, and model is running for 780.7287964820862\n","11640 iterations hase been completed, and model is running for 783.3599708080292\n","11680 iterations hase been completed, and model is running for 786.1294980049133\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1402 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["11720 iterations hase been completed, and model is running for 788.8468742370605\n","11760 iterations hase been completed, and model is running for 791.8915059566498\n","11800 iterations hase been completed, and model is running for 795.3838450908661\n","11840 iterations hase been completed, and model is running for 797.876843214035\n","11880 iterations hase been completed, and model is running for 800.4648530483246\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1527 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["11920 iterations hase been completed, and model is running for 803.6095492839813\n","11960 iterations hase been completed, and model is running for 806.2846527099609\n","12000 iterations hase been completed, and model is running for 808.8828899860382\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["12040 iterations hase been completed, and model is running for 813.3911592960358\n","12080 iterations hase been completed, and model is running for 816.0184669494629\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2323 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["12120 iterations hase been completed, and model is running for 818.7142775058746\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (926 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["12160 iterations hase been completed, and model is running for 821.428320646286\n","12200 iterations hase been completed, and model is running for 823.9428496360779\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1987 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["12240 iterations hase been completed, and model is running for 826.6577868461609\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["12280 iterations hase been completed, and model is running for 829.8635613918304\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (756 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["12320 iterations hase been completed, and model is running for 832.3852245807648\n","12360 iterations hase been completed, and model is running for 835.0407660007477\n","12400 iterations hase been completed, and model is running for 837.6575331687927\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (804 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["12440 iterations hase been completed, and model is running for 840.3048188686371\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["12480 iterations hase been completed, and model is running for 843.0698907375336\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (3010 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["12520 iterations hase been completed, and model is running for 845.7290391921997\n","12560 iterations hase been completed, and model is running for 848.3724799156189\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1987 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["12600 iterations hase been completed, and model is running for 851.0218110084534\n","12640 iterations hase been completed, and model is running for 853.6075642108917\n","12680 iterations hase been completed, and model is running for 856.2977437973022\n","12720 iterations hase been completed, and model is running for 858.944712638855\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["12760 iterations hase been completed, and model is running for 861.7107825279236\n","12800 iterations hase been completed, and model is running for 864.2051668167114\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 512). Running this sequence through the model will result in indexing errors\n","/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["12840 iterations hase been completed, and model is running for 866.8670344352722\n","12880 iterations hase been completed, and model is running for 869.5995664596558\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["12920 iterations hase been completed, and model is running for 872.3227224349976\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["12960 iterations hase been completed, and model is running for 874.9327282905579\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["13000 iterations hase been completed, and model is running for 877.5240044593811\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1410 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["13040 iterations hase been completed, and model is running for 880.237340927124\n","13080 iterations hase been completed, and model is running for 882.839560508728\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["13120 iterations hase been completed, and model is running for 885.4738218784332\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  \"Palette images with Transparency expressed in bytes should be \"\n"],"name":"stderr"},{"output_type":"stream","text":["13160 iterations hase been completed, and model is running for 888.1906566619873\n","13200 iterations hase been completed, and model is running for 890.833509683609\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["13240 iterations hase been completed, and model is running for 893.5493535995483\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["13280 iterations hase been completed, and model is running for 896.320937871933\n","13320 iterations hase been completed, and model is running for 898.8024871349335\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1613 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["13360 iterations hase been completed, and model is running for 901.355489730835\n","13400 iterations hase been completed, and model is running for 904.1298384666443\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (978 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (2434 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["13440 iterations hase been completed, and model is running for 906.8283874988556\n","13480 iterations hase been completed, and model is running for 909.3740491867065\n","13520 iterations hase been completed, and model is running for 912.1686050891876\n","13560 iterations hase been completed, and model is running for 914.9293165206909\n","13600 iterations hase been completed, and model is running for 917.573942899704\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (883 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (925 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["13640 iterations hase been completed, and model is running for 920.2509450912476\n","13680 iterations hase been completed, and model is running for 922.8999650478363\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["13720 iterations hase been completed, and model is running for 926.4069163799286\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["13760 iterations hase been completed, and model is running for 929.0269839763641\n","13800 iterations hase been completed, and model is running for 931.5479428768158\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2779 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["13840 iterations hase been completed, and model is running for 933.9749646186829\n","13880 iterations hase been completed, and model is running for 936.7073683738708\n","13920 iterations hase been completed, and model is running for 939.28409075737\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["13960 iterations hase been completed, and model is running for 941.788824558258\n","14000 iterations hase been completed, and model is running for 944.6902506351471\n","14040 iterations hase been completed, and model is running for 947.3900451660156\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["14080 iterations hase been completed, and model is running for 950.0482547283173\n","14120 iterations hase been completed, and model is running for 952.7841510772705\n","14160 iterations hase been completed, and model is running for 955.3656489849091\n","14200 iterations hase been completed, and model is running for 957.9762935638428\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (8020 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["14240 iterations hase been completed, and model is running for 960.6807560920715\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2434 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["14280 iterations hase been completed, and model is running for 963.1128127574921\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["14320 iterations hase been completed, and model is running for 966.3335247039795\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["14360 iterations hase been completed, and model is running for 968.8877980709076\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (800 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["14400 iterations hase been completed, and model is running for 971.6214489936829\n","14440 iterations hase been completed, and model is running for 974.4842233657837\n","14480 iterations hase been completed, and model is running for 977.259352684021\n","14520 iterations hase been completed, and model is running for 979.9037673473358\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (756 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["14560 iterations hase been completed, and model is running for 982.5344793796539\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["14600 iterations hase been completed, and model is running for 985.0592339038849\n","14640 iterations hase been completed, and model is running for 987.774941444397\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["14680 iterations hase been completed, and model is running for 990.3093404769897\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2960 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["14720 iterations hase been completed, and model is running for 992.9417741298676\n","14760 iterations hase been completed, and model is running for 995.6411328315735\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["14800 iterations hase been completed, and model is running for 998.187974691391\n","14840 iterations hase been completed, and model is running for 1000.842520236969\n","14880 iterations hase been completed, and model is running for 1003.4431247711182\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1571 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["14920 iterations hase been completed, and model is running for 1006.241973400116\n","14960 iterations hase been completed, and model is running for 1008.8976044654846\n","15000 iterations hase been completed, and model is running for 1011.6094899177551\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["15040 iterations hase been completed, and model is running for 1014.2237613201141\n","15080 iterations hase been completed, and model is running for 1016.7322328090668\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (8836 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (2009 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["15120 iterations hase been completed, and model is running for 1019.3913731575012\n","15160 iterations hase been completed, and model is running for 1022.1298689842224\n","15200 iterations hase been completed, and model is running for 1024.6344339847565\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1624 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["15240 iterations hase been completed, and model is running for 1027.0838050842285\n","15280 iterations hase been completed, and model is running for 1029.5447525978088\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2187 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["15320 iterations hase been completed, and model is running for 1032.2491858005524\n","15360 iterations hase been completed, and model is running for 1034.9084236621857\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2954 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["15400 iterations hase been completed, and model is running for 1037.4209315776825\n","15440 iterations hase been completed, and model is running for 1040.0242447853088\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["15480 iterations hase been completed, and model is running for 1043.3974595069885\n","15520 iterations hase been completed, and model is running for 1046.0602066516876\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["15560 iterations hase been completed, and model is running for 1048.7634880542755\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (785 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["15600 iterations hase been completed, and model is running for 1053.04265499115\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["15640 iterations hase been completed, and model is running for 1055.885368347168\n","15680 iterations hase been completed, and model is running for 1058.4763016700745\n","15720 iterations hase been completed, and model is running for 1061.0568656921387\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["15760 iterations hase been completed, and model is running for 1063.7932069301605\n","15800 iterations hase been completed, and model is running for 1066.4520564079285\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (4234 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["15840 iterations hase been completed, and model is running for 1069.2252039909363\n","15880 iterations hase been completed, and model is running for 1071.9810767173767\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["15920 iterations hase been completed, and model is running for 1074.4127852916718\n","15960 iterations hase been completed, and model is running for 1077.3755156993866\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (762 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["16000 iterations hase been completed, and model is running for 1080.1627659797668\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["16040 iterations hase been completed, and model is running for 1084.9981126785278\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["16080 iterations hase been completed, and model is running for 1087.5120360851288\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (975 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (3859 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["16120 iterations hase been completed, and model is running for 1090.1891651153564\n","16160 iterations hase been completed, and model is running for 1092.7194130420685\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["16200 iterations hase been completed, and model is running for 1095.3064110279083\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (6220 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["16240 iterations hase been completed, and model is running for 1097.872594833374\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["16280 iterations hase been completed, and model is running for 1100.9421467781067\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (879 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["16320 iterations hase been completed, and model is running for 1103.5968458652496\n","16360 iterations hase been completed, and model is running for 1106.2309594154358\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["16400 iterations hase been completed, and model is running for 1109.1844940185547\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["16440 iterations hase been completed, and model is running for 1111.9995603561401\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.00011871156652301434"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"4avOC38-mi6U"},"source":["# Rough"]}]}