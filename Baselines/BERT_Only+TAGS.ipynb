{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_Only+TAGS.ipynb","provenance":[],"collapsed_sections":["JHAMYwNfv5Th","quJKUGIXv8zk","IsOrcAQ_jXL6","M2mT9dqsm5Vy","beqWAJVP2_aP","TEwqX5TfdPKk","J2Mw6eG5KqVn","ZuGYeCAq97yQ","kYlESuc6HmGF"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rXKu5-xjGwOa","executionInfo":{"status":"ok","timestamp":1617269340363,"user_tz":-330,"elapsed":1325,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}},"outputId":"e4ef32d7-441e-4f59-a399-c6f67ce773c6"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Thu Apr  1 09:28:59 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   46C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mz76Bz490lqB","executionInfo":{"status":"ok","timestamp":1617269340949,"user_tz":-330,"elapsed":1903,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}},"outputId":"d25ac3da-9fee-4ad2-9d32-39ed38f9a78d"},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JHAMYwNfv5Th"},"source":["# Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"_pwgo3m2wVQS","executionInfo":{"status":"ok","timestamp":1617269343793,"user_tz":-330,"elapsed":4743,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}},"outputId":"6eb8a725-051a-4c7d-ab6b-3cae1ef2477b"},"source":["!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jKIzzX6J3QtS","executionInfo":{"status":"ok","timestamp":1617269344402,"user_tz":-330,"elapsed":5347,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["import pandas as pd\n","import pickle\n","import random\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","import os\n","from enum import Enum\n","from torch.nn import functional as F\n","import time\n","import logging\n","import numpy as np\n","import math\n","from matplotlib import pyplot as plt\n","\n","logger = logging.getLogger(__name__)\n","random.seed(13)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"quJKUGIXv8zk"},"source":["# Utilities"]},{"cell_type":"code","metadata":{"id":"u1t9DLnOsFN_","executionInfo":{"status":"ok","timestamp":1617269344402,"user_tz":-330,"elapsed":5339,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["def pytorch_cos_sim(a: torch.Tensor, b: torch.Tensor):\n","    \"\"\"\n","    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n","    This function can be used as a faster replacement for 1-scipy.spatial.distance.cdist(a,b)\n","    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n","    \"\"\"\n","    if not isinstance(a, torch.Tensor):\n","        a = torch.tensor(a)\n","\n","    if not isinstance(b, torch.Tensor):\n","        b = torch.tensor(b)\n","\n","    if len(a.shape) == 1:\n","        a = a.unsqueeze(0)\n","\n","    if len(b.shape) == 1:\n","        b = b.unsqueeze(0)\n","\n","    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n","    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n","    return torch.mm(a_norm, b_norm.transpose(0, 1))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"DQdj5p8fzl-1","executionInfo":{"status":"ok","timestamp":1617269344402,"user_tz":-330,"elapsed":5333,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["def string_sentence(i,qr):\n","    return qr.loc[i,'Title'] + ' '  + ' '.join(qr.loc[i,'Tags']) + ' '  + qr.loc[i,'Text']"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"STnKB8R7NVEa"},"source":["# Model Hyper-Parameters"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DebNqaCF2uE_","executionInfo":{"status":"ok","timestamp":1617269344404,"user_tz":-330,"elapsed":5329,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}},"outputId":"de495070-1b48-489f-e022-27b0cf3f2932"},"source":["folder_quora = '/gdrive/MyDrive/Linked/new_splits'\n","folder = '/gdrive/MyDrive/Linked/Models'\n","os.makedirs(folder,exist_ok = True)\n","BATCH_SIZE = 8\n","fin_BATCH_SIZE = 32\n","n_worker = 2\n","margin = 0.8\n","\n","#---------\n","#Note that amp cannot be used without sigmoid\n","use_amp = True\n","use_sig = True\n","#----------\n","\n","use_sig_eval = False\n","# eval_BATCH_SIZE = 4 \n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tgk_opqd2prV"},"source":["# Creating Dataset and Dataloader"]},{"cell_type":"markdown","metadata":{"id":"xnOxcgwk5WiU"},"source":["###Loading Data"]},{"cell_type":"code","metadata":{"id":"N1RqPrOk5Ynm","executionInfo":{"status":"ok","timestamp":1617269349113,"user_tz":-330,"elapsed":10033,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["with open(folder_quora+'/data/splits/pandas_split.txt','rb') as a:\n","    train_qr=pickle.load(a)\n","    dev_qr = pickle.load(a)\n","    test_qr = pickle.load(a)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z5qm94QOFH2V","executionInfo":{"status":"ok","timestamp":1617269349130,"user_tz":-330,"elapsed":10046,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["with open(folder_quora+'/data/splits/train_dev_test.txt','rb') as a:\n","    train_data=pickle.load(a)\n","    train_score = pickle.load(a)\n","    dev_data = pickle.load(a)\n","    dev_score = pickle.load(a)\n","    test_data = pickle.load(a)\n","    test_score = pickle.load(a)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IsOrcAQ_jXL6"},"source":["## Glove word embeddings"]},{"cell_type":"code","metadata":{"id":"QbNi3BPUjV9p","executionInfo":{"status":"ok","timestamp":1617269349771,"user_tz":-330,"elapsed":10680,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["from torchtext.vocab import GloVe\n","embedding_glove = GloVe(name='6B', dim=100)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M2mT9dqsm5Vy"},"source":["## Creating Dataset "]},{"cell_type":"code","metadata":{"id":"E6I9YioKE8uK","executionInfo":{"status":"ok","timestamp":1617269349774,"user_tz":-330,"elapsed":10677,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["from transformers import BertTokenizerFast, BertConfig,BertModel\n","config = BertConfig()\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"KXPoomQx4Zby","executionInfo":{"status":"ok","timestamp":1617269349775,"user_tz":-330,"elapsed":10673,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["class custom_dataset(Dataset):\n","    def __init__(self,qr,qr_idx,label,transform = None):\n","        self.qr = qr\n","        self.qr_idx = qr_idx\n","        self.label = label\n","        self.transform = transform\n","    \n","    def __getitem__(self,idx):\n","        id1 = self.qr_idx[idx][0]\n","        id2 = self.qr_idx[idx][1]\n","\n","        sample = dict()\n","\n","        t1 = '[CLS]' + self.qr.loc[id1,'Title']  + ' ' + self.qr.loc[id1,'Text'] + '[SEP]'\n","        t2 = '[CLS]' + self.qr.loc[id2,'Title']+ ' ' + self.qr.loc[id2,'Text'] + '[SEP]'\n","        indexed_t1 = tokenizer.encode(t1,max_length = 512,truncation = True)\n","        indexed_t2 = tokenizer.encode(t2,max_length = 512,truncation = True)\n","\n","        tg1 = self.qr.loc[id1,'Tags']\n","        tg2 = self.qr.loc[id1,'Tags']\n","\n","        if(type(tg1)==str):\n","            tg1 = [tg1]\n","        if(type(tg2)==str):\n","            tg2 = [tg2]\n","\n","        while(len(tg1)<10):\n","            tg1.append('')\n","        while(len(tg2)<10):\n","            tg2.append('')\n","\n","        tag1 = embedding_glove.get_vecs_by_tokens(tg1,lower_case_backup=True)\n","        tag2 = embedding_glove.get_vecs_by_tokens(tg2,lower_case_backup=True)\n","\n","        # [tag1,tag2] = rnn_utils.pad_sequence([tag1,tag2],batch_first=True)\n","\n","        while(len(indexed_t1)<512):\n","            indexed_t1.append(0)\n","        while(len(indexed_t2)<512):\n","            indexed_t2.append(0)\n","\n","        ten_t1 = torch.tensor(indexed_t1)[:512]\n","        ten_t2 = torch.tensor(indexed_t2)[:512]\n","\n","        try:\n","            sample[\"label\"] = self.label[idx]\n","            sample[\"token\"] = [ten_t1,ten_t2] # torch.Size([batch_size, 512])\n","            sample[\"tag\"] = [tag1,tag2] # Maximum no of tags in train data: 10\n","            \n","        except Exception as e:\n","            print(e)\n","        \n","        return sample\n","\n","    def __len__(self):\n","        return len(self.label)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hV30ckW6NElG"},"source":["## Train, dev and test dataloader"]},{"cell_type":"code","metadata":{"id":"qRNteBxHOomg","executionInfo":{"status":"ok","timestamp":1617269349776,"user_tz":-330,"elapsed":10667,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["train_dataset = custom_dataset(train_qr,\n","                               train_data,\n","                               train_score)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"d78ebAQBSdJI","executionInfo":{"status":"ok","timestamp":1617269349776,"user_tz":-330,"elapsed":10663,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=BATCH_SIZE,\n","    pin_memory=True,\n","    num_workers = n_worker,\n","    shuffle = True,\n","    drop_last = True\n","    )"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"IU4CNMybfgqI","executionInfo":{"status":"ok","timestamp":1617269349777,"user_tz":-330,"elapsed":10662,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["dev_dataset = custom_dataset(pd.concat([train_qr,dev_qr]),\n","                             dev_data,\n","                             dev_score)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"AUvKZ6rifxQW","executionInfo":{"status":"ok","timestamp":1617269349778,"user_tz":-330,"elapsed":10655,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["dev_loader = DataLoader(\n","    dev_dataset,\n","    batch_size=BATCH_SIZE,\n","    pin_memory=True,\n","    num_workers = n_worker,\n","    shuffle = True,\n","    drop_last = True\n","    )"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"fe1vYfiifhM2","executionInfo":{"status":"ok","timestamp":1617269349780,"user_tz":-330,"elapsed":10652,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["test_dataset = custom_dataset(pd.concat([train_qr,test_qr]),\n","                              test_data,\n","                              test_score,)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"RP_N_Kb5f1jD","executionInfo":{"status":"ok","timestamp":1617269349780,"user_tz":-330,"elapsed":10648,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=BATCH_SIZE,\n","    pin_memory=True,\n","    num_workers = n_worker,\n","    shuffle = True,\n","    drop_last = True\n","    )"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rVzPL-EMTXpM"},"source":["#Model"]},{"cell_type":"markdown","metadata":{"id":"beqWAJVP2_aP"},"source":["## Loading Model "]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Ye9P1XUUToUA","executionInfo":{"status":"ok","timestamp":1617269355783,"user_tz":-330,"elapsed":16646,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["from torchvision import models\n","\n","bert = BertModel.from_pretrained('bert-base-uncased')\n","bert = bert.to(device)\n","for param in bert.parameters():\n","    param.requires_grad = True"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TEwqX5TfdPKk"},"source":["## Model Class"]},{"cell_type":"code","metadata":{"id":"ZtngyhwHmEll","executionInfo":{"status":"ok","timestamp":1617269355790,"user_tz":-330,"elapsed":16635,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["class bertmodel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bert = bert\n","        self.LSTM = nn.LSTM(input_size=100,\n","                            hidden_size = 10,\n","                            num_layers = 2,\n","                            batch_first = True,\n","                            dropout = 0.2,\n","                            bidirectional = True)\n","        self.fc = nn.Linear(768+2*10,760)\n","    def forward(self,X1,X2):\n","        # X2 shape: [BATCH_SIZE,10,100]\n","        LSTM_out = torch.sum(self.LSTM(X2)[0],dim=1) #[BATCH_SIZE,2*hidden_size]\n","       \n","        #Taking average embeddings of all the words\n","        bert_out = torch.mean(self.bert(X1).last_hidden_state,dim=1) #[BATCH_SIZE,768]\n","\n","        out = self.fc(torch.cat((bert_out,LSTM_out),dim=1)) #[BATCH_SIZE,760]\n","        return out"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"2uH4JgQ7oVtB","executionInfo":{"status":"ok","timestamp":1617269355791,"user_tz":-330,"elapsed":16630,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["model = bertmodel().to(device)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J2Mw6eG5KqVn"},"source":["# Losses"]},{"cell_type":"markdown","metadata":{"id":"hFtpg_GR4iNJ"},"source":["## Multiple Negative Ranking loss"]},{"cell_type":"code","metadata":{"id":"xMIA3Ydod65P","executionInfo":{"status":"ok","timestamp":1617269355794,"user_tz":-330,"elapsed":16628,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["class negrankloss():\n","    def __init__(self,scale: float = 20.0):\n","        # self.cosine_sim = nn.CosineSimilarity()\n","        self.scale = scale\n","        self.cross_entropy = nn.CrossEntropyLoss()\n","\n","    def cal_loss(self,emb1: torch.Tensor,emb2: torch.Tensor, labels: torch.Tensor):\n","        scores  = pytorch_cos_sim(emb1,emb2) *self.scale\n","        # print(f'The scores of cosine similarity for MNRloss is {scores}')\n","        labels = torch.tensor(range(len(scores)), dtype=torch.long, device=scores.device)\n","        loss = self.cross_entropy(scores, labels)\n","        return loss"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"tMbsWT-DlN1G","executionInfo":{"status":"ok","timestamp":1617269355795,"user_tz":-330,"elapsed":16624,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["MNRloss = negrankloss()"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3O5iEjYD7H-s"},"source":["## Online Constrantive Loss\n"]},{"cell_type":"code","metadata":{"id":"pv3V30gQ7LKy","executionInfo":{"status":"ok","timestamp":1617269355796,"user_tz":-330,"elapsed":16622,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["class SiameseDistanceMetric(Enum):\n","    \"\"\"\n","    The metric for the contrastive loss\n","    \"\"\"\n","    EUCLIDEAN = lambda x, y: F.pairwise_distance(x, y, p=2)\n","    MANHATTAN = lambda x, y: F.pairwise_distance(x, y, p=1)\n","    COSINE_DISTANCE = lambda x, y: 1-F.cosine_similarity(x, y)\n"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zSArl7MQ4sO","executionInfo":{"status":"ok","timestamp":1617269355797,"user_tz":-330,"elapsed":16618,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["class OnlineConstrantiveLoss():\n","    def __init__(self,distance_metric=SiameseDistanceMetric.COSINE_DISTANCE,margin: float = 0.8):\n","        self.distance_metric = distance_metric\n","        self.margin = margin\n","\n","    def cal_loss(self,emb1,emb2,labels,size_average=False):\n","        distance_matrix = self.distance_metric(emb1,emb2)\n","        # print(f'distance matrix of OCloss is {distance_matrix}')\n","        negs = distance_matrix[labels == 0]\n","        poss = distance_matrix[labels == 1]\n","        # print(f'positive and negatives are {poss} and {negs}')\n","\n","        # select hard positive and hard negative pairs\n","        # But for current batch size of 1, it is impossible to consider hard positive and hard negative\n","        negative_pairs = negs[negs < (poss.max() if len(poss) > 1 else negs.mean())]\n","        positive_pairs = poss[poss > (negs.min() if len(negs) > 1 else poss.mean())]\n","\n","        negative_pairs = negs\n","        positive_pairs = poss\n","\n","        # print(f'positive and negative pairs are {positive_pairs} and {negative_pairs}')\n","\n","        positive_loss = positive_pairs.pow(2).sum()\n","        negative_loss = F.relu(self.margin - negative_pairs).pow(2).sum()\n","        # print(f'positive loss is {positive_loss} and negative loss is {negative_loss}')\n","        loss = positive_loss + negative_loss\n","        return loss\n","    "],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"cr5sO1wM8NIc","executionInfo":{"status":"ok","timestamp":1617269355797,"user_tz":-330,"elapsed":16614,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["OCloss = OnlineConstrantiveLoss(margin = margin)"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"76ht5qjQMVsm"},"source":["## Cross Entropy Loss"]},{"cell_type":"code","metadata":{"id":"iSxbp43HMVHn","executionInfo":{"status":"ok","timestamp":1617269355798,"user_tz":-330,"elapsed":16610,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["class crossentropy():\n","    def __init__(self):\n","        self.cross_entropy = nn.BCELoss()\n","        self.cos_sim =  nn.CosineSimilarity(dim=1,eps=1e-6)\n","        self.sig = nn.Sigmoid()\n","        self.BCE_with_sig = nn.BCEWithLogitsLoss()\n","    \n","    def cal_loss(self,emb1:torch.Tensor,emb2:torch.Tensor,label:torch.Tensor):\n","        sim = (self.cos_sim(emb1,emb2))\n","        sim = sim - 0.5\n","        \n","        if(use_sig == True):\n","            loss = self.BCE_with_sig(sim,label)\n","        else:\n","            sim[sim<0]=0\n","            loss = self.cross_entropy(sim,label)\n","        return loss"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"tfdnKk2HUW9X","executionInfo":{"status":"ok","timestamp":1617269355798,"user_tz":-330,"elapsed":16606,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["BCEloss = crossentropy()"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iaMPRBwZdBjN"},"source":["# Evaluators: AUC(0.05) and Binary accuracy"]},{"cell_type":"code","metadata":{"id":"mAUnsRkLdQLC","executionInfo":{"status":"ok","timestamp":1617269356373,"user_tz":-330,"elapsed":17177,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["import sklearn.metrics as skm"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"N2Z1Yk_TEPj9","executionInfo":{"status":"ok","timestamp":1617269356374,"user_tz":-330,"elapsed":17171,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["class AUC():\n","    def __init__(self,max_fpr:float = 0.05):\n","        self.max_fpr = 0.05\n","        self.cos_sim =  nn.CosineSimilarity(dim=1,eps=1e-6)\n","        self.sig = nn.Sigmoid()\n","\n","    def cal(self,model:bertmodel,loader:DataLoader):\n","        y_pred = []\n","        y_true = []\n","        y_pred_sig = []\n","        start = time.time()\n","        for i,batch in enumerate(loader):\n","            with torch.no_grad():\n","                label = batch[\"label\"]\n","                label = label.float()\n","                token = batch[\"token\"]\n","                tag = batch['tag']\n","\n","                token[0],token[1] = token[0].to(device), token[1].to(device)\n","                tag[0],tag[1] = tag[0].to(device),tag[1].to(device)\n","                label = label.to(device)\n","                \n","                # compute the model output\n","                yhat1= model(token[0],tag[0])\n","                yhat2 = model(token[1],tag[1])\n","                \n","                if(i%1000==0):\n","                    print(f'    {i} iterations have been done in {time.time()-start} seconds')\n","\n","                sim = (self.cos_sim(yhat1,yhat2))\n","                a=self.sig(sim-0.5)\n","                a[a>0.5] = 1\n","                a[a<0.5] = 0\n","\n","                y_pred_sig.append(a.cpu().numpy())\n","                y_pred.append(sim.cpu().numpy())\n","                y_true.append(label.cpu().numpy())\n","\n","                del  label, token,yhat1,yhat2,sim,a,tag \n","        \n","        y_true = np.array(y_true).flatten()\n","        y_pred = np.array(y_pred).flatten()\n","        y_pred_sig = np.array(y_pred_sig).flatten()\n","        Bin_score = skm.accuracy_score(y_true,y_pred_sig) \n","        AUC_score = skm.roc_auc_score(y_true,y_pred,max_fpr = self.max_fpr)\n","        conf_matrix = skm.confusion_matrix(y_true,y_pred_sig)\n","        plt.hist(y_pred,bins='auto')\n","        plt.show()\n","        return AUC_score,Bin_score,conf_matrix"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"CXrynrKZLn2M","executionInfo":{"status":"ok","timestamp":1617269356377,"user_tz":-330,"elapsed":17168,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["AUC_evaluator = AUC()"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mwKqXD75KiPI"},"source":["# Calculating loss and executing"]},{"cell_type":"code","metadata":{"id":"bKJz98PeGje6","executionInfo":{"status":"ok","timestamp":1617269356379,"user_tz":-330,"elapsed":17162,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["save_dir = folder + '/model_state_dict'\n","os.makedirs(save_dir,exist_ok = True)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"k5H-zwQwutgN","executionInfo":{"status":"ok","timestamp":1617269357953,"user_tz":-330,"elapsed":18728,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}}},"source":["from torch.optim import Adam\n","from torch.nn import BCELoss\n","import time\n","import copy\n","from transformers import get_linear_schedule_with_warmup\n","\n","def train_model(train_loader, model,num_epochs):\n","    model.train()\n","\n","    since = time.time()\n","\n","    optimizer = Adam(model.parameters(), lr=1e-4)\n","    train_steps = num_epochs\n","    \n","    best_acc = 0.0\n","\n","    acc_steps = fin_BATCH_SIZE/BATCH_SIZE\n","\n","    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n","\n","    # enumerate epochs\n","    for epoch in range(num_epochs):\n","        # enumerate mini batches\n","        # avg_loss = 0\n","        \n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","        \n","        running_OCloss = 0.0\n","        running_MNRloss = 0.0\n","        running_BCEloss = 0.0\n","\n","        model.zero_grad()\n","\n","        for i, batch in enumerate(train_loader):\n","\n","            with torch.cuda.amp.autocast(enabled=use_amp):\n","                \n","                if(i%5000 == 0 ):\n","                    print('Running dev_evaluator for 2000 samples i.e. 1000 iterations. Time taken: 5 min')\n","                    a,b,c = AUC_evaluator.cal(model,dev_loader)\n","                    print(f'AUC score is {a}  while binary score is {b} and the confusion matrix is {c} on dev loader after {i} iterations and {epoch+1} epoch')\n","                    torch.save(model.state_dict(), save_dir+'/bert_tag.bin')\n","                    print(f'Model is saved after {i} iterations ')\n","        \n","                label = batch[\"label\"]\n","                label = label.float()\n","                token = batch[\"token\"]\n","                tag = batch['tag']\n","\n","                token[0],token[1] = token[0].to(device), token[1].to(device)\n","                tag[0],tag[1] = tag[0].to(device),tag[1].to(device)\n","                label = label.to(device)\n","                \n","                # compute the model output\n","                yhat1= model(token[0],tag[0])\n","                yhat2 = model(token[1],tag[1])\n","\n","                # yhat1_pos = model(pos_token[0])\n","                # yhat2_pos = model(pos_token[1])\n","                \n","                BCEloss_val = BCEloss.cal_loss(yhat1,yhat2,label)\n","                running_BCEloss += BCEloss_val.item()*BATCH_SIZE\n","                BCEloss_val = BCEloss_val/acc_steps\n","\n","                # MNRloss_val = MNRloss.cal_loss(yhat1_pos,yhat2_pos)\n","                # running_MNRloss += MNRloss_val.item()*BATCH_SIZE\n","                # MNRloss_val = MNRloss_val/acc_steps\n","\n","                OCloss_val = OCloss.cal_loss(yhat1,yhat2,label)\n","                running_OCloss +=  OCloss_val.item()*BATCH_SIZE\n","                OCloss_val = OCloss_val/acc_steps\n","            \n","            scaler.scale(BCEloss_val).backward(retain_graph = True)\n","            # scaler.scale(MNRloss_val).backward(retain_graph=True)\n","            scaler.scale(OCloss_val).backward()\n","\n","            if((i+1)%acc_steps==0):\n","                scaler.step(optimizer)\n","                scaler.update()\n","                optimizer.zero_grad()\n","            \n","            if(i%1000 == 0 ):\n","                print('OCloss is {} and BCEloss is {} and MNRloss is {}  and time taken is {} after {} iterations'.format(\n","                    running_OCloss/((i+1)*BATCH_SIZE),\n","                    running_BCEloss/((i+1)*BATCH_SIZE),\n","                    running_MNRloss/(i+1)*BATCH_SIZE,\n","                    time.time()-since,\n","                    i))\n","            \n","            del OCloss_val,BCEloss_val, yhat1,yhat2, label, token\n","\n","        epoch_OC = running_OCloss / len(train_data)\n","        epoch_BCE = running_BCEloss / len(train_data)\n","        epoch_MNR = running_MNRloss / len(train_data)\n","        print(f'{epoch+1} Epoch completed. OCloss is {epoch_OC} and BCEloss is {epoch_BCE} and MNRloss is {epoch_MNR}')\n","        a,b,c = AUC_evaluator.cal(model,train_loader)\n","        print(f'AUC and Bin_acc after training {epoch+1} on train dataloader is {a,b} and confusion matrix is {c}')\n","        a,b,c = AUC_evaluator.cal(model,dev_loader)\n","        print(f'AUC and Bin_acc after training {epoch+1} on dev dataloader is {a,b} and the confusion matris is {c}')\n","        torch.save(model.state_dict(), save_dir+'/bert_tag.bin')\n","        print(f'Model is saved after {epoch+1} epochs ')\n","        \n","        "],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zXsl7QFAQ1UR"},"source":["# Training the model"]},{"cell_type":"code","metadata":{"id":"bTn1JC2a4iON"},"source":["model.load_state_dict(torch.load(save_dir+'/bert_tag.bin'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GaOYt_HqWcSO","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1617282142582,"user_tz":-330,"elapsed":8007,"user":{"displayName":"Mohit Mehta","photoUrl":"","userId":"12733328250564776512"}},"outputId":"6b3dfd6e-7058-4dbf-a6cf-e88e85d03364"},"source":["#Overall parameters in model\n","print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n","train_model(train_loader,model,5)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["110093400\n","Epoch 0/4\n","----------\n","Running dev_evaluator for 2000 samples i.e. 1000 iterations. Time taken: 5 min\n","    0 iterations have been done in 0.27336978912353516 seconds\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["AUC score is 0.50214134606771  while binary score is 0.48975409836065575 and the confusion matrix is [[ 22 466]\n"," [ 32 456]] on dev loader after 0 iterations and 1 epoch\n","Model is saved after 0 iterations \n","OCloss is 3.502629518508911 and BCEloss is 0.8194822669029236 and MNRloss is 0.0  and time taken is 34.81637096405029 after 0 iterations\n","OCloss is 0.8261481822913999 and BCEloss is 0.6197851343707486 and MNRloss is 0.0  and time taken is 1112.1236872673035 after 1000 iterations\n","OCloss is 0.7109917021630661 and BCEloss is 0.6032000619849225 and MNRloss is 0.0  and time taken is 2183.8318133354187 after 2000 iterations\n","OCloss is 0.6358804780875371 and BCEloss is 0.5922343942949034 and MNRloss is 0.0  and time taken is 3250.4796726703644 after 3000 iterations\n","1 Epoch completed. OCloss is 0.6024801759859199 and BCEloss is 0.5872575920195552 and MNRloss is 0.0\n","    0 iterations have been done in 0.1834580898284912 seconds\n","    1000 iterations have been done in 632.4556407928467 seconds\n","    2000 iterations have been done in 1263.943721294403 seconds\n","    3000 iterations have been done in 1896.960265159607 seconds\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATAUlEQVR4nO3df6zdd33f8ecLh0A3oEka13UdtzdtjTbDVMOuQlC3lTZtcNKpoWqXOSrFoGhuSzK1WifNlElh0EhhGiCqptncxcJBhSSlpbGItzSkQVGr5ocDaYiThVxCWOya+JaEFISakey9P87H7GDu9T3X99xz783n+ZCO7vd8vp9zzvt7fP26n/P5fu73pqqQJPXhJStdgCRpcgx9SeqIoS9JHTH0Jakjhr4kdeS0lS7gZM4+++yamppa6TIkaU25//77/7aq1s+1b1WH/tTUFAcPHlzpMiRpTUny5fn2Ob0jSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdWdW/kStJa8nU7ltH6vfENT+3zJXMz5G+JHXE0Jekjhj6ktQR5/QlacJGmftfrnl/R/qS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6siCoZ/k5UnuTfLXSQ4l+U+t/dwk9ySZSXJTktNb+8va/Zm2f2roud7V2h9N8ublOihJ0txGGek/B/x0Vf04sA3YnuR84P3Ah6rqx4BngMtb/8uBZ1r7h1o/kmwFdgCvAbYDv59k3TgPRpJ0cguGfg18o919absV8NPAJ1r7PuAtbfuSdp+2/4Ikae03VtVzVfUlYAY4byxHIUkayUhz+knWJXkAOAbcDnwR+FpVPd+6HAY2te1NwJMAbf+zwPcNt8/xmOHX2pXkYJKDs7Oziz8iSdK8Rgr9qnqhqrYB5zAYnf+j5SqoqvZU1XRVTa9fv365XkaSurSo1TtV9TXgTuCNwBlJjv/lrXOAI237CLAZoO3/XuCrw+1zPEaSNAGjrN5Zn+SMtv09wM8CjzAI/19q3XYCt7Tt/e0+bf+fV1W19h1tdc+5wBbg3nEdiCRpYaP8jdyNwL620uYlwM1V9akkDwM3Jvkd4HPA9a3/9cBHk8wATzNYsUNVHUpyM/Aw8DxwRVW9MN7DkSSdzIKhX1UPAq+bo/1x5lh9U1V/D/yreZ7rauDqxZcpSRoHfyNXkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZMHQT7I5yZ1JHk5yKMlvtPb3JDmS5IF2u3joMe9KMpPk0SRvHmrf3tpmkuxenkOSJM3ntBH6PA/8VlV9NskrgfuT3N72faiq/stw5yRbgR3Aa4AfBD6d5NVt97XAzwKHgfuS7K+qh8dxIJKkhS0Y+lV1FDjatr+e5BFg00kecglwY1U9B3wpyQxwXts3U1WPAyS5sfU19CVpQhY1p59kCngdcE9rujLJg0n2JjmztW0Cnhx62OHWNl/7ia+xK8nBJAdnZ2cXU54kaQEjh36SVwB/DPxmVf0dcB3wo8A2Bp8EPjCOgqpqT1VNV9X0+vXrx/GUkqRmlDl9kryUQeD/YVX9CUBVPTW0/w+AT7W7R4DNQw8/p7VxknZJ0gSMsnonwPXAI1X1waH2jUPdfgF4qG3vB3YkeVmSc4EtwL3AfcCWJOcmOZ3Byd794zkMSdIoRhnp/wTwK8DnkzzQ2n4buCzJNqCAJ4BfBaiqQ0luZnCC9nngiqp6ASDJlcBtwDpgb1UdGuOxSJIWMMrqnb8AMseuAyd5zNXA1XO0HzjZ4yRJy8vfyJWkjhj6ktQRQ1+SOmLoS1JHRlqnL0k9m9p960qXMDaO9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0JakjC4Z+ks1J7kzycJJDSX6jtZ+V5PYkj7WvZ7b2JPndJDNJHkzy+qHn2tn6P5Zk5/IdliRpLqOM9J8HfquqtgLnA1ck2QrsBu6oqi3AHe0+wEXAlnbbBVwHgx8SwFXAG4DzgKuO/6CQJE3GgqFfVUer6rNt++vAI8Am4BJgX+u2D3hL274EuKEG7gbOSLIReDNwe1U9XVXPALcD28d6NJKkk1rUnH6SKeB1wD3Ahqo62nZ9BdjQtjcBTw497HBrm6/9xNfYleRgkoOzs7OLKU+StICRQz/JK4A/Bn6zqv5ueF9VFVDjKKiq9lTVdFVNr1+/fhxPKUlqRgr9JC9lEPh/WFV/0pqfatM2tK/HWvsRYPPQw89pbfO1S5ImZJTVOwGuBx6pqg8O7doPHF+BsxO4Zaj9bW0Vz/nAs20a6DbgwiRnthO4F7Y2SdKEnDZCn58AfgX4fJIHWttvA9cANye5HPgycGnbdwC4GJgBvgm8A6Cqnk7yPuC+1u+9VfX0WI5CkjSSBUO/qv4CyDy7L5ijfwFXzPNce4G9iylQkjQ+/kauJHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JFR/jC6JL1oTe2+daVLmChH+pLUEUNfkjqyYOgn2ZvkWJKHhtrek+RIkgfa7eKhfe9KMpPk0SRvHmrf3tpmkuwe/6FIkhYyykj/I8D2Odo/VFXb2u0AQJKtwA7gNe0xv59kXZJ1wLXARcBW4LLWV5I0QQueyK2qu5JMjfh8lwA3VtVzwJeSzADntX0zVfU4QJIbW9+HF12xJOmULWVO/8okD7bpnzNb2ybgyaE+h1vbfO3fJcmuJAeTHJydnV1CeZKkE51q6F8H/CiwDTgKfGBcBVXVnqqarqrp9evXj+tpJUmc4jr9qnrq+HaSPwA+1e4eATYPdT2ntXGSdknShJzSSD/JxqG7vwAcX9mzH9iR5GVJzgW2APcC9wFbkpyb5HQGJ3v3n3rZkqRTseBIP8nHgTcBZyc5DFwFvCnJNqCAJ4BfBaiqQ0luZnCC9nngiqp6oT3PlcBtwDpgb1UdGvvRSJJOapTVO5fN0Xz9SfpfDVw9R/sB4MCiqpMkjZW/kStJHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6sgp/Y1cSVrtpnbfutIlrEqO9CWpI470teqNMmJ74pqfm0Al0trnSF+SOuJIXy8Ko87fjvKJYJzPJa02jvQlqSMLjvST7AX+JXCsql7b2s4CbgKmgCeAS6vqmSQBPgxcDHwTeHtVfbY9ZifwH9vT/k5V7RvvoUgLc0WHejfKSP8jwPYT2nYDd1TVFuCOdh/gImBLu+0CroNv/5C4CngDcB5wVZIzl1q8JGlxFhzpV9VdSaZOaL4EeFPb3gd8BvgPrf2Gqirg7iRnJNnY+t5eVU8DJLmdwQ+Sjy/5CLRmOeqWJu9U5/Q3VNXRtv0VYEPb3gQ8OdTvcGubr12SNEFLPpHbRvU1hloASLIrycEkB2dnZ8f1tJIkTj30n2rTNrSvx1r7EWDzUL9zWtt87d+lqvZU1XRVTa9fv/4Uy5MkzeVUQ38/sLNt7wRuGWp/WwbOB55t00C3ARcmObOdwL2wtUmSJmiUJZsfZ3Ai9uwkhxmswrkGuDnJ5cCXgUtb9wMMlmvOMFiy+Q6Aqno6yfuA+1q/9x4/qSutVV4eQmvRKKt3Lptn1wVz9C3ginmeZy+wd1HVSZLGysswSMvISzpotTH0tSxcgy+tTl57R5I6YuhLUkec3pG05jh9eOoMfWkVcPmnJsXpHUnqiKEvSR0x9CWpI4a+JHXEE7laFFdNSGubI31J6ogjfWmN8Do+GgdH+pLUEUNfkjpi6EtSR5zTl7RquDps+TnSl6SOONKXXmTGOVp2JdCLjyN9SeqII319m/Op0oufoS9pSfylsbXF0Jc0Lz/9vfgsKfSTPAF8HXgBeL6qppOcBdwETAFPAJdW1TNJAnwYuBj4JvD2qvrsUl5f0trhD5DVYRwncn+qqrZV1XS7vxu4o6q2AHe0+wAXAVvabRdw3RheW5K0CMuxeucSYF/b3ge8Zaj9hhq4GzgjycZleH1J0jyWGvoF/FmS+5Psam0bqupo2/4KsKFtbwKeHHrs4db2HZLsSnIwycHZ2dkllidJGrbUE7n/rKqOJPl+4PYk/2t4Z1VVklrME1bVHmAPwPT09KIeK0k6uSWFflUdaV+PJfkkcB7wVJKNVXW0Td8ca92PAJuHHn5Oa9My8wSapONOeXonyT9M8srj28CFwEPAfmBn67YTuKVt7wfeloHzgWeHpoEkSROwlJH+BuCTg5WYnAZ8rKr+Z5L7gJuTXA58Gbi09T/AYLnmDIMlm+9YwmtLkk7BKYd+VT0O/Pgc7V8FLpijvYArTvX1JElL5wXXJKkjhr4kdcTQl6SOGPqS1BFDX5I64qWV1zh/8UrSYjjSl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKt3VilX5UhaDo70Jakjhr4kdcTQl6SOGPqS1BFP5K4AT9JKWimO9CWpI4a+JHXE6Z0xctpG0mrnSF+SOmLoS1JHJj69k2Q78GFgHfDfq+qaSddwKpy6kfRiMNGRfpJ1wLXARcBW4LIkWydZgyT1bNIj/fOAmap6HCDJjcAlwMPL8WKOziXpO0069DcBTw7dPwy8YbhDkl3Arnb3G0keXcZ6zgb+dhmff1ysc/zWSq1rpU5YO7WuiTrz/iXV+cPz7Vh1Szarag+wZxKvleRgVU1P4rWWwjrHb63UulbqhLVTa+91Tnr1zhFg89D9c1qbJGkCJh369wFbkpyb5HRgB7B/wjVIUrcmOr1TVc8nuRK4jcGSzb1VdWiSNZxgItNIY2Cd47dWal0rdcLaqbXrOlNVy/G8kqRVyN/IlaSOGPqS1JGuQj/JWUluT/JY+3rmSfq+KsnhJL83yRrbay9YZ5JtSf4qyaEkDyb51xOsb3uSR5PMJNk9x/6XJbmp7b8nydSkajuhjoXq/HdJHm7v3x1J5l3bvNwWqnWo3y8mqSQrsuRwlDqTXNre10NJPjbpGofqWOjf/4eS3Jnkc+174OIVqnNvkmNJHppnf5L8bjuOB5O8fkkvWFXd3ID/DOxu27uB95+k74eBjwG/txrrBF4NbGnbPwgcBc6YQG3rgC8CPwKcDvw1sPWEPu8E/mvb3gHctALv4Sh1/hTwD9r2r69EnaPW2vq9ErgLuBuYXo11AluAzwFntvvfv1rfUwYnSn+9bW8FnlihWv8F8HrgoXn2Xwz8DyDA+cA9S3m9rkb6DC75sK9t7wPeMlenJP8U2AD82YTqOtGCdVbVF6rqsbb9N8AxYP0Eavv2pTSq6v8Axy+lMWy4/k8AFyTJBGobtmCdVXVnVX2z3b2bwe+NrIRR3lOA9wHvB/5+ksUNGaXOfwNcW1XPAFTVsQnXeNwotRbwqrb9vcDfTLC+/19E1V3A0yfpcglwQw3cDZyRZOOpvl5vob+hqo627a8wCPbvkOQlwAeAfz/Jwk6wYJ3DkpzHYDTzxeUujLkvpbFpvj5V9TzwLPB9E6htzhqaueocdjmD0dRKWLDW9pF+c1Wt5AWlRnlPXw28OslfJrm7XVV3JYxS63uAtyY5DBwA/u1kSlu0xX4vn9SquwzDUiX5NPADc+x69/Cdqqokc61XfSdwoKoOL+fgdAx1Hn+ejcBHgZ1V9X/HW2UfkrwVmAZ+cqVrmUsbiHwQePsKlzKK0xhM8byJwSenu5L8k6r62opWNbfLgI9U1QeSvBH4aJLXvtj/H73oQr+qfma+fUmeSrKxqo62sJzro+cbgX+e5J3AK4DTk3yjquY9ubZCdZLkVcCtwLvbx75JGOVSGsf7HE5yGoOPzl+dTHnfVcNxc17yI8nPMPhB+5NV9dyEajvRQrW+Engt8Jk2EPkBYH+Sn6+qgxOrcrT39DCDOedvAV9K8gUGPwTum0yJ3zZKrZcD2wGq6q+SvJzBxdhWakpqPmO9fE1v0zv7gZ1teydwy4kdquqXq+qHqmqKwRTPDeMO/BEsWGe7jMUnGdT3iQnWNsqlNIbr/yXgz6udkZqgBetM8jrgvwE/v4Jzz7BArVX1bFWdXVVT7fvybgY1TzLwF6yz+VMGo3ySnM1guufxSRbZjFLr/wYuAEjyj4GXA7MTrXI0+4G3tVU85wPPDk3/Lt5KnK1eqRuDeeU7gMeATwNntfZpBn/F68T+b2dlVu8sWCfwVuBbwANDt20Tqu9i4AsMziG8u7W9l0EQweA/zx8BM8C9wI+s0L/3QnV+Gnhq6P3bv4Lfmyet9YS+n2EFVu+M+J6GwVTUw8DngR2r9T1lsGLnLxms7HkAuHCF6vw4g9V332LwSely4NeAXxt6T69tx/H5pf7bexkGSepIb9M7ktQ1Q1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR15P8BDFOMqHnQvPUAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["AUC and Bin_acc after training 1 on train dataloader is (0.8928447198150125, 0.9186218038774937) and confusion matrix is [[12411  1825]\n"," [  492 13744]]\n","    0 iterations have been done in 0.17218470573425293 seconds\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["AUC and Bin_acc after training 1 on dev dataloader is (0.7950130582487476, 0.8319672131147541) and the confusion matris is [[385 103]\n"," [ 61 427]]\n","Model is saved after 1 epochs \n","Epoch 1/4\n","----------\n","Running dev_evaluator for 2000 samples i.e. 1000 iterations. Time taken: 5 min\n","    0 iterations have been done in 0.23876595497131348 seconds\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["AUC score is 0.7856500527153577  while binary score is 0.8329918032786885 and the confusion matrix is [[385 103]\n"," [ 60 428]] on dev loader after 0 iterations and 2 epoch\n","Model is saved after 0 iterations \n","OCloss is 0.23640665411949158 and BCEloss is 0.5477365255355835 and MNRloss is 0.0  and time taken is 6212.481514453888 after 0 iterations\n","OCloss is 0.3177899717428646 and BCEloss is 0.5389117198986012 and MNRloss is 0.0  and time taken is 7271.566233634949 after 1000 iterations\n","OCloss is 0.3139059234248555 and BCEloss is 0.5376734414558182 and MNRloss is 0.0  and time taken is 8334.346330881119 after 2000 iterations\n","OCloss is 0.31467489825314304 and BCEloss is 0.5373256875848182 and MNRloss is 0.0  and time taken is 9397.315327644348 after 3000 iterations\n","2 Epoch completed. OCloss is 0.3077168099469231 and BCEloss is 0.5357099340249394 and MNRloss is 0.0\n","    0 iterations have been done in 0.18325424194335938 seconds\n","    1000 iterations have been done in 634.4050979614258 seconds\n","    2000 iterations have been done in 1268.657087802887 seconds\n","    3000 iterations have been done in 1901.9915540218353 seconds\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["AUC and Bin_acc after training 2 on train dataloader is (0.9513486239177851, 0.9664933970216353) and confusion matrix is [[13724   512]\n"," [  442 13794]]\n","    0 iterations have been done in 0.18660187721252441 seconds\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["AUC and Bin_acc after training 2 on dev dataloader is (0.7529958172258628, 0.8555327868852459) and the confusion matris is [[425  63]\n"," [ 78 410]]\n","Model is saved after 2 epochs \n","Epoch 2/4\n","----------\n","Running dev_evaluator for 2000 samples i.e. 1000 iterations. Time taken: 5 min\n","    0 iterations have been done in 0.2032146453857422 seconds\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["AUC score is 0.7481721897201608  while binary score is 0.8463114754098361 and the confusion matrix is [[427  61]\n"," [ 89 399]] on dev loader after 0 iterations and 3 epoch\n","Model is saved after 0 iterations \n","OCloss is 0.04295306280255318 and BCEloss is 0.4404056668281555 and MNRloss is 0.0  and time taken is 12362.77722120285 after 0 iterations\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-23b827d8fff8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Overall parameters in model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-33-fab1839ff61a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, model, num_epochs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mBCEloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCEloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myhat2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0mrunning_BCEloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mBCEloss_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mBCEloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCEloss_val\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0macc_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"ZuGYeCAq97yQ"},"source":["# Evaluator"]},{"cell_type":"markdown","metadata":{"id":"kYlESuc6HmGF"},"source":["## Binary Classification Evaluator"]},{"cell_type":"code","metadata":{"id":"NJ-NKaASKXoM"},"source":["# from . import SentenceEvaluator\n","import logging\n","import os\n","import csv\n","from sklearn.metrics.pairwise import paired_cosine_distances, paired_euclidean_distances, paired_manhattan_distances\n","from sklearn.metrics import average_precision_score\n","import numpy as np\n","from typing import List\n","# from ..readers import InputExample\n","\n","\n","logger = logging.getLogger(__name__)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LWrcz7PMHlaJ"},"source":["class BinaryClassificationEvaluator():\n","    \"\"\"\n","    Evaluate a model based on the similarity of the embeddings by calculating the accuracy of identifying similar and\n","    dissimilar sentences.\n","    The metrics are the cosine similarity as well as euclidean and Manhattan distance\n","    The returned score is the accuracy with a specified metric.\n","    The results are written in a CSV. If a CSV already exists, then values are appended.\n","    The labels need to be 0 for dissimilar pairs and 1 for similar pairs.\n","    :param sentences1: The first column of sentences\n","    :param sentences2: The second column of sentences\n","    :param labels: labels[i] is the label for the pair (sentences1[i], sentences2[i]). Must be 0 or 1\n","    :param name: Name for the output\n","    :param batch_size: Batch size used to compute embeddings\n","    :param show_progress_bar: If true, prints a progress bar\n","    :param write_csv: Write results to a CSV file\n","    \"\"\"\n","\n","    def __init__(self,\n","                 dataset,\n","                 name: str = '',\n","                 batch_size: int = 32,\n","                 show_progress_bar: bool = False,\n","                 write_csv: bool = True\n","                 ):\n","        \n","        self.dataset = dataset\n","        self.labels = list()\n","        self.write_csv = write_csv\n","        self.name = name\n","        self.batch_size = batch_size\n","        self.dataloader = DataLoader(\n","            self.dataset,\n","            batch_size=self.batch_size,\n","            pin_memory=True,\n","            num_workers = 8,\n","            shuffle = True\n","        )\n","\n","        if show_progress_bar is None:\n","            show_progress_bar = (logger.getEffectiveLevel() == logging.INFO or logger.getEffectiveLevel() == logging.DEBUG)\n","        self.show_progress_bar = show_progress_bar\n","\n","        self.csv_file = \"binary_classification_evaluation\" + (\"_\"+name if name else '') + \"_results.csv\"\n","        self.csv_headers = [\"epoch\", \"steps\",\n","                            \"cosine_acc\", \"cosine_acc_threshold\", \"cosine_f1\", \"cosine_precision\", \"cosine_recall\", \"cosine_f1_threshold\", \"cosine_average_precision\",\n","                            \"manhatten_acc\", \"manhatten_acc_threshold\", \"manhatten_f1\", \"manhatten_precision\", \"manhatten_recall\", \"manhatten_f1_threshold\", \"manhatten_average_precision\",\n","                            \"eucledian_acc\", \"eucledian_acc_threshold\", \"eucledian_f1\", \"eucledian_precision\", \"eucledian_recall\", \"eucledian_f1_threshold\", \"eucledian_average_precision\"]\n","\n","\n","    # @classmethod\n","    # def from_input_examples(cls, examples: List[InputExample], **kwargs):\n","    #     sentences1 = []\n","    #     sentences2 = []\n","    #     scores = []\n","\n","    #     for example in examples:\n","    #         sentences1.append(example.texts[0])\n","    #         sentences2.append(example.texts[1])\n","    #         scores.append(example.label)\n","    #     return cls(sentences1, sentences2, scores, **kwargs)\n","\n","    def __call__(self, model, output_path: str = None, epoch: int = -1, steps: int = -1) -> float:\n","\n","        if epoch != -1:\n","            if steps == -1:\n","                out_txt = f\" after epoch {epoch}:\"\n","            else:\n","                out_txt = f\" in epoch {epoch} after {steps} steps:\"\n","        else:\n","            out_txt = \":\"\n","\n","        logger.info(\"Binary Accuracy Evaluation of the model on \" + self.name + \" dataset\" + out_txt)\n","        \n","        embeddings1 = list()\n","        embeddings2 = list()\n","\n","        with torch.no_grad():\n","            model.eval()\n","            for i, batch in enumerate(self.dataloader):\n","                images = batch[\"image\"]\n","                label = batch[\"label\"]\n","                label = label.float()\n","                token = batch[\"token\"]\n","                \n","                # print(images,label,token)\n","\n","                images[0],images[1] = images[0].to(device),images[1].to(device)\n","                token[0],token[1] = token[0].to(device), token[1].to(device)\n","                label = label.to(device)\n","                \n","                # compute the model output\n","                yhat1 = model(images[0], token[0])\n","                yhat2 = model(images[1],token[1])\n","\n","                for j in yhat1:\n","                    embeddings1.append(j.cpu().detach().numpy())\n","                for j in yhat2:\n","                    embeddings2.append(j.cpu().detach().numpy())\n","                for j in label:\n","                    self.labels.append(float(j))\n","                \n","                if(i%30==0 and i!=0):\n","                    print(f'Completed {i} iterations')\n","\n","        cosine_scores = 1-paired_cosine_distances(embeddings1, embeddings2)\n","        manhattan_distances = paired_manhattan_distances(embeddings1, embeddings2)\n","        euclidean_distances = paired_euclidean_distances(embeddings1, embeddings2)\n","\n","\n","        labels = np.asarray(self.labels)\n","\n","        file_output_data = [epoch, steps]\n","\n","        main_score = None\n","        for name, scores, reverse in [['Cosine-Similarity', cosine_scores, True], ['Manhatten-Distance', manhattan_distances, False], ['Euclidean-Distance', euclidean_distances, False]]:\n","            acc, acc_threshold = self.find_best_acc_and_threshold(scores, labels, reverse)\n","            f1, precision, recall, f1_threshold = self.find_best_f1_and_threshold(scores, labels, reverse)\n","            ap = average_precision_score(labels, scores * (1 if reverse else -1))\n","\n","            logger.info(\"Accuracy with {}:           {:.2f}\\t(Threshold: {:.4f})\".format(name, acc * 100, acc_threshold))\n","            logger.info(\"F1 with {}:                 {:.2f}\\t(Threshold: {:.4f})\".format(name, f1 * 100, f1_threshold))\n","            logger.info(\"Precision with {}:          {:.2f}\".format(name, precision * 100))\n","            logger.info(\"Recall with {}:             {:.2f}\".format(name, recall * 100))\n","            logger.info(\"Average Precision with {}:  {:.2f}\\n\".format(name, ap * 100))\n","\n","            file_output_data.extend([acc, acc_threshold, f1, precision, recall, f1_threshold, ap])\n","\n","            if main_score is None: #Use AveragePrecision with Cosine-Similarity as main score\n","                main_score = ap\n","\n","        if output_path is not None and self.write_csv:\n","            csv_path = os.path.join(output_path, self.csv_file)\n","            if not os.path.isfile(csv_path):\n","                with open(csv_path, mode=\"w\", encoding=\"utf-8\") as f:\n","                    writer = csv.writer(f)\n","                    writer.writerow(self.csv_headers)\n","                    writer.writerow(file_output_data)\n","            else:\n","                with open(csv_path, mode=\"a\", encoding=\"utf-8\") as f:\n","                    writer = csv.writer(f)\n","                    writer.writerow(file_output_data)\n","\n","        return main_score\n","\n","    @staticmethod\n","    def find_best_acc_and_threshold(scores, labels, high_score_more_similar: bool):\n","        # assert len(scores) == len(labels)\n","        rows = list(zip(scores, labels))\n","\n","        rows = sorted(rows, key=lambda x: x[0], reverse=high_score_more_similar)\n","\n","        max_acc = 0\n","        best_threshold = -1\n","\n","        positive_so_far = 0\n","        remaining_negatives = sum(labels == 0)\n","\n","        for i in range(len(rows)-1):\n","            score, label = rows[i]\n","            if label == 1:\n","                positive_so_far += 1\n","            else:\n","                remaining_negatives -= 1\n","\n","            acc = (positive_so_far + remaining_negatives) / len(labels)\n","            if acc > max_acc:\n","                max_acc = acc\n","                best_threshold = (rows[i][0] + rows[i+1][0]) / 2\n","\n","        return max_acc, best_threshold\n","\n","    @staticmethod\n","    def find_best_f1_and_threshold(scores, labels, high_score_more_similar: bool):\n","        # assert len(scores) == len(labels)\n","\n","        scores = np.asarray(scores)\n","        labels = np.asarray(labels)\n","\n","        rows = list(zip(scores, labels))\n","\n","        rows = sorted(rows, key=lambda x: x[0], reverse=high_score_more_similar)\n","\n","        best_f1 = best_precision = best_recall = 0\n","        threshold = 0\n","        nextract = 0\n","        ncorrect = 0\n","        total_num_duplicates = sum(labels)\n","\n","        for i in range(len(rows)-1):\n","            score, label = rows[i]\n","            nextract += 1\n","\n","            if label == 1:\n","                ncorrect += 1\n","\n","            if ncorrect > 0:\n","                precision = ncorrect / nextract\n","                recall = ncorrect / total_num_duplicates\n","                f1 = 2 * precision * recall / (precision + recall)\n","                if f1 > best_f1:\n","                    best_f1 = f1\n","                    best_precision = precision\n","                    best_recall = recall\n","                    threshold = (rows[i][0] + rows[i + 1][0]) / 2\n","\n","        return best_f1, best_precision, best_recall, threshold"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iSnnK9vk-U_J","colab":{"base_uri":"https://localhost:8080/","height":264},"executionInfo":{"status":"error","timestamp":1616401366324,"user_tz":-330,"elapsed":3189,"user":{"displayName":"Ticket project _CKM","photoUrl":"","userId":"12122662661545911577"}},"outputId":"8b021db4-396b-4051-9d10-7864d94937ad"},"source":["dev_BCEvaluator = BinaryClassificationEvaluator(dev_dataset,batch_size=BATCH_SIZE,show_progress_bar=True)\n","os.makedirs(folder+'/dev',exist_ok = True)\n","dev_BCEvaluator(model,output_path=folder+'/dev')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-ddab3ad768a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdev_BCEvaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/dev'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexist_ok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdev_BCEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/dev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","metadata":{"id":"pdO-HPtiEcIn"},"source":["train_BCEvaluator = BinaryClassificationEvaluator(train_dataset,batch_size=BATCH_SIZE,show_progress_bar=True)\n","os.makedirs(folder+'/train',exist_ok = True)\n","train_BCEvaluator(model,output_path=folder+'/train')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MQ3f5gO7Hhu0"},"source":["## Information retreival evaluator"]},{"cell_type":"code","metadata":{"id":"f4yW9Gn2DL9i"},"source":["import torch\n","import logging\n","from tqdm import tqdm, trange\n","import os\n","import numpy as np\n","from typing import List, Tuple, Dict, Set"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"izMNQie5XZmi"},"source":["class infodataset(Dataset):\n","    def __init__(self,qr,qr_idx,img_dir,transform = None):\n","        self.qr = qr\n","        self.qr_idx = qr_idx\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def image_adder(self,id1):\n","        img_id1 = list()\n","        if((self.qr.at[id1,'Attachments'])!=None):\n","            for i in self.qr.at[id1,'Attachments']:\n","                try:\n","                    img_path = os.path.join(self.img_dir,i)\n","                    img = Image.open(img_path).convert('RGB')\n","                    if(self.transform):\n","                        img = self.transform(img)\n","                        img.reshape(3,224,224)\n","                    img_id1.append(img)\n","                except Exception as e: \n","                    print(e)\n","        else:\n","            img_id1.append(torch.zeros(3,224,224))\n","\n","        # Work on this, for few examples, it is still saying list index out of range\n","        if(len(img_id1)==0):\n","            # print('No attachments found for id {}'.format(id1))\n","            print(f'Something went wrong with the image of id {id1}')\n","            img_id1.append(torch.zeros(3,224,224))\n","\n","        return img_id1\n","    \n","    def __getitem__(self,idx):\n","        id1 = self.qr_idx[idx]\n","        img_id1 = self.image_adder(id1)\n","\n","        # print(len(img_id1))\n","\n","        # print('Printing id1 {} and len {} and id2 {} and len {} '.format(\n","        #     id1,len(img_id1),\n","        #     id2, len(img_id2)\n","        # ))\n","\n","        # print('Printing id1 shape {} and id2  shape {}'.format(\n","        #     img_id1[0].shape,\n","        #     img_id2[0].shape\n","        # ))        \n","\n","        sample = {\n","            'image': img_id1[0]    #Currently taking only one input image\n","        }\n","\n","        t1 = '[CLS]' + self.qr.loc[id1,'Title'] + ' ' + ' '.join(self.qr.loc[id1,'Tags']) + ' ' + self.qr.loc[id1,'Text'] + '[SEP]'\n","        tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","        t1_token = tokenizer.tokenize(t1)\n","        indexed_t1 = tokenizer.convert_tokens_to_ids(t1_token)\n","        \n","        while(len(indexed_t1)<512):\n","            indexed_t1.append(0)\n","        \n","        ten_t1 = torch.tensor(indexed_t1)[:512]\n","        \n","        try:\n","            sample[\"token\"] = ten_t1 # torch.Size([batch_size, 512])\n","        except Exception as e:\n","            print(e)\n","        \n","        return sample\n","\n","    def __len__(self):\n","        return len(self.qr_idx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qhOlgHW9El3T"},"source":["class InformationRetreivalEvaluator():\n","    def __init__(self,\n","                 qr,\n","                 queries: Dict[str, str],  #qid => query\n","                 corpus: Dict[str, str],  #cid => doc\n","                 relevant_docs: Dict[str, Set[str]],  #qid => Set[cid]\n","                 corpus_chunk_size: int = 50000,\n","                 mrr_at_k: List[int] = [10],\n","                 ndcg_at_k: List[int] = [10],\n","                 accuracy_at_k: List[int] = [1, 3, 5, 10],\n","                 precision_recall_at_k: List[int] = [1, 3, 5, 10],\n","                 map_at_k: List[int] = [100],\n","                 show_progress_bar: bool = False,\n","                 batch_size: int = 32,\n","                 name: str = '',\n","                 write_csv: bool = True\n","                 ):\n","        \n","        self.qr = qr\n","        self.queries_ids = []\n","        for qid in queries:\n","            if qid in relevant_docs and len(relevant_docs[qid]) > 0:\n","                self.queries_ids.append(qid)\n","\n","        self.queries = [queries[qid] for qid in self.queries_ids]\n","\n","        self.corpus_ids = list(corpus.keys())\n","        self.corpus = [corpus[cid] for cid in self.corpus_ids]\n","\n","        self.relevant_docs = relevant_docs\n","        self.corpus_chunk_size = corpus_chunk_size\n","        self.mrr_at_k = mrr_at_k\n","        self.ndcg_at_k = ndcg_at_k\n","        self.accuracy_at_k = accuracy_at_k\n","        self.precision_recall_at_k = precision_recall_at_k\n","        self.map_at_k = map_at_k\n","\n","        self.show_progress_bar = show_progress_bar\n","        self.batch_size = batch_size\n","        self.name = name\n","        self.write_csv = write_csv\n","\n","        if name:\n","            name = \"_\" + name\n","\n","        self.csv_file: str = \"Information-Retrieval_evaluation\" + name + \"_results.csv\"\n","        self.csv_headers = [\"epoch\", \"steps\"]\n","\n","\n","        for k in accuracy_at_k:\n","            self.csv_headers.append(\"Accuracy@{}\".format(k))\n","\n","        for k in precision_recall_at_k:\n","            self.csv_headers.append(\"Precision@{}\".format(k))\n","            self.csv_headers.append(\"Recall@{}\".format(k))\n","\n","        for k in mrr_at_k:\n","            self.csv_headers.append(\"MRR@{}\".format(k))\n","\n","        for k in ndcg_at_k:\n","            self.csv_headers.append(\"NDCG@{}\".format(k))\n","\n","        for k in map_at_k:\n","            self.csv_headers.append(\"MAP@{}\".format(k))\n","    \n","    def __call__(self,model : BridgeModel,output_path: str = None,epoch: int = -1, steps: int = -1) ->float:\n","        if epoch != -1:\n","            out_txt = \" after epoch {}:\".format(epoch) if steps == -1 else \" in epoch {} after {} steps:\".format(epoch, steps)\n","        else:\n","            out_txt = \":\"\n","\n","        logger.info(\"Information Retrieval Evaluation on \" + self.name + \" dataset\" + out_txt)\n","\n","        max_k = max(max(self.mrr_at_k), max(self.ndcg_at_k), max(self.accuracy_at_k), max(self.precision_recall_at_k), max(self.map_at_k))\n","\n","        query_embeddings = self.get_embeddings(model,self.qr,self.queries_ids)\n","\n","        queries_result_list = [[] for _ in range(len(query_embeddings))]\n","\n","        itr = range(0, len(self.corpus), self.corpus_chunk_size)\n","\n","        if self.show_progress_bar:\n","            itr = tqdm(itr, desc='Corpus Chunks')\n","\n","        #Iterate over chunks of the corpus\n","        for corpus_start_idx in itr:\n","            corpus_end_idx = min(corpus_start_idx + self.corpus_chunk_size, len(self.corpus))\n","\n","            #Encode chunk of corpus\n","            sub_corpus_embeddings = self.get_embeddings(model,self.qr,self.corpus_ids[corpus_start_idx:corpus_end_idx])\n","\n","            #Compute cosine similarites\n","            cos_scores = pytorch_cos_sim(query_embeddings, sub_corpus_embeddings)\n","            del sub_corpus_embeddings\n","\n","            #Get top-k values\n","            cos_scores_top_k_values, cos_scores_top_k_idx = torch.topk(cos_scores, min(max_k, len(cos_scores[0])), dim=1, largest=True, sorted=False)\n","            cos_scores_top_k_values = cos_scores_top_k_values.cpu().tolist()\n","            cos_scores_top_k_idx = cos_scores_top_k_idx.cpu().tolist()\n","            del cos_scores\n","\n","            for query_itr in range(len(query_embeddings)):\n","                for sub_corpus_id, score in zip(cos_scores_top_k_idx[query_itr], cos_scores_top_k_values[query_itr]):\n","                    corpus_id = self.corpus_ids[corpus_start_idx+sub_corpus_id]\n","                    queries_result_list[query_itr].append({'corpus_id': corpus_id, 'score': score})\n","\n","\n","        #Compute scores\n","        scores = self.compute_metrics(queries_result_list)\n","\n","        #Output\n","        self.output_scores(scores)\n","\n","\n","        # logger.info(\"Queries: {}\".format(len(self.queries)))\n","        # logger.info(\"Corpus: {}\\n\".format(len(self.corpus)))\n","\n","        if output_path is not None and self.write_csv:\n","            csv_path = os.path.join(output_path, self.csv_file)\n","            if not os.path.isfile(csv_path):\n","                fOut = open(csv_path, mode=\"w\", encoding=\"utf-8\")\n","                fOut.write(\",\".join(self.csv_headers))\n","                fOut.write(\"\\n\")\n","\n","            else:\n","                fOut = open(csv_path, mode=\"a\", encoding=\"utf-8\")\n","\n","            output_data = [epoch, steps]\n","            for k in self.accuracy_at_k:\n","                output_data.append(scores['accuracy@k'][k])\n","\n","            for k in self.precision_recall_at_k:\n","                output_data.append(scores['precision@k'][k])\n","                output_data.append(scores['recall@k'][k])\n","\n","            for k in self.mrr_at_k:\n","                output_data.append(scores['mrr@k'][k])\n","\n","            for k in self.ndcg_at_k:\n","                output_data.append(scores['ndcg@k'][k])\n","\n","            for k in self.map_at_k:\n","                output_data.append(scores['map@k'][k])\n","\n","            fOut.write(\",\".join(map(str,output_data)))\n","            fOut.write(\"\\n\")\n","            fOut.close()\n","\n","        return scores['map@k'][max(self.map_at_k)]\n","\n","\n","    def compute_metrics(self, queries_result_list: List[object]):\n","        # Init score computation values\n","        num_hits_at_k = {k: 0 for k in self.accuracy_at_k}\n","        precisions_at_k = {k: [] for k in self.precision_recall_at_k}\n","        recall_at_k = {k: [] for k in self.precision_recall_at_k}\n","        MRR = {k: 0 for k in self.mrr_at_k}\n","        ndcg = {k: [] for k in self.ndcg_at_k}\n","        AveP_at_k = {k: [] for k in self.map_at_k}\n","\n","        # Compute scores on results\n","        for query_itr in range(len(queries_result_list)):\n","            query_id = self.queries_ids[query_itr]\n","\n","            # Sort scores\n","            top_hits = sorted(queries_result_list[query_itr], key=lambda x: x['score'], reverse=True)\n","            query_relevant_docs = self.relevant_docs[query_id]\n","\n","            # Accuracy@k - We count the result correct, if at least one relevant doc is accross the top-k documents\n","            for k_val in self.accuracy_at_k:\n","                for hit in top_hits[0:k_val]:\n","                    if hit['corpus_id'] in query_relevant_docs:\n","                        num_hits_at_k[k_val] += 1\n","                        break\n","\n","            # Precision and Recall@k\n","            for k_val in self.precision_recall_at_k:\n","                num_correct = 0\n","                for hit in top_hits[0:k_val]:\n","                    if hit['corpus_id'] in query_relevant_docs:\n","                        num_correct += 1\n","\n","                precisions_at_k[k_val].append(num_correct / k_val)\n","                recall_at_k[k_val].append(num_correct / len(query_relevant_docs))\n","\n","            # MRR@k\n","            for k_val in self.mrr_at_k:\n","                for rank, hit in enumerate(top_hits[0:k_val]):\n","                    if hit['corpus_id'] in query_relevant_docs:\n","                        MRR[k_val] += 1.0 / (rank + 1)\n","                        break\n","\n","            # NDCG@k\n","            for k_val in self.ndcg_at_k:\n","                predicted_relevance = [1 if top_hit['corpus_id'] in query_relevant_docs else 0 for top_hit in top_hits[0:k_val]]\n","                true_relevances = [1] * len(query_relevant_docs)\n","\n","                ndcg_value = self.compute_dcg_at_k(predicted_relevance, k_val) / self.compute_dcg_at_k(true_relevances, k_val)\n","                ndcg[k_val].append(ndcg_value)\n","\n","            # MAP@k\n","            for k_val in self.map_at_k:\n","                num_correct = 0\n","                sum_precisions = 0\n","\n","                for rank, hit in enumerate(top_hits[0:k_val]):\n","                    if hit['corpus_id'] in query_relevant_docs:\n","                        num_correct += 1\n","                        sum_precisions += num_correct / (rank + 1)\n","\n","                avg_precision = sum_precisions / min(k_val, len(query_relevant_docs))\n","                AveP_at_k[k_val].append(avg_precision)\n","\n","        # Compute averages\n","        for k in num_hits_at_k:\n","            num_hits_at_k[k] /= len(self.queries_ids)\n","\n","        for k in precisions_at_k:\n","            precisions_at_k[k] = np.mean(precisions_at_k[k])\n","\n","        for k in recall_at_k:\n","            recall_at_k[k] = np.mean(recall_at_k[k])\n","\n","        for k in ndcg:\n","            ndcg[k] = np.mean(ndcg[k])\n","\n","        for k in MRR:\n","            MRR[k] /= len(self.queries_ids)\n","\n","        for k in AveP_at_k:\n","            AveP_at_k[k] = np.mean(AveP_at_k[k])\n","\n","\n","        return {'accuracy@k': num_hits_at_k, 'precision@k': precisions_at_k, 'recall@k': recall_at_k, 'ndcg@k': ndcg, 'mrr@k': MRR, 'map@k': AveP_at_k}\n","\n","\n","    def output_scores(self, scores):\n","        for k in scores['accuracy@k']:\n","            logger.info(\"Accuracy@{}: {:.2f}%\".format(k, scores['accuracy@k'][k]*100))\n","\n","        for k in scores['precision@k']:\n","            logger.info(\"Precision@{}: {:.2f}%\".format(k, scores['precision@k'][k]*100))\n","\n","        for k in scores['recall@k']:\n","            logger.info(\"Recall@{}: {:.2f}%\".format(k, scores['recall@k'][k]*100))\n","\n","        for k in scores['mrr@k']:\n","            logger.info(\"MRR@{}: {:.4f}\".format(k, scores['mrr@k'][k]))\n","\n","        for k in scores['ndcg@k']:\n","            logger.info(\"NDCG@{}: {:.4f}\".format(k, scores['ndcg@k'][k]))\n","\n","        for k in scores['map@k']:\n","            logger.info(\"MAP@{}: {:.4f}\".format(k, scores['map@k'][k]))\n","\n","\n","    @staticmethod\n","    def compute_dcg_at_k(relevances, k):\n","        dcg = 0\n","        for i in range(min(len(relevances), k)):\n","            dcg += relevances[i] / np.log2(i + 2)  #+2 as we start our idx at 0\n","        return dcg\n","    \n","    def get_embeddings(self,model,qr,qr_idx):\n","        info_dataset = infodataset(qr,qr_idx,img_dir,transform = transform_pipe)\n","        info_loader = DataLoader(\n","            info_dataset,\n","            batch_size=BATCH_SIZE,\n","            pin_memory=True,\n","            num_workers = 8,\n","            )\n","        \n","        embeddings = list()\n","        since = time.time()\n","        for i,batch in enumerate(info_loader):\n","            model.eval()\n","\n","            text = batch['token']\n","            images = batch['image']\n","\n","            text,images = torch.tensor(text).to(device), torch.tensor(images).to(device)\n","\n","            with torch.no_grad():\n","                yhat = model.forward(images,text)\n","            \n","            for j in yhat:\n","                embeddings.append(j.cpu().detach().numpy())\n","            \n","            if(i%40==0):\n","                print(f'{i} iterations hase been completed, and model is running for {time.time()-since}')\n","        \n","        return embeddings\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pZFzkQT1oKEP"},"source":["with open(folder_quora+'/devinfo_100.txt','rb') as a:\n","    queries_dev = pickle.load(a)\n","    rel_docs_dev= pickle.load(a)\n","\n","with open(folder_quora+'/testinfo_100.txt','rb') as a:\n","    queries_test= pickle.load(a)\n","    rel_docs_test= pickle.load(a)\n","\n","with open(folder_quora+'/traininfo_100.txt','rb') as a:\n","    queries_train= pickle.load(a)\n","    rel_docs_train= pickle.load(a)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5XTuVNlbeF-5"},"source":["def corpus(qr):\n","    corpus = dict()\n","    for i in qr.index.values:\n","        corpus[i] = 'I dont care'\n","    return corpus"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zFwNBTJCoOS4"},"source":["train_inforet = InformationRetreivalEvaluator(train_qr,queries_train,corpus(train_qr),rel_docs_train)\n","os.makedirs(folder+'/train',exist_ok=True)\n","train_inforet(model,folder+'/train')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WktSxgTYEqg1"},"source":["dev_inforet = InformationRetreivalEvaluator(pd.concat([train_qr,dev_qr]),queries_dev,corpus(train_qr),rel_docs_dev)\n","os.makedirs(folder+'/dev',exist_ok=True)\n","dev_inforet(model,folder+'/dev')"],"execution_count":null,"outputs":[]}]}