{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"BERT_Only.ipynb","provenance":[],"collapsed_sections":["tgk_opqd2prV","xnOxcgwk5WiU","M2mT9dqsm5Vy","hV30ckW6NElG","beqWAJVP2_aP","lom9KYDHpGFM","hFtpg_GR4iNJ","3O5iEjYD7H-s","mwKqXD75KiPI","ZuGYeCAq97yQ","kYlESuc6HmGF","MQ3f5gO7Hhu0"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rXKu5-xjGwOa","executionInfo":{"status":"ok","timestamp":1617635079844,"user_tz":-330,"elapsed":1121,"user":{"displayName":"Ticket project _CKM","photoUrl":"","userId":"12122662661545911577"}},"outputId":"7a9d234d-6991-47b0-f06c-053644129777"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon Apr  5 15:04:40 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P8    34W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mz76Bz490lqB","executionInfo":{"status":"ok","timestamp":1617635103863,"user_tz":-330,"elapsed":22511,"user":{"displayName":"Ticket project _CKM","photoUrl":"","userId":"12122662661545911577"}},"outputId":"da59caf0-d8fe-4e6d-aa6c-147e37233fec"},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MIxecV2o-0qY"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"JHAMYwNfv5Th"},"source":["# Imports"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"_pwgo3m2wVQS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617635114880,"user_tz":-330,"elapsed":11008,"user":{"displayName":"Ticket project _CKM","photoUrl":"","userId":"12122662661545911577"}},"outputId":"bb92b241-da95-440b-c67d-0ebd39b7706f"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n","\u001b[K     |████████████████████████████████| 2.0MB 5.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 37.8MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n","\u001b[K     |████████████████████████████████| 870kB 37.5MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=5464dd7657315b8cf46c94636e42f7e69d39440d3dff2a35da6d7094a7ae4d09\n","  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.44 tokenizers-0.10.1 transformers-4.4.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jKIzzX6J3QtS"},"source":["import pandas as pd\n","import pickle\n","import random\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","import os\n","from enum import Enum\n","from torch.nn import functional as F\n","import time\n","import logging\n","import numpy as np\n","import math\n","from matplotlib import pyplot as plt\n","\n","logger = logging.getLogger(__name__)\n","random.seed(13)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"quJKUGIXv8zk"},"source":["# Utilities"]},{"cell_type":"code","metadata":{"id":"u1t9DLnOsFN_"},"source":["def pytorch_cos_sim(a: torch.Tensor, b: torch.Tensor):\n","    \"\"\"\n","    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n","    This function can be used as a faster replacement for 1-scipy.spatial.distance.cdist(a,b)\n","    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n","    \"\"\"\n","    if not isinstance(a, torch.Tensor):\n","        a = torch.tensor(a)\n","\n","    if not isinstance(b, torch.Tensor):\n","        b = torch.tensor(b)\n","\n","    if len(a.shape) == 1:\n","        a = a.unsqueeze(0)\n","\n","    if len(b.shape) == 1:\n","        b = b.unsqueeze(0)\n","\n","    a_norm = torch.nn.functional.normalize(a, p=2, dim=1)\n","    b_norm = torch.nn.functional.normalize(b, p=2, dim=1)\n","    return torch.mm(a_norm, b_norm.transpose(0, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DQdj5p8fzl-1"},"source":["def string_sentence(i,qr):\n","    return qr.loc[i,'Title'] + ' '  + ' '.join(qr.loc[i,'Tags']) + ' '  + qr.loc[i,'Text']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"STnKB8R7NVEa"},"source":["# Model Hyper-Parameters"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DebNqaCF2uE_","executionInfo":{"status":"ok","timestamp":1617635118575,"user_tz":-330,"elapsed":14687,"user":{"displayName":"Ticket project _CKM","photoUrl":"","userId":"12122662661545911577"}},"outputId":"80f3f059-7a3e-46a5-f1ae-562fd10ac2a9"},"source":["folder_quora = '/gdrive/MyDrive/quora_android_2'\n","folder = '/gdrive/MyDrive/Linked/Models'\n","os.makedirs(folder,exist_ok = True)\n","BATCH_SIZE = 128\n","fin_BATCH_SIZE = 32\n","n_worker = 2\n","margin = 0.8\n","\n","#---------\n","#Note that amp cannot be used without sigmoid\n","use_amp = False\n","use_sig = True\n","#----------\n","\n","use_sig_eval = False\n","# eval_BATCH_SIZE = 4 \n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tgk_opqd2prV"},"source":["# Creating Dataset and Dataloader"]},{"cell_type":"markdown","metadata":{"id":"xnOxcgwk5WiU"},"source":["###Loading Data"]},{"cell_type":"code","metadata":{"id":"N1RqPrOk5Ynm"},"source":["with open(folder_quora+'/data/splits/pandas_split.txt','rb') as a:\n","    train_qr=pickle.load(a)\n","    dev_qr = pickle.load(a)\n","    test_qr = pickle.load(a)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z5qm94QOFH2V"},"source":["with open(folder_quora+'/data/splits/train_dev_test.txt','rb') as a:\n","    train_data=pickle.load(a)\n","    train_score = pickle.load(a)\n","    dev_data = pickle.load(a)\n","    dev_score = pickle.load(a)\n","    test_data = pickle.load(a)\n","    test_score = pickle.load(a)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ik9u67jbYLXB"},"source":["with open(folder_quora+'/data/splits/data_pos_neg.txt','rb') as a:\n","    train_data_pos = pickle.load(a)\n","    train_data_neg = pickle.load(a)\n","    dev_data_pos = pickle.load(a)\n","    dev_data_neg = pickle.load(a)\n","    test_data_pos = pickle.load(a)\n","    test_data_neg = pickle.load(a)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LkaN37_BkO9P"},"source":["qr = pd.concat([train_qr,dev_qr,test_qr])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fvikTitRkXTt","executionInfo":{"status":"ok","timestamp":1617635174124,"user_tz":-330,"elapsed":1012,"user":{"displayName":"Ticket project _CKM","photoUrl":"","userId":"12122662661545911577"}},"outputId":"cac95f82-e8cf-42bf-9ab4-1dad64cd39f7"},"source":["print(qr.loc[31,'Text'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["home screen icon email . not want use default email app . use gmail use google gmail app . change icon go remove / disable app ? at&t captivate ( galaxy s ) android 2.1 \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M2mT9dqsm5Vy"},"source":["### Creating Dataset "]},{"cell_type":"code","metadata":{"id":"E6I9YioKE8uK"},"source":["from transformers import BertTokenizerFast, BertConfig,BertModel\n","config = BertConfig()\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KXPoomQx4Zby"},"source":["class custom_dataset(Dataset):\n","    def __init__(self,qr,qr_idx,label,transform = None):\n","        self.qr = qr\n","        self.qr_idx = qr_idx\n","        self.label = label\n","        self.transform = transform\n","    \n","    def __getitem__(self,idx):\n","        id1 = self.qr_idx[idx][0]\n","        id2 = self.qr_idx[idx][1]\n","\n","        sample = dict()\n","\n","        t1 = '[CLS]' + self.qr.loc[id1,'Title'] + ' ' + ' '.join(self.qr.loc[id1,'Tags']) + ' ' + self.qr.loc[id1,'Text'] + '[SEP]'\n","        t2 = '[CLS]' + self.qr.loc[id2,'Title']+ ' ' + ' '.join(self.qr.loc[id2,'Tags']) + ' ' + self.qr.loc[id2,'Text'] + '[SEP]'\n","        indexed_t1 = tokenizer.encode(t1,max_length = 512,truncation = True)\n","        indexed_t2 = tokenizer.encode(t2,max_length = 512,truncation = True)\n","\n","        while(len(indexed_t1)<512):\n","            indexed_t1.append(0)\n","        while(len(indexed_t2)<512):\n","            indexed_t2.append(0)\n","\n","        ten_t1 = torch.tensor(indexed_t1)[:512]\n","        ten_t2 = torch.tensor(indexed_t2)[:512]\n","\n","        label_cos = self.label[idx]\n","        if(label_cos==0.0):\n","            label_cos = -1.0\n","\n","        try:\n","            sample[\"label\"] = self.label[idx]\n","            sample[\"token\"] = [ten_t1,ten_t2] # torch.Size([batch_size, 512])\n","            sample[\"label_cos\"] = label_cos\n","        except Exception as e:\n","            print(e)\n","        \n","        return sample\n","\n","    def __len__(self):\n","        return len(self.label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kk3AIIM8Yk0G"},"source":["class pos_dataset(Dataset):\n","    def __init__(self,qr,qr_idx):\n","        self.qr = qr\n","        self.qr_idx = qr_idx\n","    \n","    def __getitem__(self,idx):\n","        id1 = self.qr_idx[idx][0]\n","        id2 = self.qr_idx[idx][1]\n","\n","        sample = dict()\n","\n","        t1 = '[CLS]' + self.qr.loc[id1,'Title'] + ' ' + ' '.join(self.qr.loc[id1,'Tags']) + ' ' + self.qr.loc[id1,'Text'] + '[SEP]'\n","        t2 = '[CLS]' + self.qr.loc[id2,'Title']+ ' ' + ' '.join(self.qr.loc[id2,'Tags']) + ' ' + self.qr.loc[id2,'Text'] + '[SEP]'\n","        indexed_t1 = tokenizer.encode(t1,max_length = 512,truncation = True)\n","        indexed_t2 = tokenizer.encode(t2,max_length = 512,truncation = True)\n","\n","        while(len(indexed_t1)<512):\n","            indexed_t1.append(0)\n","        while(len(indexed_t2)<512):\n","            indexed_t2.append(0)\n","\n","        ten_t1 = torch.tensor(indexed_t1)[:512]\n","        ten_t2 = torch.tensor(indexed_t2)[:512]\n","\n","        try:\n","            sample[\"token\"] = [ten_t1,ten_t2] # torch.Size([batch_size, 512])\n","        except Exception as e:\n","            print(e)\n","        \n","        return sample\n","\n","    def __len__(self):\n","        return len(self.qr_idx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eSXhMsWFZFdD"},"source":["class ConcatDataset(Dataset):\n","    def __init__(self, *datasets):\n","        self.datasets = datasets\n","\n","    def __getitem__(self, i):\n","        return tuple(d[i] for d in self.datasets)\n","\n","    def __len__(self):\n","        return min(len(d) for d in self.datasets)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hV30ckW6NElG"},"source":["## Train, dev and test dataloader"]},{"cell_type":"code","metadata":{"id":"qRNteBxHOomg"},"source":["train_dataset = custom_dataset(train_qr,\n","                               train_data,\n","                               train_score)\n","\n","# train_MNR_dataset = pos_dataset(train_qr,\n","#                                 train_data_pos)\n","\n","# fin_train_dataset = ConcatDataset(train_dataset,train_MNR_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d78ebAQBSdJI"},"source":["train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=BATCH_SIZE,\n","    pin_memory=True,\n","    num_workers = n_worker,\n","    shuffle = True,\n","    drop_last = True\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IU4CNMybfgqI"},"source":["dev_dataset = custom_dataset(pd.concat([train_qr,dev_qr]),\n","                             dev_data,\n","                             dev_score)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AUvKZ6rifxQW"},"source":["dev_loader = DataLoader(\n","    dev_dataset,\n","    batch_size=BATCH_SIZE,\n","    pin_memory=True,\n","    num_workers = n_worker,\n","    shuffle = True,\n","    drop_last = True\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fe1vYfiifhM2"},"source":["test_dataset = custom_dataset(pd.concat([train_qr,test_qr]),\n","                              test_data,\n","                              test_score)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RP_N_Kb5f1jD"},"source":["test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=BATCH_SIZE,\n","    pin_memory=True,\n","    num_workers = n_worker,\n","    shuffle = True,\n","    drop_last = True\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rVzPL-EMTXpM"},"source":["#Model"]},{"cell_type":"markdown","metadata":{"id":"beqWAJVP2_aP"},"source":["## Loading Model "]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Ye9P1XUUToUA"},"source":["from torchvision import models\n","\n","bert = BertModel.from_pretrained('bert-base-uncased')\n","bert = bert.to(device)\n","for param in bert.parameters():\n","    param.requires_grad = True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lom9KYDHpGFM"},"source":["## Model Class"]},{"cell_type":"code","metadata":{"id":"ZtngyhwHmEll"},"source":["class bertmodel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bert = bert\n","    \n","    def forward(self,X1):\n","        #Taking average embeddings of all the words\n","        bert_out = torch.mean(self.bert(X1).last_hidden_state,dim=1) #[BATCH_SIZE,768] \n","        return bert_out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2uH4JgQ7oVtB"},"source":["model = bertmodel().to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J2Mw6eG5KqVn"},"source":["# Losses"]},{"cell_type":"markdown","metadata":{"id":"hFtpg_GR4iNJ"},"source":["## Multiple Negative Ranking loss"]},{"cell_type":"code","metadata":{"id":"xMIA3Ydod65P"},"source":["class negrankloss():\n","    def __init__(self,scale: float = 20.0):\n","        # self.cosine_sim = nn.CosineSimilarity()\n","        self.scale = scale\n","        self.cross_entropy = nn.CrossEntropyLoss()\n","\n","    def cal_loss(self,emb1: torch.Tensor,emb2: torch.Tensor):\n","        scores  = pytorch_cos_sim(emb1,emb2) *self.scale\n","        # print(f'The scores of cosine similarity for MNRloss is {scores}')\n","        labels = torch.tensor(range(len(scores)), dtype=torch.long, device=scores.device)\n","        loss = self.cross_entropy(scores, labels)\n","        return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tMbsWT-DlN1G"},"source":["MNRloss = negrankloss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3O5iEjYD7H-s"},"source":["## Online Constrantive Loss\n"]},{"cell_type":"code","metadata":{"id":"pv3V30gQ7LKy"},"source":["class SiameseDistanceMetric(Enum):\n","    \"\"\"\n","    The metric for the contrastive loss\n","    \"\"\"\n","    EUCLIDEAN = lambda x, y: F.pairwise_distance(x, y, p=2)\n","    MANHATTAN = lambda x, y: F.pairwise_distance(x, y, p=1)\n","    COSINE_DISTANCE = lambda x, y: 1-F.cosine_similarity(x, y)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zSArl7MQ4sO"},"source":["class OnlineConstrantiveLoss():\n","    def __init__(self,distance_metric=SiameseDistanceMetric.COSINE_DISTANCE,margin: float = 0.8):\n","        self.distance_metric = distance_metric\n","        self.margin = margin\n","\n","    def cal_loss(self,emb1,emb2,labels,size_average=False):\n","        distance_matrix = self.distance_metric(emb1,emb2)\n","        # print(f'distance matrix of OCloss is {distance_matrix}')\n","        negs = distance_matrix[labels == 0]\n","        poss = distance_matrix[labels == 1]\n","        # print(f'positive and negatives are {poss} and {negs}')\n","\n","        # select hard positive and hard negative pairs\n","        negative_pairs = negs[negs < (poss.max() if len(poss) > 1 else negs.mean())]\n","        positive_pairs = poss[poss > (negs.min() if len(negs) > 1 else poss.mean())]\n","\n","        # print(f'positive and negative pairs are {positive_pairs} and {negative_pairs}')\n","\n","        positive_loss = positive_pairs.pow(2).sum()\n","        negative_loss = F.relu(self.margin - negative_pairs).pow(2).sum()\n","        # print(f'positive loss is {positive_loss} and negative loss is {negative_loss}')\n","        loss = positive_loss + negative_loss\n","        return loss\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cr5sO1wM8NIc"},"source":["OCloss = OnlineConstrantiveLoss(margin = margin)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"76ht5qjQMVsm"},"source":["## Cross Entropy Loss"]},{"cell_type":"code","metadata":{"id":"iSxbp43HMVHn"},"source":["class crossentropy():\n","    def __init__(self):\n","        self.cross_entropy = nn.BCELoss()\n","        self.cos_sim =  nn.CosineSimilarity(dim=1,eps=1e-6)\n","        self.sig = nn.Sigmoid()\n","        self.BCE_with_sig = nn.BCEWithLogitsLoss()\n","    \n","    def cal_loss(self,emb1:torch.Tensor,emb2:torch.Tensor,label:torch.Tensor):\n","        sim = (self.cos_sim(emb1,emb2))\n","\n","        if(use_sig == True):\n","            loss = self.BCE_with_sig(sim,label)\n","        else:\n","            sim[sim<0]=0\n","            loss = self.cross_entropy(sim,label)\n","        return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tfdnKk2HUW9X"},"source":["BCEloss = crossentropy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lQZLDcbJeYuF"},"source":["## Cosine Similarity"]},{"cell_type":"code","metadata":{"id":"E0frkfuWbpal"},"source":["class cos_sim():\n","    def __init__(self):\n","        self.cossim = nn.CosineEmbeddingLoss()\n","\n","    def cal_loss(self,emb1,emb2,target):\n","        loss = self.cossim(emb1,emb2,target)\n","        return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lKJD374XhaAI"},"source":["Cosloss = cos_sim()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iaMPRBwZdBjN"},"source":["# Evaluators: AUC(0.05) and Binary accuracy"]},{"cell_type":"code","metadata":{"id":"mAUnsRkLdQLC"},"source":["import sklearn.metrics as skm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N2Z1Yk_TEPj9"},"source":["class AUC():\n","    def __init__(self,max_fpr:float = 0.05):\n","        self.max_fpr = 0.05\n","        self.cos_sim =  nn.CosineSimilarity(dim=1,eps=1e-6)\n","        self.sig = nn.Sigmoid()\n","\n","    def cal(self,model:bertmodel,loader:DataLoader):\n","        y_pred = []\n","        y_true = []\n","        y_pred_sig = []\n","        start = time.time()\n","        for i,batch in enumerate(loader):\n","            with torch.no_grad():\n","                label = batch[\"label\"]\n","                label = label.float()\n","                token = batch[\"token\"]\n","\n","                token[0],token[1] = token[0].to(device), token[1].to(device)\n","                label = label.to(device)\n","            \n","                # compute the model output\n","                yhat1 = model(token[0])\n","                yhat2 = model(token[1])\n","\n","                if(i%1000==0):\n","                    print(f'    {i} iterations have been done in {time.time()-start} seconds')\n","\n","                sim = (self.cos_sim(yhat1,yhat2))\n","                a=self.sig(sim)\n","                a[a>0.5] = 1\n","                a[a<0.5] = 0\n","\n","                y_pred_sig.append(a.cpu().numpy())\n","                y_pred.append(sim.cpu().numpy())\n","                y_true.append(label.cpu().numpy())\n","\n","                del  label, token,yhat1,yhat2,sim,a \n","        \n","        y_true = np.array(y_true).flatten()\n","        y_pred = np.array(y_pred).flatten()\n","        y_pred_sig = np.array(y_pred_sig).flatten()\n","        y_auc = np.array(y_auc).flatten()\n","        Bin_score = skm.accuracy_score(y_true,y_pred_sig) \n","        AUC_score = skm.roc_auc_score(y_true,y_pred,max_fpr = self.max_fpr)\n","        conf_matrix = skm.confusion_matrix(y_true,y_pred_sig)\n","        plt.hist(y_pred,bins='auto')\n","        plt.show()\n","        return AUC_score,Bin_score,conf_matrix\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CXrynrKZLn2M"},"source":["AUC_evaluator = AUC()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mwKqXD75KiPI"},"source":["# Calculating loss and executing"]},{"cell_type":"code","metadata":{"id":"bKJz98PeGje6"},"source":["save_dir = folder + '/model_state_dict'\n","os.makedirs(save_dir,exist_ok = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_gc2jj5PKkGP"},"source":["from torch.optim import Adam\n","from torch.nn import BCELoss\n","import time\n","import copy\n","from transformers import get_linear_schedule_with_warmup\n","\n","def train_model(train_loader, model,num_epochs):\n","    model.train()\n","\n","    since = time.time()\n","\n","    optimizer = Adam(model.parameters(), lr=1e-4)\n","    train_steps = num_epochs\n","    \n","    best_acc = 0.0\n","\n","    acc_steps = fin_BATCH_SIZE/BATCH_SIZE\n","\n","    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n","    # torch.autograd.set_detect_anomaly(True)\n","\n","    # Evaluating on dev loader\n","    print('Running dev_evaluator for 2000 samples i.e. 1000 iterations. Time taken: 5 min')\n","    a,b,c = AUC_evaluator.cal(model,dev_loader)\n","    print(f'AUC score is {a}  while binary score is {b} and the confusion matrix is {c} on dev loader before training')\n","\n","    for epoch in range(num_epochs):\n","        # enumerate mini batches\n","        # avg_loss = 0\n","        \n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","        \n","        running_OCloss = 0.0\n","        running_MNRloss = 0.0\n","        running_BCEloss = 0.0\n","        running_Cosloss = 0.0\n","\n","        model.zero_grad()\n","\n","        for i, batch in enumerate(train_loader):\n","\n","            with torch.cuda.amp.autocast(enabled=use_amp):\n","                \n","                if(i%4000 == 0 and i!=0 ):\n","                    print('Running dev_evaluator for 2000 samples i.e. 1000 iterations. Time taken: 5 min')\n","                    a,b,c = AUC_evaluator.cal(model,dev_loader)\n","                    print(f'AUC score is {a}  while binary score is {b} and the confusion matrix is {c} on dev loader after {i} iterations and {epoch+1} epoch')\n","                    torch.save(model.state_dict(), save_dir+'/bert_cos.bin')\n","                    print(f'Model is saved after {i} iterations ')\n","        \n","                label = batch[\"label\"]\n","                label = label.float()\n","                token = batch[\"token\"]\n","                label_cos = batch['label_cos']\n","\n","                # pos_token = batch[1]['token']\n","\n","                token[0],token[1] = token[0].to(device), token[1].to(device)\n","                # pos_token[0],pos_token[1] = pos_token[0].to(device), pos_token[1].to(device)\n","                label = label.to(device)\n","                label_cos = label_cos.to(device)\n","                \n","                # compute the model output\n","                yhat1= model(token[0])\n","                yhat2 = model(token[1])\n","\n","                # yhat1_pos = model(pos_token[0])\n","                # yhat2_pos = model(pos_token[1])\n","                \n","                BCEloss_val = BCEloss.cal_loss(yhat1,yhat2,label)\n","                running_BCEloss += BCEloss_val.item()*BATCH_SIZE\n","                BCEloss_val = BCEloss_val/acc_steps\n","\n","                # MNRloss_val = MNRloss.cal_loss(yhat1_pos,yhat2_pos)\n","                # running_MNRloss += MNRloss_val.item()*BATCH_SIZE\n","                # MNRloss_val = MNRloss_val/acc_steps\n","\n","                OCloss_val = OCloss.cal_loss(yhat1,yhat2,label)\n","                running_OCloss +=  OCloss_val.item()*BATCH_SIZE\n","                OCloss_val = OCloss_val/acc_steps\n","\n","                Cosloss_val = Cosloss.cal_loss(yhat1,yhat2,label_cos)\n","                running_Cosloss += Cosloss_val.item()*BATCH_SIZE\n","                Cosloss_val = Cosloss_val/acc_steps\n","            \n","            scaler.scale(Cosloss_val).backward(retain_graph = True)\n","            scaler.scale(BCEloss_val).backward(retain_graph = True)\n","            # scaler.scale(MNRloss_val).backward(retain_graph=True)\n","            scaler.scale(OCloss_val).backward()\n","\n","            if((i+1)%acc_steps==0):\n","                scaler.step(optimizer)\n","                scaler.update()\n","                optimizer.zero_grad()\n","            \n","            if(i%500 == 0 ):\n","                print('OCloss is {} and BCEloss is {} and MNRloss is {} and Cosloss is {}  and time taken is {} after {} iterations'.format(\n","                    running_OCloss/((i+1)*BATCH_SIZE),\n","                    running_BCEloss/((i+1)*BATCH_SIZE),\n","                    running_MNRloss/(i+1)*BATCH_SIZE,\n","                    running_Cosloss/(i+1)*BATCH_SIZE,\n","                    time.time()-since,\n","                    i))\n","            \n","            del OCloss_val,BCEloss_val, yhat1,yhat2, label, token,Cosloss_val,label_cos\n","\n","        epoch_OC = running_OCloss / len(train_data)\n","        epoch_BCE = running_BCEloss / len(train_data)\n","        epoch_MNR = running_MNRloss / len(train_data)\n","        epoch_Cos = running_Cosloss/len(train_data)\n","        print(f'{epoch+1} Epoch completed. OCloss is {epoch_OC} and BCEloss is {epoch_BCE} and MNRloss is {epoch_MNR} and Cosloss is {epoch_Cos}')\n","        a,b,c = AUC_evaluator.cal(model,train_loader)\n","        print(f'AUC and Bin_acc after training {epoch+1} on train dataloader is {a,b} and confusion matrix is {c}')\n","        a,b,c = AUC_evaluator.cal(model,dev_loader)\n","        print(f'AUC and Bin_acc after training {epoch+1} on dev dataloader is {a,b} and the confusion matris is {c}')\n","        torch.save(model.state_dict(), save_dir+'/bert_cos.bin')\n","        print(f'Model is saved after {epoch+1} epochs ')\n","        \n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5AqQUAXTDy7f"},"source":["# model.load_state_dict(torch.load(folder+'/model.bin'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0qdEeWYIKgbK"},"source":["# os.makedirs('./model',exist_ok=True)\n","# torch.save(model.state_dict(), '/gdrive/MyDrive/MultiModal/model.bin')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zXsl7QFAQ1UR"},"source":["# Training the model"]},{"cell_type":"code","metadata":{"id":"G2cb3syg4xdu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617625082392,"user_tz":-330,"elapsed":22302,"user":{"displayName":"Ticket project _CKM","photoUrl":"","userId":"12122662661545911577"}},"outputId":"cd88008c-918e-432e-9b4d-14600d6a2a25"},"source":["model.load_state_dict(torch.load(save_dir+'/bert_cos.bin'))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":325},"id":"wQr7U7ei7y1Z","executionInfo":{"status":"error","timestamp":1617626047806,"user_tz":-330,"elapsed":987713,"user":{"displayName":"Ticket project _CKM","photoUrl":"","userId":"12122662661545911577"}},"outputId":"576475ac-574f-4322-e250-3607655d07f2"},"source":["AUC_evaluator.cal(model,train_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["    0 iterations have been done in 0.5002717971801758 seconds\n"],"name":"stdout"},{"output_type":"error","ename":"UnboundLocalError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-7a20d620f272>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAUC_evaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-34-662dc1c8acb2>\u001b[0m in \u001b[0;36mcal\u001b[0;34m(self, model, loader)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0my_pred_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_sig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0my_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mBin_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_sig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mAUC_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_fpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_fpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'y_auc' referenced before assignment"]}]},{"cell_type":"code","metadata":{"id":"SKL9faXs768D"},"source":["AUC_evaluator.cal(model,dev_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GaOYt_HqWcSO","colab":{"base_uri":"https://localhost:8080/","height":963},"outputId":"070dd62b-789d-46ad-9c8c-ab3bd0d9c213"},"source":["#Overall parameters in model\n","print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n","train_model(train_loader,model,5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["109482240\n","Running dev_evaluator for 2000 samples i.e. 1000 iterations. Time taken: 5 min\n","    0 iterations have been done in 0.31961774826049805 seconds\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["AUC score is 0.5037090250070632  while binary score is 0.5 and the confusion matrix is [[  0 488]\n"," [  0 488]] on dev loader before training\n","Epoch 0/4\n","----------\n","OCloss is 1.2373502254486084 and BCEloss is 1.3003754615783691 and MNRloss is 0.0 and Cosloss is 15.717244148254395  and time taken is 74.41431951522827 after 0 iterations\n","OCloss is 0.474021737388021 and BCEloss is 0.7216411588077773 and MNRloss is 0.0 and Cosloss is 6.934771479246859  and time taken is 1370.6295444965363 after 500 iterations\n","OCloss is 0.3771525548000426 and BCEloss is 0.6822808179762456 and MNRloss is 0.0 and Cosloss is 5.993706772734711  and time taken is 2658.891426086426 after 1000 iterations\n","OCloss is 0.3471635688902924 and BCEloss is 0.6697300540098423 and MNRloss is 0.0 and Cosloss is 5.601141032801915  and time taken is 3945.9590888023376 after 1500 iterations\n","OCloss is 0.3216458582849692 and BCEloss is 0.6551029457562212 and MNRloss is 0.0 and Cosloss is 5.250447229247192  and time taken is 5230.5720982551575 after 2000 iterations\n","OCloss is 0.3070995084050549 and BCEloss is 0.6455851385637266 and MNRloss is 0.0 and Cosloss is 4.991375629426312  and time taken is 6513.520419359207 after 2500 iterations\n","OCloss is 0.29764294673508473 and BCEloss is 0.6396604560983455 and MNRloss is 0.0 and Cosloss is 4.8442964843241265  and time taken is 7798.304127931595 after 3000 iterations\n","OCloss is 0.28733878771988863 and BCEloss is 0.6331146901861254 and MNRloss is 0.0 and Cosloss is 4.6655016564613785  and time taken is 9075.767461299896 after 3500 iterations\n","Running dev_evaluator for 2000 samples i.e. 1000 iterations. Time taken: 5 min\n","    0 iterations have been done in 0.14265751838684082 seconds\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["AUC score is 0.744476946505971  while binary score is 0.5819672131147541 and the confusion matrix is [[ 80 408]\n"," [  0 488]] on dev loader after 4000 iterations and 1 epoch\n","Model is saved after 4000 iterations \n","OCloss is 0.2791523764712039 and BCEloss is 0.6274350649623447 and MNRloss is 0.0 and Cosloss is 4.5336787026264735  and time taken is 10434.50796365738 after 4000 iterations\n","OCloss is 0.2723358069557262 and BCEloss is 0.6225236832459909 and MNRloss is 0.0 and Cosloss is 4.431445810034245  and time taken is 11719.019290685654 after 4500 iterations\n","OCloss is 0.2652614910366243 and BCEloss is 0.6184436633595941 and MNRloss is 0.0 and Cosloss is 4.32826463081996  and time taken is 12998.897641658783 after 5000 iterations\n","OCloss is 0.2565339907552332 and BCEloss is 0.6135568903849529 and MNRloss is 0.0 and Cosloss is 4.22062945460985  and time taken is 14277.86932849884 after 5500 iterations\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZuGYeCAq97yQ"},"source":["# Evaluator"]},{"cell_type":"markdown","metadata":{"id":"kYlESuc6HmGF"},"source":["## Binary Classification Evaluator"]},{"cell_type":"code","metadata":{"id":"NJ-NKaASKXoM"},"source":["# from . import SentenceEvaluator\n","import logging\n","import os\n","import csv\n","from sklearn.metrics.pairwise import paired_cosine_distances, paired_euclidean_distances, paired_manhattan_distances\n","from sklearn.metrics import average_precision_score\n","import numpy as np\n","from typing import List\n","# from ..readers import InputExample\n","\n","\n","logger = logging.getLogger(__name__)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LWrcz7PMHlaJ"},"source":["class BinaryClassificationEvaluator():\n","    \"\"\"\n","    Evaluate a model based on the similarity of the embeddings by calculating the accuracy of identifying similar and\n","    dissimilar sentences.\n","    The metrics are the cosine similarity as well as euclidean and Manhattan distance\n","    The returned score is the accuracy with a specified metric.\n","    The results are written in a CSV. If a CSV already exists, then values are appended.\n","    The labels need to be 0 for dissimilar pairs and 1 for similar pairs.\n","    :param sentences1: The first column of sentences\n","    :param sentences2: The second column of sentences\n","    :param labels: labels[i] is the label for the pair (sentences1[i], sentences2[i]). Must be 0 or 1\n","    :param name: Name for the output\n","    :param batch_size: Batch size used to compute embeddings\n","    :param show_progress_bar: If true, prints a progress bar\n","    :param write_csv: Write results to a CSV file\n","    \"\"\"\n","\n","    def __init__(self,\n","                 dataset,\n","                 name: str = '',\n","                 batch_size: int = 32,\n","                 show_progress_bar: bool = False,\n","                 write_csv: bool = True\n","                 ):\n","        \n","        self.dataset = dataset\n","        self.labels = list()\n","        self.write_csv = write_csv\n","        self.name = name\n","        self.batch_size = batch_size\n","        self.dataloader = DataLoader(\n","            self.dataset,\n","            batch_size=self.batch_size,\n","            pin_memory=True,\n","            num_workers = 8,\n","            shuffle = True\n","        )\n","\n","        if show_progress_bar is None:\n","            show_progress_bar = (logger.getEffectiveLevel() == logging.INFO or logger.getEffectiveLevel() == logging.DEBUG)\n","        self.show_progress_bar = show_progress_bar\n","\n","        self.csv_file = \"binary_classification_evaluation\" + (\"_\"+name if name else '') + \"_results.csv\"\n","        self.csv_headers = [\"epoch\", \"steps\",\n","                            \"cosine_acc\", \"cosine_acc_threshold\", \"cosine_f1\", \"cosine_precision\", \"cosine_recall\", \"cosine_f1_threshold\", \"cosine_average_precision\",\n","                            \"manhatten_acc\", \"manhatten_acc_threshold\", \"manhatten_f1\", \"manhatten_precision\", \"manhatten_recall\", \"manhatten_f1_threshold\", \"manhatten_average_precision\",\n","                            \"eucledian_acc\", \"eucledian_acc_threshold\", \"eucledian_f1\", \"eucledian_precision\", \"eucledian_recall\", \"eucledian_f1_threshold\", \"eucledian_average_precision\"]\n","\n","\n","    # @classmethod\n","    # def from_input_examples(cls, examples: List[InputExample], **kwargs):\n","    #     sentences1 = []\n","    #     sentences2 = []\n","    #     scores = []\n","\n","    #     for example in examples:\n","    #         sentences1.append(example.texts[0])\n","    #         sentences2.append(example.texts[1])\n","    #         scores.append(example.label)\n","    #     return cls(sentences1, sentences2, scores, **kwargs)\n","\n","    def __call__(self, model, output_path: str = None, epoch: int = -1, steps: int = -1) -> float:\n","\n","        if epoch != -1:\n","            if steps == -1:\n","                out_txt = f\" after epoch {epoch}:\"\n","            else:\n","                out_txt = f\" in epoch {epoch} after {steps} steps:\"\n","        else:\n","            out_txt = \":\"\n","\n","        logger.info(\"Binary Accuracy Evaluation of the model on \" + self.name + \" dataset\" + out_txt)\n","        \n","        embeddings1 = list()\n","        embeddings2 = list()\n","\n","        with torch.no_grad():\n","            model.eval()\n","            for i, batch in enumerate(self.dataloader):\n","                images = batch[\"image\"]\n","                label = batch[\"label\"]\n","                label = label.float()\n","                token = batch[\"token\"]\n","                \n","                # print(images,label,token)\n","\n","                images[0],images[1] = images[0].to(device),images[1].to(device)\n","                token[0],token[1] = token[0].to(device), token[1].to(device)\n","                label = label.to(device)\n","                \n","                # compute the model output\n","                yhat1 = model(images[0], token[0])\n","                yhat2 = model(images[1],token[1])\n","\n","                for j in yhat1:\n","                    embeddings1.append(j.cpu().detach().numpy())\n","                for j in yhat2:\n","                    embeddings2.append(j.cpu().detach().numpy())\n","                for j in label:\n","                    self.labels.append(float(j))\n","                \n","                if(i%30==0 and i!=0):\n","                    print(f'Completed {i} iterations')\n","\n","        cosine_scores = 1-paired_cosine_distances(embeddings1, embeddings2)\n","        manhattan_distances = paired_manhattan_distances(embeddings1, embeddings2)\n","        euclidean_distances = paired_euclidean_distances(embeddings1, embeddings2)\n","\n","\n","        labels = np.asarray(self.labels)\n","\n","        file_output_data = [epoch, steps]\n","\n","        main_score = None\n","        for name, scores, reverse in [['Cosine-Similarity', cosine_scores, True], ['Manhatten-Distance', manhattan_distances, False], ['Euclidean-Distance', euclidean_distances, False]]:\n","            acc, acc_threshold = self.find_best_acc_and_threshold(scores, labels, reverse)\n","            f1, precision, recall, f1_threshold = self.find_best_f1_and_threshold(scores, labels, reverse)\n","            ap = average_precision_score(labels, scores * (1 if reverse else -1))\n","\n","            logger.info(\"Accuracy with {}:           {:.2f}\\t(Threshold: {:.4f})\".format(name, acc * 100, acc_threshold))\n","            logger.info(\"F1 with {}:                 {:.2f}\\t(Threshold: {:.4f})\".format(name, f1 * 100, f1_threshold))\n","            logger.info(\"Precision with {}:          {:.2f}\".format(name, precision * 100))\n","            logger.info(\"Recall with {}:             {:.2f}\".format(name, recall * 100))\n","            logger.info(\"Average Precision with {}:  {:.2f}\\n\".format(name, ap * 100))\n","\n","            file_output_data.extend([acc, acc_threshold, f1, precision, recall, f1_threshold, ap])\n","\n","            if main_score is None: #Use AveragePrecision with Cosine-Similarity as main score\n","                main_score = ap\n","\n","        if output_path is not None and self.write_csv:\n","            csv_path = os.path.join(output_path, self.csv_file)\n","            if not os.path.isfile(csv_path):\n","                with open(csv_path, mode=\"w\", encoding=\"utf-8\") as f:\n","                    writer = csv.writer(f)\n","                    writer.writerow(self.csv_headers)\n","                    writer.writerow(file_output_data)\n","            else:\n","                with open(csv_path, mode=\"a\", encoding=\"utf-8\") as f:\n","                    writer = csv.writer(f)\n","                    writer.writerow(file_output_data)\n","\n","        return main_score\n","\n","    @staticmethod\n","    def find_best_acc_and_threshold(scores, labels, high_score_more_similar: bool):\n","        # assert len(scores) == len(labels)\n","        rows = list(zip(scores, labels))\n","\n","        rows = sorted(rows, key=lambda x: x[0], reverse=high_score_more_similar)\n","\n","        max_acc = 0\n","        best_threshold = -1\n","\n","        positive_so_far = 0\n","        remaining_negatives = sum(labels == 0)\n","\n","        for i in range(len(rows)-1):\n","            score, label = rows[i]\n","            if label == 1:\n","                positive_so_far += 1\n","            else:\n","                remaining_negatives -= 1\n","\n","            acc = (positive_so_far + remaining_negatives) / len(labels)\n","            if acc > max_acc:\n","                max_acc = acc\n","                best_threshold = (rows[i][0] + rows[i+1][0]) / 2\n","\n","        return max_acc, best_threshold\n","\n","    @staticmethod\n","    def find_best_f1_and_threshold(scores, labels, high_score_more_similar: bool):\n","        # assert len(scores) == len(labels)\n","\n","        scores = np.asarray(scores)\n","        labels = np.asarray(labels)\n","\n","        rows = list(zip(scores, labels))\n","\n","        rows = sorted(rows, key=lambda x: x[0], reverse=high_score_more_similar)\n","\n","        best_f1 = best_precision = best_recall = 0\n","        threshold = 0\n","        nextract = 0\n","        ncorrect = 0\n","        total_num_duplicates = sum(labels)\n","\n","        for i in range(len(rows)-1):\n","            score, label = rows[i]\n","            nextract += 1\n","\n","            if label == 1:\n","                ncorrect += 1\n","\n","            if ncorrect > 0:\n","                precision = ncorrect / nextract\n","                recall = ncorrect / total_num_duplicates\n","                f1 = 2 * precision * recall / (precision + recall)\n","                if f1 > best_f1:\n","                    best_f1 = f1\n","                    best_precision = precision\n","                    best_recall = recall\n","                    threshold = (rows[i][0] + rows[i + 1][0]) / 2\n","\n","        return best_f1, best_precision, best_recall, threshold"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iSnnK9vk-U_J","colab":{"base_uri":"https://localhost:8080/","height":213},"executionInfo":{"status":"error","timestamp":1617284523636,"user_tz":-330,"elapsed":2164,"user":{"displayName":"MOHIT MEHTA","photoUrl":"","userId":"00949415454628222481"}},"outputId":"9e5c6720-05cb-4df4-e247-40e73e13d6cc"},"source":["dev_BCEvaluator = BinaryClassificationEvaluator(dev_dataset,batch_size=BATCH_SIZE,show_progress_bar=True)\n","os.makedirs(folder+'/dev',exist_ok = True)\n","dev_BCEvaluator(model,output_path=folder+'/dev')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-ddab3ad768a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdev_BCEvaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryClassificationEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/dev'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexist_ok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdev_BCEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/dev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dev_dataset' is not defined"]}]},{"cell_type":"code","metadata":{"id":"pdO-HPtiEcIn"},"source":["train_BCEvaluator = BinaryClassificationEvaluator(train_dataset,batch_size=BATCH_SIZE,show_progress_bar=True)\n","os.makedirs(folder+'/train',exist_ok = True)\n","train_BCEvaluator(model,output_path=folder+'/train')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MQ3f5gO7Hhu0"},"source":["## Information retreival evaluator"]},{"cell_type":"code","metadata":{"id":"f4yW9Gn2DL9i"},"source":["import torch\n","import logging\n","from tqdm import tqdm, trange\n","import os\n","import numpy as np\n","from typing import List, Tuple, Dict, Set"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"izMNQie5XZmi"},"source":["class infodataset(Dataset):\n","    def __init__(self,qr,qr_idx,img_dir,transform = None):\n","        self.qr = qr\n","        self.qr_idx = qr_idx\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def image_adder(self,id1):\n","        img_id1 = list()\n","        if((self.qr.at[id1,'Attachments'])!=None):\n","            for i in self.qr.at[id1,'Attachments']:\n","                try:\n","                    img_path = os.path.join(self.img_dir,i)\n","                    img = Image.open(img_path).convert('RGB')\n","                    if(self.transform):\n","                        img = self.transform(img)\n","                        img.reshape(3,224,224)\n","                    img_id1.append(img)\n","                except Exception as e: \n","                    print(e)\n","        else:\n","            img_id1.append(torch.zeros(3,224,224))\n","\n","        # Work on this, for few examples, it is still saying list index out of range\n","        if(len(img_id1)==0):\n","            # print('No attachments found for id {}'.format(id1))\n","            print(f'Something went wrong with the image of id {id1}')\n","            img_id1.append(torch.zeros(3,224,224))\n","\n","        return img_id1\n","    \n","    def __getitem__(self,idx):\n","        id1 = self.qr_idx[idx]\n","        img_id1 = self.image_adder(id1)\n","\n","        # print(len(img_id1))\n","\n","        # print('Printing id1 {} and len {} and id2 {} and len {} '.format(\n","        #     id1,len(img_id1),\n","        #     id2, len(img_id2)\n","        # ))\n","\n","        # print('Printing id1 shape {} and id2  shape {}'.format(\n","        #     img_id1[0].shape,\n","        #     img_id2[0].shape\n","        # ))        \n","\n","        sample = {\n","            'image': img_id1[0]    #Currently taking only one input image\n","        }\n","\n","        t1 = '[CLS]' + self.qr.loc[id1,'Title'] + ' ' + ' '.join(self.qr.loc[id1,'Tags']) + ' ' + self.qr.loc[id1,'Text'] + '[SEP]'\n","        tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","        t1_token = tokenizer.tokenize(t1)\n","        indexed_t1 = tokenizer.convert_tokens_to_ids(t1_token)\n","        \n","        while(len(indexed_t1)<512):\n","            indexed_t1.append(0)\n","        \n","        ten_t1 = torch.tensor(indexed_t1)[:512]\n","        \n","        try:\n","            sample[\"token\"] = ten_t1 # torch.Size([batch_size, 512])\n","        except Exception as e:\n","            print(e)\n","        \n","        return sample\n","\n","    def __len__(self):\n","        return len(self.qr_idx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qhOlgHW9El3T"},"source":["class InformationRetreivalEvaluator():\n","    def __init__(self,\n","                 qr,\n","                 queries: Dict[str, str],  #qid => query\n","                 corpus: Dict[str, str],  #cid => doc\n","                 relevant_docs: Dict[str, Set[str]],  #qid => Set[cid]\n","                 corpus_chunk_size: int = 50000,\n","                 mrr_at_k: List[int] = [10],\n","                 ndcg_at_k: List[int] = [10],\n","                 accuracy_at_k: List[int] = [1, 3, 5, 10],\n","                 precision_recall_at_k: List[int] = [1, 3, 5, 10],\n","                 map_at_k: List[int] = [100],\n","                 show_progress_bar: bool = False,\n","                 batch_size: int = 32,\n","                 name: str = '',\n","                 write_csv: bool = True\n","                 ):\n","        \n","        self.qr = qr\n","        self.queries_ids = []\n","        for qid in queries:\n","            if qid in relevant_docs and len(relevant_docs[qid]) > 0:\n","                self.queries_ids.append(qid)\n","\n","        self.queries = [queries[qid] for qid in self.queries_ids]\n","\n","        self.corpus_ids = list(corpus.keys())\n","        self.corpus = [corpus[cid] for cid in self.corpus_ids]\n","\n","        self.relevant_docs = relevant_docs\n","        self.corpus_chunk_size = corpus_chunk_size\n","        self.mrr_at_k = mrr_at_k\n","        self.ndcg_at_k = ndcg_at_k\n","        self.accuracy_at_k = accuracy_at_k\n","        self.precision_recall_at_k = precision_recall_at_k\n","        self.map_at_k = map_at_k\n","\n","        self.show_progress_bar = show_progress_bar\n","        self.batch_size = batch_size\n","        self.name = name\n","        self.write_csv = write_csv\n","\n","        if name:\n","            name = \"_\" + name\n","\n","        self.csv_file: str = \"Information-Retrieval_evaluation\" + name + \"_results.csv\"\n","        self.csv_headers = [\"epoch\", \"steps\"]\n","\n","\n","        for k in accuracy_at_k:\n","            self.csv_headers.append(\"Accuracy@{}\".format(k))\n","\n","        for k in precision_recall_at_k:\n","            self.csv_headers.append(\"Precision@{}\".format(k))\n","            self.csv_headers.append(\"Recall@{}\".format(k))\n","\n","        for k in mrr_at_k:\n","            self.csv_headers.append(\"MRR@{}\".format(k))\n","\n","        for k in ndcg_at_k:\n","            self.csv_headers.append(\"NDCG@{}\".format(k))\n","\n","        for k in map_at_k:\n","            self.csv_headers.append(\"MAP@{}\".format(k))\n","    \n","    def __call__(self,model : BridgeModel,output_path: str = None,epoch: int = -1, steps: int = -1) ->float:\n","        if epoch != -1:\n","            out_txt = \" after epoch {}:\".format(epoch) if steps == -1 else \" in epoch {} after {} steps:\".format(epoch, steps)\n","        else:\n","            out_txt = \":\"\n","\n","        logger.info(\"Information Retrieval Evaluation on \" + self.name + \" dataset\" + out_txt)\n","\n","        max_k = max(max(self.mrr_at_k), max(self.ndcg_at_k), max(self.accuracy_at_k), max(self.precision_recall_at_k), max(self.map_at_k))\n","\n","        query_embeddings = self.get_embeddings(model,self.qr,self.queries_ids)\n","\n","        queries_result_list = [[] for _ in range(len(query_embeddings))]\n","\n","        itr = range(0, len(self.corpus), self.corpus_chunk_size)\n","\n","        if self.show_progress_bar:\n","            itr = tqdm(itr, desc='Corpus Chunks')\n","\n","        #Iterate over chunks of the corpus\n","        for corpus_start_idx in itr:\n","            corpus_end_idx = min(corpus_start_idx + self.corpus_chunk_size, len(self.corpus))\n","\n","            #Encode chunk of corpus\n","            sub_corpus_embeddings = self.get_embeddings(model,self.qr,self.corpus_ids[corpus_start_idx:corpus_end_idx])\n","\n","            #Compute cosine similarites\n","            cos_scores = pytorch_cos_sim(query_embeddings, sub_corpus_embeddings)\n","            del sub_corpus_embeddings\n","\n","            #Get top-k values\n","            cos_scores_top_k_values, cos_scores_top_k_idx = torch.topk(cos_scores, min(max_k, len(cos_scores[0])), dim=1, largest=True, sorted=False)\n","            cos_scores_top_k_values = cos_scores_top_k_values.cpu().tolist()\n","            cos_scores_top_k_idx = cos_scores_top_k_idx.cpu().tolist()\n","            del cos_scores\n","\n","            for query_itr in range(len(query_embeddings)):\n","                for sub_corpus_id, score in zip(cos_scores_top_k_idx[query_itr], cos_scores_top_k_values[query_itr]):\n","                    corpus_id = self.corpus_ids[corpus_start_idx+sub_corpus_id]\n","                    queries_result_list[query_itr].append({'corpus_id': corpus_id, 'score': score})\n","\n","\n","        #Compute scores\n","        scores = self.compute_metrics(queries_result_list)\n","\n","        #Output\n","        self.output_scores(scores)\n","\n","\n","        # logger.info(\"Queries: {}\".format(len(self.queries)))\n","        # logger.info(\"Corpus: {}\\n\".format(len(self.corpus)))\n","\n","        if output_path is not None and self.write_csv:\n","            csv_path = os.path.join(output_path, self.csv_file)\n","            if not os.path.isfile(csv_path):\n","                fOut = open(csv_path, mode=\"w\", encoding=\"utf-8\")\n","                fOut.write(\",\".join(self.csv_headers))\n","                fOut.write(\"\\n\")\n","\n","            else:\n","                fOut = open(csv_path, mode=\"a\", encoding=\"utf-8\")\n","\n","            output_data = [epoch, steps]\n","            for k in self.accuracy_at_k:\n","                output_data.append(scores['accuracy@k'][k])\n","\n","            for k in self.precision_recall_at_k:\n","                output_data.append(scores['precision@k'][k])\n","                output_data.append(scores['recall@k'][k])\n","\n","            for k in self.mrr_at_k:\n","                output_data.append(scores['mrr@k'][k])\n","\n","            for k in self.ndcg_at_k:\n","                output_data.append(scores['ndcg@k'][k])\n","\n","            for k in self.map_at_k:\n","                output_data.append(scores['map@k'][k])\n","\n","            fOut.write(\",\".join(map(str,output_data)))\n","            fOut.write(\"\\n\")\n","            fOut.close()\n","\n","        return scores['map@k'][max(self.map_at_k)]\n","\n","\n","    def compute_metrics(self, queries_result_list: List[object]):\n","        # Init score computation values\n","        num_hits_at_k = {k: 0 for k in self.accuracy_at_k}\n","        precisions_at_k = {k: [] for k in self.precision_recall_at_k}\n","        recall_at_k = {k: [] for k in self.precision_recall_at_k}\n","        MRR = {k: 0 for k in self.mrr_at_k}\n","        ndcg = {k: [] for k in self.ndcg_at_k}\n","        AveP_at_k = {k: [] for k in self.map_at_k}\n","\n","        # Compute scores on results\n","        for query_itr in range(len(queries_result_list)):\n","            query_id = self.queries_ids[query_itr]\n","\n","            # Sort scores\n","            top_hits = sorted(queries_result_list[query_itr], key=lambda x: x['score'], reverse=True)\n","            query_relevant_docs = self.relevant_docs[query_id]\n","\n","            # Accuracy@k - We count the result correct, if at least one relevant doc is accross the top-k documents\n","            for k_val in self.accuracy_at_k:\n","                for hit in top_hits[0:k_val]:\n","                    if hit['corpus_id'] in query_relevant_docs:\n","                        num_hits_at_k[k_val] += 1\n","                        break\n","\n","            # Precision and Recall@k\n","            for k_val in self.precision_recall_at_k:\n","                num_correct = 0\n","                for hit in top_hits[0:k_val]:\n","                    if hit['corpus_id'] in query_relevant_docs:\n","                        num_correct += 1\n","\n","                precisions_at_k[k_val].append(num_correct / k_val)\n","                recall_at_k[k_val].append(num_correct / len(query_relevant_docs))\n","\n","            # MRR@k\n","            for k_val in self.mrr_at_k:\n","                for rank, hit in enumerate(top_hits[0:k_val]):\n","                    if hit['corpus_id'] in query_relevant_docs:\n","                        MRR[k_val] += 1.0 / (rank + 1)\n","                        break\n","\n","            # NDCG@k\n","            for k_val in self.ndcg_at_k:\n","                predicted_relevance = [1 if top_hit['corpus_id'] in query_relevant_docs else 0 for top_hit in top_hits[0:k_val]]\n","                true_relevances = [1] * len(query_relevant_docs)\n","\n","                ndcg_value = self.compute_dcg_at_k(predicted_relevance, k_val) / self.compute_dcg_at_k(true_relevances, k_val)\n","                ndcg[k_val].append(ndcg_value)\n","\n","            # MAP@k\n","            for k_val in self.map_at_k:\n","                num_correct = 0\n","                sum_precisions = 0\n","\n","                for rank, hit in enumerate(top_hits[0:k_val]):\n","                    if hit['corpus_id'] in query_relevant_docs:\n","                        num_correct += 1\n","                        sum_precisions += num_correct / (rank + 1)\n","\n","                avg_precision = sum_precisions / min(k_val, len(query_relevant_docs))\n","                AveP_at_k[k_val].append(avg_precision)\n","\n","        # Compute averages\n","        for k in num_hits_at_k:\n","            num_hits_at_k[k] /= len(self.queries_ids)\n","\n","        for k in precisions_at_k:\n","            precisions_at_k[k] = np.mean(precisions_at_k[k])\n","\n","        for k in recall_at_k:\n","            recall_at_k[k] = np.mean(recall_at_k[k])\n","\n","        for k in ndcg:\n","            ndcg[k] = np.mean(ndcg[k])\n","\n","        for k in MRR:\n","            MRR[k] /= len(self.queries_ids)\n","\n","        for k in AveP_at_k:\n","            AveP_at_k[k] = np.mean(AveP_at_k[k])\n","\n","\n","        return {'accuracy@k': num_hits_at_k, 'precision@k': precisions_at_k, 'recall@k': recall_at_k, 'ndcg@k': ndcg, 'mrr@k': MRR, 'map@k': AveP_at_k}\n","\n","\n","    def output_scores(self, scores):\n","        for k in scores['accuracy@k']:\n","            logger.info(\"Accuracy@{}: {:.2f}%\".format(k, scores['accuracy@k'][k]*100))\n","\n","        for k in scores['precision@k']:\n","            logger.info(\"Precision@{}: {:.2f}%\".format(k, scores['precision@k'][k]*100))\n","\n","        for k in scores['recall@k']:\n","            logger.info(\"Recall@{}: {:.2f}%\".format(k, scores['recall@k'][k]*100))\n","\n","        for k in scores['mrr@k']:\n","            logger.info(\"MRR@{}: {:.4f}\".format(k, scores['mrr@k'][k]))\n","\n","        for k in scores['ndcg@k']:\n","            logger.info(\"NDCG@{}: {:.4f}\".format(k, scores['ndcg@k'][k]))\n","\n","        for k in scores['map@k']:\n","            logger.info(\"MAP@{}: {:.4f}\".format(k, scores['map@k'][k]))\n","\n","\n","    @staticmethod\n","    def compute_dcg_at_k(relevances, k):\n","        dcg = 0\n","        for i in range(min(len(relevances), k)):\n","            dcg += relevances[i] / np.log2(i + 2)  #+2 as we start our idx at 0\n","        return dcg\n","    \n","    def get_embeddings(self,model,qr,qr_idx):\n","        info_dataset = infodataset(qr,qr_idx,img_dir,transform = transform_pipe)\n","        info_loader = DataLoader(\n","            info_dataset,\n","            batch_size=BATCH_SIZE,\n","            pin_memory=True,\n","            num_workers = 8,\n","            )\n","        \n","        embeddings = list()\n","        since = time.time()\n","        for i,batch in enumerate(info_loader):\n","            model.eval()\n","\n","            text = batch['token']\n","            images = batch['image']\n","\n","            text,images = torch.tensor(text).to(device), torch.tensor(images).to(device)\n","\n","            with torch.no_grad():\n","                yhat = model.forward(images,text)\n","            \n","            for j in yhat:\n","                embeddings.append(j.cpu().detach().numpy())\n","            \n","            if(i%40==0):\n","                print(f'{i} iterations hase been completed, and model is running for {time.time()-since}')\n","        \n","        return embeddings\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pZFzkQT1oKEP"},"source":["with open(folder_quora+'/devinfo_100.txt','rb') as a:\n","    queries_dev = pickle.load(a)\n","    rel_docs_dev= pickle.load(a)\n","\n","with open(folder_quora+'/testinfo_100.txt','rb') as a:\n","    queries_test= pickle.load(a)\n","    rel_docs_test= pickle.load(a)\n","\n","with open(folder_quora+'/traininfo_100.txt','rb') as a:\n","    queries_train= pickle.load(a)\n","    rel_docs_train= pickle.load(a)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5XTuVNlbeF-5"},"source":["def corpus(qr):\n","    corpus = dict()\n","    for i in qr.index.values:\n","        corpus[i] = 'I dont care'\n","    return corpus"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zFwNBTJCoOS4"},"source":["train_inforet = InformationRetreivalEvaluator(train_qr,queries_train,corpus(train_qr),rel_docs_train)\n","os.makedirs(folder+'/train',exist_ok=True)\n","train_inforet(model,folder+'/train')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WktSxgTYEqg1"},"source":["dev_inforet = InformationRetreivalEvaluator(pd.concat([train_qr,dev_qr]),queries_dev,corpus(train_qr),rel_docs_dev)\n","os.makedirs(folder+'/dev',exist_ok=True)\n","dev_inforet(model,folder+'/dev')"],"execution_count":null,"outputs":[]}]}